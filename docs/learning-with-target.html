<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 5 LEARNING: WITH TARGET | Data Science Book</title>
  <meta name="description" content="Chapter 5 LEARNING: WITH TARGET | Data Science Book" />
  <meta name="generator" content="bookdown 0.21 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 5 LEARNING: WITH TARGET | Data Science Book" />
  <meta property="og:type" content="book" />
  
  
  
  <meta name="github-repo" content="rstudio/bookdown-demo" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 5 LEARNING: WITH TARGET | Data Science Book" />
  
  
  

<meta name="author" content="Łukasz Muszyński" />


<meta name="date" content="2021-04-06" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="learning-patterns-discovering.html"/>
<link rel="next" href="learning-hybrid.html"/>
<script src="libs/header-attrs-2.6/header-attrs.js"></script>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />












<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">A Minimal Book Example</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> INTRO</a></li>
<li class="chapter" data-level="2" data-path="introduction.html"><a href="introduction.html"><i class="fa fa-check"></i><b>2</b> INTRODUCTION</a>
<ul>
<li class="chapter" data-level="2.1" data-path="introduction.html"><a href="introduction.html#to-do"><i class="fa fa-check"></i><b>2.1</b> TO DO</a></li>
<li class="chapter" data-level="2.2" data-path="introduction.html"><a href="introduction.html#draft"><i class="fa fa-check"></i><b>2.2</b> draft</a></li>
<li class="chapter" data-level="2.3" data-path="introduction.html"><a href="introduction.html#introduction-1"><i class="fa fa-check"></i><b>2.3</b> Introduction</a></li>
<li class="chapter" data-level="2.4" data-path="introduction.html"><a href="introduction.html#ai-problems-and-algorithms-classification"><i class="fa fa-check"></i><b>2.4</b> AI problems and algorithms classification</a></li>
<li class="chapter" data-level="2.5" data-path="introduction.html"><a href="introduction.html#meta-issues"><i class="fa fa-check"></i><b>2.5</b> Meta issues</a>
<ul>
<li class="chapter" data-level="2.5.1" data-path="introduction.html"><a href="introduction.html#knowledge-representation"><i class="fa fa-check"></i><b>2.5.1</b> Knowledge representation</a></li>
<li class="chapter" data-level="2.5.2" data-path="introduction.html"><a href="introduction.html#types-of-learning"><i class="fa fa-check"></i><b>2.5.2</b> Types of learning</a>
<ul>
<li class="chapter" data-level="2.5.2.1" data-path="introduction.html"><a href="introduction.html#ensemble-zespołowe"><i class="fa fa-check"></i><b>2.5.2.1</b> Ensemble (zespołowe)</a>
<ul>
<li class="chapter" data-level="2.5.2.1.1" data-path="introduction.html"><a href="introduction.html#bagging-and-pasting"><i class="fa fa-check"></i><b>2.5.2.1.1</b> Bagging and Pasting</a></li>
<li class="chapter" data-level="2.5.2.1.2" data-path="introduction.html"><a href="introduction.html#boosting"><i class="fa fa-check"></i><b>2.5.2.1.2</b> Boosting</a></li>
<li class="chapter" data-level="2.5.2.1.3" data-path="introduction.html"><a href="introduction.html#stacking"><i class="fa fa-check"></i><b>2.5.2.1.3</b> Stacking</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="2.5.3" data-path="introduction.html"><a href="introduction.html#model-complexity"><i class="fa fa-check"></i><b>2.5.3</b> Model complexity</a></li>
<li class="chapter" data-level="2.5.4" data-path="introduction.html"><a href="introduction.html#overfittng-underfitting"><i class="fa fa-check"></i><b>2.5.4</b> Overfittng / underfitting</a></li>
<li class="chapter" data-level="2.5.5" data-path="introduction.html"><a href="introduction.html#bias-variance-trade-off"><i class="fa fa-check"></i><b>2.5.5</b> Bias / Variance trade off</a></li>
<li class="chapter" data-level="2.5.6" data-path="introduction.html"><a href="introduction.html#curse-of-dimentionality"><i class="fa fa-check"></i><b>2.5.6</b> Curse of dimentionality</a></li>
<li class="chapter" data-level="2.5.7" data-path="introduction.html"><a href="introduction.html#sparious-phenomenon"><i class="fa fa-check"></i><b>2.5.7</b> Sparious phenomenon</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="auxiliary-fields.html"><a href="auxiliary-fields.html"><i class="fa fa-check"></i><b>3</b> AUXILIARY FIELDS</a>
<ul>
<li class="chapter" data-level="3.1" data-path="auxiliary-fields.html"><a href="auxiliary-fields.html#introduction-2"><i class="fa fa-check"></i><b>3.1</b> Introduction</a></li>
<li class="chapter" data-level="3.2" data-path="auxiliary-fields.html"><a href="auxiliary-fields.html#philosophy"><i class="fa fa-check"></i><b>3.2</b> Philosophy</a></li>
<li class="chapter" data-level="3.3" data-path="auxiliary-fields.html"><a href="auxiliary-fields.html#logic"><i class="fa fa-check"></i><b>3.3</b> Logic</a></li>
<li class="chapter" data-level="3.4" data-path="auxiliary-fields.html"><a href="auxiliary-fields.html#psychology"><i class="fa fa-check"></i><b>3.4</b> Psychology</a></li>
<li class="chapter" data-level="3.5" data-path="auxiliary-fields.html"><a href="auxiliary-fields.html#linguistics"><i class="fa fa-check"></i><b>3.5</b> Linguistics</a></li>
<li class="chapter" data-level="3.6" data-path="auxiliary-fields.html"><a href="auxiliary-fields.html#cybernetics-control-theory"><i class="fa fa-check"></i><b>3.6</b> Cybernetics (control theory)</a></li>
<li class="chapter" data-level="3.7" data-path="auxiliary-fields.html"><a href="auxiliary-fields.html#math_1-probability"><i class="fa fa-check"></i><b>3.7</b> Math_1 – Probability</a>
<ul>
<li class="chapter" data-level="3.7.1" data-path="auxiliary-fields.html"><a href="auxiliary-fields.html#basics"><i class="fa fa-check"></i><b>3.7.1</b> Basics</a></li>
<li class="chapter" data-level="3.7.2" data-path="auxiliary-fields.html"><a href="auxiliary-fields.html#univariate-distributions"><i class="fa fa-check"></i><b>3.7.2</b> Univariate distributions</a></li>
<li class="chapter" data-level="3.7.3" data-path="auxiliary-fields.html"><a href="auxiliary-fields.html#multivariate-distributions"><i class="fa fa-check"></i><b>3.7.3</b> Multivariate distributions</a></li>
<li class="chapter" data-level="3.7.4" data-path="auxiliary-fields.html"><a href="auxiliary-fields.html#stochastic-processes"><i class="fa fa-check"></i><b>3.7.4</b> Stochastic processes</a></li>
</ul></li>
<li class="chapter" data-level="3.8" data-path="auxiliary-fields.html"><a href="auxiliary-fields.html#math_2-statistics"><i class="fa fa-check"></i><b>3.8</b> Math_2 – Statistics</a>
<ul>
<li class="chapter" data-level="3.8.1" data-path="auxiliary-fields.html"><a href="auxiliary-fields.html#descriptive-statistics"><i class="fa fa-check"></i><b>3.8.1</b> Descriptive statistics</a>
<ul>
<li class="chapter" data-level="3.8.1.1" data-path="auxiliary-fields.html"><a href="auxiliary-fields.html#univariate"><i class="fa fa-check"></i><b>3.8.1.1</b> Univariate</a></li>
<li class="chapter" data-level="3.8.1.2" data-path="auxiliary-fields.html"><a href="auxiliary-fields.html#multivariate"><i class="fa fa-check"></i><b>3.8.1.2</b> Multivariate</a>
<ul>
<li class="chapter" data-level="3.8.1.2.1" data-path="auxiliary-fields.html"><a href="auxiliary-fields.html#correlation"><i class="fa fa-check"></i><b>3.8.1.2.1</b> Correlation</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3.8.2" data-path="auxiliary-fields.html"><a href="auxiliary-fields.html#statistical-and-ecometrical-inference"><i class="fa fa-check"></i><b>3.8.2</b> Statistical and ecometrical inference</a>
<ul>
<li class="chapter" data-level="3.8.2.1" data-path="auxiliary-fields.html"><a href="auxiliary-fields.html#basics-1"><i class="fa fa-check"></i><b>3.8.2.1</b> Basics</a></li>
<li class="chapter" data-level="3.8.2.2" data-path="auxiliary-fields.html"><a href="auxiliary-fields.html#pameters-estimation-algorithms"><i class="fa fa-check"></i><b>3.8.2.2</b> Pameters estimation algorithms</a>
<ul>
<li class="chapter" data-level="3.8.2.2.1" data-path="auxiliary-fields.html"><a href="auxiliary-fields.html#general-moments-methods"><i class="fa fa-check"></i><b>3.8.2.2.1</b> General moments methods</a></li>
<li class="chapter" data-level="3.8.2.2.2" data-path="auxiliary-fields.html"><a href="auxiliary-fields.html#maxium-likehood"><i class="fa fa-check"></i><b>3.8.2.2.2</b> Maxium likehood</a></li>
<li class="chapter" data-level="3.8.2.2.3" data-path="auxiliary-fields.html"><a href="auxiliary-fields.html#nonparametric-techniques"><i class="fa fa-check"></i><b>3.8.2.2.3</b> Nonparametric techniques</a></li>
</ul></li>
<li class="chapter" data-level="3.8.2.3" data-path="auxiliary-fields.html"><a href="auxiliary-fields.html#sampling-techniques"><i class="fa fa-check"></i><b>3.8.2.3</b> Sampling techniques</a>
<ul>
<li class="chapter" data-level="3.8.2.3.1" data-path="auxiliary-fields.html"><a href="auxiliary-fields.html#holdout"><i class="fa fa-check"></i><b>3.8.2.3.1</b> Holdout</a></li>
<li class="chapter" data-level="3.8.2.3.2" data-path="auxiliary-fields.html"><a href="auxiliary-fields.html#boostrap"><i class="fa fa-check"></i><b>3.8.2.3.2</b> Boostrap</a></li>
<li class="chapter" data-level="3.8.2.3.3" data-path="auxiliary-fields.html"><a href="auxiliary-fields.html#jacknife"><i class="fa fa-check"></i><b>3.8.2.3.3</b> Jacknife</a></li>
<li class="chapter" data-level="3.8.2.3.4" data-path="auxiliary-fields.html"><a href="auxiliary-fields.html#permutation"><i class="fa fa-check"></i><b>3.8.2.3.4</b> Permutation</a></li>
<li class="chapter" data-level="3.8.2.3.5" data-path="auxiliary-fields.html"><a href="auxiliary-fields.html#cross-validation"><i class="fa fa-check"></i><b>3.8.2.3.5</b> Cross validation</a></li>
<li class="chapter" data-level="3.8.2.3.6" data-path="auxiliary-fields.html"><a href="auxiliary-fields.html#monte-carlo"><i class="fa fa-check"></i><b>3.8.2.3.6</b> Monte Carlo</a></li>
<li class="chapter" data-level="3.8.2.3.7" data-path="auxiliary-fields.html"><a href="auxiliary-fields.html#stratified-sampling"><i class="fa fa-check"></i><b>3.8.2.3.7</b> Stratified sampling</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3.8.3" data-path="auxiliary-fields.html"><a href="auxiliary-fields.html#other-issues"><i class="fa fa-check"></i><b>3.8.3</b> Other issues</a>
<ul>
<li class="chapter" data-level="3.8.3.1" data-path="auxiliary-fields.html"><a href="auxiliary-fields.html#similarity-and-dissimilarity-meassures-for-observations"><i class="fa fa-check"></i><b>3.8.3.1</b> Similarity and dissimilarity meassures for observations</a></li>
<li class="chapter" data-level="3.8.3.2" data-path="auxiliary-fields.html"><a href="auxiliary-fields.html#similarity-and-dissimilarity-meassures-for-distributions"><i class="fa fa-check"></i><b>3.8.3.2</b> Similarity and dissimilarity meassures for distributions</a></li>
<li class="chapter" data-level="3.8.3.3" data-path="auxiliary-fields.html"><a href="auxiliary-fields.html#measures-of-disorderrandomness"><i class="fa fa-check"></i><b>3.8.3.3</b> Measures of disorder/randomness</a></li>
<li class="chapter" data-level="3.8.3.4" data-path="auxiliary-fields.html"><a href="auxiliary-fields.html#paradoxes"><i class="fa fa-check"></i><b>3.8.3.4</b> Paradoxes</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3.9" data-path="auxiliary-fields.html"><a href="auxiliary-fields.html#math_3-game-theory"><i class="fa fa-check"></i><b>3.9</b> Math_3 – Game theory</a></li>
<li class="chapter" data-level="3.10" data-path="auxiliary-fields.html"><a href="auxiliary-fields.html#math_4-optimisation"><i class="fa fa-check"></i><b>3.10</b> Math_4 – Optimisation</a>
<ul>
<li class="chapter" data-level="3.10.1" data-path="auxiliary-fields.html"><a href="auxiliary-fields.html#functions-optimum"><i class="fa fa-check"></i><b>3.10.1</b> Functions optimum</a></li>
<li class="chapter" data-level="3.10.2" data-path="auxiliary-fields.html"><a href="auxiliary-fields.html#functions-optimum-constrained"><i class="fa fa-check"></i><b>3.10.2</b> Functions optimum – constrained</a>
<ul>
<li class="chapter" data-level="3.10.2.1" data-path="auxiliary-fields.html"><a href="auxiliary-fields.html#lagrange-multipliers"><i class="fa fa-check"></i><b>3.10.2.1</b> Lagrange Multipliers</a></li>
<li class="chapter" data-level="3.10.2.2" data-path="auxiliary-fields.html"><a href="auxiliary-fields.html#linear-programming"><i class="fa fa-check"></i><b>3.10.2.2</b> Linear programming</a></li>
<li class="chapter" data-level="3.10.2.3" data-path="auxiliary-fields.html"><a href="auxiliary-fields.html#nonlinear-programming"><i class="fa fa-check"></i><b>3.10.2.3</b> Nonlinear programming</a></li>
<li class="chapter" data-level="3.10.2.4" data-path="auxiliary-fields.html"><a href="auxiliary-fields.html#regularization"><i class="fa fa-check"></i><b>3.10.2.4</b> Regularization</a></li>
</ul></li>
<li class="chapter" data-level="3.10.3" data-path="auxiliary-fields.html"><a href="auxiliary-fields.html#functional-optimum"><i class="fa fa-check"></i><b>3.10.3</b> Functional optimum</a>
<ul>
<li class="chapter" data-level="3.10.3.1" data-path="auxiliary-fields.html"><a href="auxiliary-fields.html#dynamic-programming"><i class="fa fa-check"></i><b>3.10.3.1</b> Dynamic programming</a></li>
<li class="chapter" data-level="3.10.3.2" data-path="auxiliary-fields.html"><a href="auxiliary-fields.html#calculus-of-variations"><i class="fa fa-check"></i><b>3.10.3.2</b> Calculus of variations</a></li>
</ul></li>
<li class="chapter" data-level="3.10.4" data-path="auxiliary-fields.html"><a href="auxiliary-fields.html#cost-functions"><i class="fa fa-check"></i><b>3.10.4</b> Cost functions</a></li>
<li class="chapter" data-level="3.10.5" data-path="auxiliary-fields.html"><a href="auxiliary-fields.html#back-propagation"><i class="fa fa-check"></i><b>3.10.5</b> Back propagation</a></li>
<li class="chapter" data-level="3.10.6" data-path="auxiliary-fields.html"><a href="auxiliary-fields.html#heuristic-algorithms"><i class="fa fa-check"></i><b>3.10.6</b> Heuristic algorithms</a>
<ul>
<li class="chapter" data-level="3.10.6.1" data-path="auxiliary-fields.html"><a href="auxiliary-fields.html#swarm-algorithm"><i class="fa fa-check"></i><b>3.10.6.1</b> Swarm algorithm</a></li>
<li class="chapter" data-level="3.10.6.2" data-path="auxiliary-fields.html"><a href="auxiliary-fields.html#ants-algoritms"><i class="fa fa-check"></i><b>3.10.6.2</b> Ants algoritms</a></li>
<li class="chapter" data-level="3.10.6.3" data-path="auxiliary-fields.html"><a href="auxiliary-fields.html#genetics-algorithms"><i class="fa fa-check"></i><b>3.10.6.3</b> Genetics algorithms</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3.11" data-path="auxiliary-fields.html"><a href="auxiliary-fields.html#math_4-other-issues"><i class="fa fa-check"></i><b>3.11</b> Math_4 – Other issues</a>
<ul>
<li class="chapter" data-level="3.11.1" data-path="auxiliary-fields.html"><a href="auxiliary-fields.html#functions-usefull-in-data-science"><i class="fa fa-check"></i><b>3.11.1</b> Functions usefull in Data Science</a></li>
<li class="chapter" data-level="3.11.2" data-path="auxiliary-fields.html"><a href="auxiliary-fields.html#useful-tricks"><i class="fa fa-check"></i><b>3.11.2</b> Useful tricks</a></li>
<li class="chapter" data-level="3.11.3" data-path="auxiliary-fields.html"><a href="auxiliary-fields.html#linear-algebra"><i class="fa fa-check"></i><b>3.11.3</b> Linear algebra</a></li>
<li class="chapter" data-level="3.11.4" data-path="auxiliary-fields.html"><a href="auxiliary-fields.html#combinatorics"><i class="fa fa-check"></i><b>3.11.4</b> Combinatorics</a></li>
<li class="chapter" data-level="3.11.5" data-path="auxiliary-fields.html"><a href="auxiliary-fields.html#numerical-methods"><i class="fa fa-check"></i><b>3.11.5</b> Numerical methods</a></li>
<li class="chapter" data-level="3.11.6" data-path="auxiliary-fields.html"><a href="auxiliary-fields.html#equations"><i class="fa fa-check"></i><b>3.11.6</b> Equations</a>
<ul>
<li class="chapter" data-level="3.11.6.1" data-path="auxiliary-fields.html"><a href="auxiliary-fields.html#x-as-number"><i class="fa fa-check"></i><b>3.11.6.1</b> x as number</a></li>
<li class="chapter" data-level="3.11.6.2" data-path="auxiliary-fields.html"><a href="auxiliary-fields.html#x-as-derivative-differential-and-difference-equations"><i class="fa fa-check"></i><b>3.11.6.2</b> X as derivative: differential and difference equations</a></li>
<li class="chapter" data-level="3.11.6.3" data-path="auxiliary-fields.html"><a href="auxiliary-fields.html#choas"><i class="fa fa-check"></i><b>3.11.6.3</b> Choas</a>
<ul>
<li class="chapter" data-level="3.11.6.3.1" data-path="auxiliary-fields.html"><a href="auxiliary-fields.html#logistic-map"><i class="fa fa-check"></i><b>3.11.6.3.1</b> logistic map</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3.11.7" data-path="auxiliary-fields.html"><a href="auxiliary-fields.html#fuzzy-logic"><i class="fa fa-check"></i><b>3.11.7</b> Fuzzy logic</a></li>
<li class="chapter" data-level="3.11.8" data-path="auxiliary-fields.html"><a href="auxiliary-fields.html#graphs"><i class="fa fa-check"></i><b>3.11.8</b> Graphs</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html"><i class="fa fa-check"></i><b>4</b> LEARNING: PATTERNS DISCOVERING</a>
<ul>
<li class="chapter" data-level="4.1" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#introduction-3"><i class="fa fa-check"></i><b>4.1</b> Introduction</a></li>
<li class="chapter" data-level="4.2" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#clustering"><i class="fa fa-check"></i><b>4.2</b> Clustering</a>
<ul>
<li class="chapter" data-level="4.2.1" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#introduction-4"><i class="fa fa-check"></i><b>4.2.1</b> Introduction</a></li>
<li class="chapter" data-level="4.2.2" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#hierarchical"><i class="fa fa-check"></i><b>4.2.2</b> Hierarchical</a>
<ul>
<li class="chapter" data-level="4.2.2.1" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#agglomerativedivisive"><i class="fa fa-check"></i><b>4.2.2.1</b> Agglomerative/Divisive</a></li>
<li class="chapter" data-level="4.2.2.2" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#chameleon"><i class="fa fa-check"></i><b>4.2.2.2</b> CHAMELEON</a></li>
<li class="chapter" data-level="4.2.2.3" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#birch"><i class="fa fa-check"></i><b>4.2.2.3</b> BIRCH</a></li>
<li class="chapter" data-level="4.2.2.4" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#hdbscan"><i class="fa fa-check"></i><b>4.2.2.4</b> HDBSCAN</a></li>
<li class="chapter" data-level="4.2.2.5" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#rock"><i class="fa fa-check"></i><b>4.2.2.5</b> ROCK</a></li>
<li class="chapter" data-level="4.2.2.6" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#echidna"><i class="fa fa-check"></i><b>4.2.2.6</b> Echidna</a></li>
<li class="chapter" data-level="4.2.2.7" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#diana"><i class="fa fa-check"></i><b>4.2.2.7</b> Diana</a></li>
<li class="chapter" data-level="4.2.2.8" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#agnes"><i class="fa fa-check"></i><b>4.2.2.8</b> Agnes</a></li>
</ul></li>
<li class="chapter" data-level="4.2.3" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#partititonal"><i class="fa fa-check"></i><b>4.2.3</b> Partititonal</a>
<ul>
<li class="chapter" data-level="4.2.3.1" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#k-methods"><i class="fa fa-check"></i><b>4.2.3.1</b> k-methods</a>
<ul>
<li class="chapter" data-level="4.2.3.1.1" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#k-means"><i class="fa fa-check"></i><b>4.2.3.1.1</b> k-means</a></li>
<li class="chapter" data-level="4.2.3.1.2" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#k-centroids"><i class="fa fa-check"></i><b>4.2.3.1.2</b> k-centroids</a></li>
<li class="chapter" data-level="4.2.3.1.3" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#k-modes"><i class="fa fa-check"></i><b>4.2.3.1.3</b> k-modes</a></li>
<li class="chapter" data-level="4.2.3.1.4" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#k-mini-batches"><i class="fa fa-check"></i><b>4.2.3.1.4</b> k-mini-batches</a></li>
</ul></li>
<li class="chapter" data-level="4.2.3.2" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#pam"><i class="fa fa-check"></i><b>4.2.3.2</b> PAM</a></li>
<li class="chapter" data-level="4.2.3.3" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#claranas"><i class="fa fa-check"></i><b>4.2.3.3</b> CLARANAS</a></li>
<li class="chapter" data-level="4.2.3.4" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#clara"><i class="fa fa-check"></i><b>4.2.3.4</b> CLARA</a></li>
<li class="chapter" data-level="4.2.3.5" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#fcm"><i class="fa fa-check"></i><b>4.2.3.5</b> FCM</a></li>
<li class="chapter" data-level="4.2.3.6" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#fcmdc"><i class="fa fa-check"></i><b>4.2.3.6</b> FCMdC</a></li>
<li class="chapter" data-level="4.2.3.7" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#fanny"><i class="fa fa-check"></i><b>4.2.3.7</b> Fanny</a></li>
</ul></li>
<li class="chapter" data-level="4.2.4" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#density-latent-distibutions"><i class="fa fa-check"></i><b>4.2.4</b> Density /Latent distibutions</a>
<ul>
<li class="chapter" data-level="4.2.4.1" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#dbscan"><i class="fa fa-check"></i><b>4.2.4.1</b> DBSCAN</a></li>
<li class="chapter" data-level="4.2.4.2" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#optics"><i class="fa fa-check"></i><b>4.2.4.2</b> OPTICS</a></li>
<li class="chapter" data-level="4.2.4.3" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#predecon"><i class="fa fa-check"></i><b>4.2.4.3</b> PreDeCon</a></li>
<li class="chapter" data-level="4.2.4.4" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#subclu"><i class="fa fa-check"></i><b>4.2.4.4</b> SUBCLU</a></li>
<li class="chapter" data-level="4.2.4.5" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#denclue"><i class="fa fa-check"></i><b>4.2.4.5</b> DENCLUE</a></li>
<li class="chapter" data-level="4.2.4.6" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#dbclasd"><i class="fa fa-check"></i><b>4.2.4.6</b> DBCLASD</a></li>
<li class="chapter" data-level="4.2.4.7" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#graph-based-clustering"><i class="fa fa-check"></i><b>4.2.4.7</b> Graph based clustering</a>
<ul>
<li class="chapter" data-level="4.2.4.7.1" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#spectral-clustering"><i class="fa fa-check"></i><b>4.2.4.7.1</b> Spectral clustering</a></li>
</ul></li>
<li class="chapter" data-level="4.2.4.8" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#mean-shift"><i class="fa fa-check"></i><b>4.2.4.8</b> Mean Shift</a></li>
<li class="chapter" data-level="4.2.4.9" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#substractive-methods"><i class="fa fa-check"></i><b>4.2.4.9</b> Substractive Methods</a></li>
</ul></li>
<li class="chapter" data-level="4.2.5" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#grids"><i class="fa fa-check"></i><b>4.2.5</b> Grids</a>
<ul>
<li class="chapter" data-level="4.2.5.1" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#sting"><i class="fa fa-check"></i><b>4.2.5.1</b> STING</a></li>
<li class="chapter" data-level="4.2.5.2" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#clique"><i class="fa fa-check"></i><b>4.2.5.2</b> CLIQUE</a></li>
<li class="chapter" data-level="4.2.5.3" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#wavecluster"><i class="fa fa-check"></i><b>4.2.5.3</b> WaveCluster</a></li>
<li class="chapter" data-level="4.2.5.4" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#optigrid"><i class="fa fa-check"></i><b>4.2.5.4</b> OptiGrid</a></li>
</ul></li>
<li class="chapter" data-level="4.2.6" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#model-based"><i class="fa fa-check"></i><b>4.2.6</b> Model Based</a>
<ul>
<li class="chapter" data-level="4.2.6.1" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#em"><i class="fa fa-check"></i><b>4.2.6.1</b> EM</a></li>
<li class="chapter" data-level="4.2.6.2" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#classit"><i class="fa fa-check"></i><b>4.2.6.2</b> CLASSIT</a></li>
<li class="chapter" data-level="4.2.6.3" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#soms"><i class="fa fa-check"></i><b>4.2.6.3</b> SOMs</a></li>
<li class="chapter" data-level="4.2.6.4" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#cobweb"><i class="fa fa-check"></i><b>4.2.6.4</b> COBWEB</a></li>
<li class="chapter" data-level="4.2.6.5" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#neural-networks"><i class="fa fa-check"></i><b>4.2.6.5</b> Neural Networks</a></li>
</ul></li>
<li class="chapter" data-level="4.2.7" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#other"><i class="fa fa-check"></i><b>4.2.7</b> Other</a>
<ul>
<li class="chapter" data-level="4.2.7.1" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#affinity-propagation"><i class="fa fa-check"></i><b>4.2.7.1</b> Affinity propagation</a></li>
<li class="chapter" data-level="4.2.7.2" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#fuzzy-c-means"><i class="fa fa-check"></i><b>4.2.7.2</b> Fuzzy c-means</a></li>
</ul></li>
<li class="chapter" data-level="4.2.8" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#by-problems"><i class="fa fa-check"></i><b>4.2.8</b> By problems</a>
<ul>
<li class="chapter" data-level="4.2.8.1" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#numerical-and-categorical"><i class="fa fa-check"></i><b>4.2.8.1</b> Numerical and categorical</a></li>
<li class="chapter" data-level="4.2.8.2" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#text-data"><i class="fa fa-check"></i><b>4.2.8.2</b> Text data</a></li>
<li class="chapter" data-level="4.2.8.3" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#sound"><i class="fa fa-check"></i><b>4.2.8.3</b> Sound</a></li>
<li class="chapter" data-level="4.2.8.4" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#vision"><i class="fa fa-check"></i><b>4.2.8.4</b> Vision</a></li>
</ul></li>
<li class="chapter" data-level="4.2.9" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#results-diagnostics"><i class="fa fa-check"></i><b>4.2.9</b> Results diagnostics</a></li>
<li class="chapter" data-level="4.2.10" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#elements-selection"><i class="fa fa-check"></i><b>4.2.10</b> Elements selection</a></li>
<li class="chapter" data-level="4.2.11" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#iml"><i class="fa fa-check"></i><b>4.2.11</b> IML</a></li>
<li class="chapter" data-level="4.2.12" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#by-problems-1"><i class="fa fa-check"></i><b>4.2.12</b> By problems</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#association"><i class="fa fa-check"></i><b>4.3</b> Association</a>
<ul>
<li class="chapter" data-level="4.3.1" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#apriori"><i class="fa fa-check"></i><b>4.3.1</b> Apriori</a></li>
<li class="chapter" data-level="4.3.2" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#euclat"><i class="fa fa-check"></i><b>4.3.2</b> Euclat</a></li>
<li class="chapter" data-level="4.3.3" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#fp-growth"><i class="fa fa-check"></i><b>4.3.3</b> FP-growth</a></li>
<li class="chapter" data-level="4.3.4" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#assoc"><i class="fa fa-check"></i><b>4.3.4</b> ASSOC</a></li>
<li class="chapter" data-level="4.3.5" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#opus"><i class="fa fa-check"></i><b>4.3.5</b> OPUS</a></li>
<li class="chapter" data-level="4.3.6" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#neural-networks-1"><i class="fa fa-check"></i><b>4.3.6</b> Neural Networks</a></li>
<li class="chapter" data-level="4.3.7" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#results-diagnostics-1"><i class="fa fa-check"></i><b>4.3.7</b> Results diagnostics</a></li>
<li class="chapter" data-level="4.3.8" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#elements-selection-1"><i class="fa fa-check"></i><b>4.3.8</b> Elements selection</a></li>
<li class="chapter" data-level="4.3.9" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#iml-1"><i class="fa fa-check"></i><b>4.3.9</b> IML</a></li>
<li class="chapter" data-level="4.3.10" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#by-problems-2"><i class="fa fa-check"></i><b>4.3.10</b> By problems</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#dimentionality-reduction"><i class="fa fa-check"></i><b>4.4</b> Dimentionality reduction</a>
<ul>
<li class="chapter" data-level="4.4.1" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#unsupervised"><i class="fa fa-check"></i><b>4.4.1</b> Unsupervised</a>
<ul>
<li class="chapter" data-level="4.4.1.1" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#pca"><i class="fa fa-check"></i><b>4.4.1.1</b> PCA</a>
<ul>
<li class="chapter" data-level="4.4.1.1.1" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#basic-pca"><i class="fa fa-check"></i><b>4.4.1.1.1</b> Basic PCA</a></li>
<li class="chapter" data-level="4.4.1.1.2" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#incremental-pca"><i class="fa fa-check"></i><b>4.4.1.1.2</b> Incremental PCA</a></li>
<li class="chapter" data-level="4.4.1.1.3" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#kernel-pca"><i class="fa fa-check"></i><b>4.4.1.1.3</b> kernel PCA</a></li>
</ul></li>
<li class="chapter" data-level="4.4.1.2" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#t-sne"><i class="fa fa-check"></i><b>4.4.1.2</b> t-SNE</a></li>
<li class="chapter" data-level="4.4.1.3" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#local-linear-embedding"><i class="fa fa-check"></i><b>4.4.1.3</b> Local Linear Embedding</a></li>
<li class="chapter" data-level="4.4.1.4" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#isomap"><i class="fa fa-check"></i><b>4.4.1.4</b> Isomap</a></li>
<li class="chapter" data-level="4.4.1.5" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#lda-as-dimentional-reduction"><i class="fa fa-check"></i><b>4.4.1.5</b> LDA as dimentional reduction</a></li>
<li class="chapter" data-level="4.4.1.6" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#partial-least-squares"><i class="fa fa-check"></i><b>4.4.1.6</b> Partial Least Squares</a></li>
<li class="chapter" data-level="4.4.1.7" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#multidimentional-scaling"><i class="fa fa-check"></i><b>4.4.1.7</b> Multidimentional Scaling</a></li>
<li class="chapter" data-level="4.4.1.8" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#correspondence-analysis"><i class="fa fa-check"></i><b>4.4.1.8</b> Correspondence Analysis</a></li>
<li class="chapter" data-level="4.4.1.9" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#kohonen-networks"><i class="fa fa-check"></i><b>4.4.1.9</b> Kohonen Networks</a></li>
<li class="chapter" data-level="4.4.1.10" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#neural-networks-other-than-kohonen"><i class="fa fa-check"></i><b>4.4.1.10</b> Neural Networks (other than Kohonen)</a></li>
<li class="chapter" data-level="4.4.1.11" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#factor-analysis"><i class="fa fa-check"></i><b>4.4.1.11</b> Factor Analysis</a></li>
<li class="chapter" data-level="4.4.1.12" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#latent-semantic-analysis"><i class="fa fa-check"></i><b>4.4.1.12</b> Latent semantic analysis</a></li>
<li class="chapter" data-level="4.4.1.13" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#autoencoders"><i class="fa fa-check"></i><b>4.4.1.13</b> Autoencoders</a></li>
<li class="chapter" data-level="4.4.1.14" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#analiza-glownych-skladowych-pca-principal-component-analysis"><i class="fa fa-check"></i><b>4.4.1.14</b> Analiza glownych skladowych (PCA) [Principal Component Analysis]</a></li>
<li class="chapter" data-level="4.4.1.15" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#analiza-glownych-wspolrzednych-pcoa-principal-coordinates-analysis"><i class="fa fa-check"></i><b>4.4.1.15</b> Analiza glownych wspolrzednych (PCoA) [Principal Coordinates Analysis]</a></li>
<li class="chapter" data-level="4.4.1.16" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#analiza-korespondencji-ca-correspondenca-analysis"><i class="fa fa-check"></i><b>4.4.1.16</b> Analiza korespondencji (CA) [Correspondenca Analysis]</a></li>
<li class="chapter" data-level="4.4.1.17" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#asymetryczna-analiza-korespondencji-aca-non-symmetric-correspondence-analysis"><i class="fa fa-check"></i><b>4.4.1.17</b> Asymetryczna analiza korespondencji (ACA) [Non-symmetric correspondence analysis]</a></li>
<li class="chapter" data-level="4.4.1.18" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#kanoniczna-analiza-korespondencji-cca-canonical-correspondence-analysis"><i class="fa fa-check"></i><b>4.4.1.18</b> Kanoniczna analiza korespondencji (CCA) [Canonical correspondence analysis]</a></li>
<li class="chapter" data-level="4.4.1.19" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#laczna-analiza-korespondencji-jca-joint-correspondence-analysis"><i class="fa fa-check"></i><b>4.4.1.19</b> Laczna analiza korespondencji (JCA) [Joint Correspondence Analysis]</a></li>
<li class="chapter" data-level="4.4.1.20" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#odwrocona-analiza-korespondencji-invca-inverse-correspondence-analysis"><i class="fa fa-check"></i><b>4.4.1.20</b> Odwrocona analiza korespondencji (InvCA) [Inverse correspondence analysis]</a></li>
<li class="chapter" data-level="4.4.1.21" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#taksowkowa-analiza-korespondencji-tca-taxicab-correspondence-analysis"><i class="fa fa-check"></i><b>4.4.1.21</b> Taksowkowa analiza korespondencji (TCA) [Taxicab Correspondence Analysis]</a></li>
<li class="chapter" data-level="4.4.1.22" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#rozmyta-analiza-korespondencji-fca-fuzzy-correspondence-analysis"><i class="fa fa-check"></i><b>4.4.1.22</b> Rozmyta analiza korespondencji (FCA) [Fuzzy correspondence analysis]</a></li>
<li class="chapter" data-level="4.4.1.23" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#wieloraka-analiza-korespondencji-mca-multiple-correspondence-analysis"><i class="fa fa-check"></i><b>4.4.1.23</b> Wieloraka analiza korespondencji (MCA) [Multiple correspondence analysis]</a></li>
<li class="chapter" data-level="4.4.1.24" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#regularyzowana-wieloraka-analiza-korespondencji-rmca-regularized-multiple-correspondence-analysis"><i class="fa fa-check"></i><b>4.4.1.24</b> Regularyzowana wieloraka analiza korespondencji (RMCA) [Regularized Multiple Correspondence Analysis]</a></li>
<li class="chapter" data-level="4.4.1.25" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#analiza-czynnikowa-fa-factor-analysis"><i class="fa fa-check"></i><b>4.4.1.25</b> Analiza czynnikowa (FA) <span>Factor analysis</span></a></li>
<li class="chapter" data-level="4.4.1.26" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#wieloraka-analiza-czynnikowa-mfa-multiple-factor-analysis"><i class="fa fa-check"></i><b>4.4.1.26</b> Wieloraka analiza czynnikowa (MFA) [Multiple Factor Analysis]</a></li>
<li class="chapter" data-level="4.4.1.27" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#analiza-skladowych-niezaleznych-ica-independent-component-analysis"><i class="fa fa-check"></i><b>4.4.1.27</b> Analiza skladowych niezaleznych (ICA) [Independent component analysis ]</a></li>
<li class="chapter" data-level="4.4.1.28" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#dca-detreded-correspondence-analysis"><i class="fa fa-check"></i><b>4.4.1.28</b> (DCA) [Detreded Correspondence Analysis]</a></li>
<li class="chapter" data-level="4.4.1.29" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#nieliniowa-analiza-korespondencji-npca-nonlinear-principal-components-analysis"><i class="fa fa-check"></i><b>4.4.1.29</b> Nieliniowa Analiza Korespondencji (NPCA) [Nonlinear Principal Components Analysis]</a></li>
<li class="chapter" data-level="4.4.1.30" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#mds-non-metric-multidimensional-scaling"><i class="fa fa-check"></i><b>4.4.1.30</b> (MDS) [Non-Metric Multidimensional Scaling]</a></li>
</ul></li>
<li class="chapter" data-level="4.4.2" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#supervised"><i class="fa fa-check"></i><b>4.4.2</b> Supervised</a>
<ul>
<li class="chapter" data-level="4.4.2.1" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#lda"><i class="fa fa-check"></i><b>4.4.2.1</b> LDA</a></li>
<li class="chapter" data-level="4.4.2.2" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#partial-least-squares-1"><i class="fa fa-check"></i><b>4.4.2.2</b> Partial Least Squares</a></li>
</ul></li>
<li class="chapter" data-level="4.4.3" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#results-diagnostics-2"><i class="fa fa-check"></i><b>4.4.3</b> Results diagnostics</a></li>
<li class="chapter" data-level="4.4.4" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#elements-selection-2"><i class="fa fa-check"></i><b>4.4.4</b> Elements selection</a></li>
<li class="chapter" data-level="4.4.5" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#iml-2"><i class="fa fa-check"></i><b>4.4.5</b> IML</a></li>
<li class="chapter" data-level="4.4.6" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#by-problems-3"><i class="fa fa-check"></i><b>4.4.6</b> By problems</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#casuality-analysis"><i class="fa fa-check"></i><b>4.5</b> Casuality analysis</a>
<ul>
<li class="chapter" data-level="4.5.1" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#sem"><i class="fa fa-check"></i><b>4.5.1</b> SEM</a>
<ul>
<li class="chapter" data-level="4.5.1.1" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#confirmatory-factor-analysis"><i class="fa fa-check"></i><b>4.5.1.1</b> Confirmatory factor analysis</a></li>
<li class="chapter" data-level="4.5.1.2" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#confirmatory-composite-analysis"><i class="fa fa-check"></i><b>4.5.1.2</b> Confirmatory composite analysis</a></li>
<li class="chapter" data-level="4.5.1.3" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#path-analysis"><i class="fa fa-check"></i><b>4.5.1.3</b> Path analysis</a></li>
<li class="chapter" data-level="4.5.1.4" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#partial-least-squares-path-modeling"><i class="fa fa-check"></i><b>4.5.1.4</b> Partial least squares path modeling</a></li>
<li class="chapter" data-level="4.5.1.5" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#latent-growth-modeling"><i class="fa fa-check"></i><b>4.5.1.5</b> Latent growth modeling</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4.6" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#dimentions-decomoposition"><i class="fa fa-check"></i><b>4.6</b> Dimentions decomoposition</a>
<ul>
<li class="chapter" data-level="4.6.1" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#results-diagnostics-3"><i class="fa fa-check"></i><b>4.6.1</b> Results diagnostics</a></li>
<li class="chapter" data-level="4.6.2" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#elements-selection-3"><i class="fa fa-check"></i><b>4.6.2</b> Elements selection</a></li>
<li class="chapter" data-level="4.6.3" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#iml-3"><i class="fa fa-check"></i><b>4.6.3</b> IML</a></li>
<li class="chapter" data-level="4.6.4" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#by-problems-4"><i class="fa fa-check"></i><b>4.6.4</b> By problems</a></li>
</ul></li>
<li class="chapter" data-level="4.7" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#generative-models"><i class="fa fa-check"></i><b>4.7</b> Generative models</a>
<ul>
<li class="chapter" data-level="4.7.1" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#results-diagnostics-4"><i class="fa fa-check"></i><b>4.7.1</b> Results diagnostics</a></li>
<li class="chapter" data-level="4.7.2" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#elements-selection-4"><i class="fa fa-check"></i><b>4.7.2</b> Elements selection</a></li>
<li class="chapter" data-level="4.7.3" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#iml-4"><i class="fa fa-check"></i><b>4.7.3</b> IML</a></li>
<li class="chapter" data-level="4.7.4" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#by-problems-5"><i class="fa fa-check"></i><b>4.7.4</b> By problems</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="learning-with-target.html"><a href="learning-with-target.html"><i class="fa fa-check"></i><b>5</b> LEARNING: WITH TARGET</a>
<ul>
<li class="chapter" data-level="5.1" data-path="learning-with-target.html"><a href="learning-with-target.html#introduction-5"><i class="fa fa-check"></i><b>5.1</b> Introduction</a>
<ul>
<li class="chapter" data-level="5.1.1" data-path="learning-with-target.html"><a href="learning-with-target.html#classification"><i class="fa fa-check"></i><b>5.1.1</b> Classification</a></li>
<li class="chapter" data-level="5.1.2" data-path="learning-with-target.html"><a href="learning-with-target.html#regression"><i class="fa fa-check"></i><b>5.1.2</b> Regression</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="learning-with-target.html"><a href="learning-with-target.html#econometrical-regression"><i class="fa fa-check"></i><b>5.2</b> Econometrical regression</a>
<ul>
<li class="chapter" data-level="5.2.1" data-path="learning-with-target.html"><a href="learning-with-target.html#basic-regression"><i class="fa fa-check"></i><b>5.2.1</b> Basic regression</a></li>
<li class="chapter" data-level="5.2.2" data-path="learning-with-target.html"><a href="learning-with-target.html#basic-dynamic-model"><i class="fa fa-check"></i><b>5.2.2</b> Basic dynamic model</a></li>
<li class="chapter" data-level="5.2.3" data-path="learning-with-target.html"><a href="learning-with-target.html#generalisations-and-constrains"><i class="fa fa-check"></i><b>5.2.3</b> Generalisations and constrains</a></li>
<li class="chapter" data-level="5.2.4" data-path="learning-with-target.html"><a href="learning-with-target.html#bayesian-inference"><i class="fa fa-check"></i><b>5.2.4</b> Bayesian inference</a></li>
<li class="chapter" data-level="5.2.5" data-path="learning-with-target.html"><a href="learning-with-target.html#multivariate-models"><i class="fa fa-check"></i><b>5.2.5</b> Multivariate models</a></li>
<li class="chapter" data-level="5.2.6" data-path="learning-with-target.html"><a href="learning-with-target.html#models-with-effects"><i class="fa fa-check"></i><b>5.2.6</b> Models with effects</a></li>
<li class="chapter" data-level="5.2.7" data-path="learning-with-target.html"><a href="learning-with-target.html#nonparametric-regression"><i class="fa fa-check"></i><b>5.2.7</b> Nonparametric regression</a>
<ul>
<li class="chapter" data-level="5.2.7.1" data-path="learning-with-target.html"><a href="learning-with-target.html#splines"><i class="fa fa-check"></i><b>5.2.7.1</b> Splines</a></li>
<li class="chapter" data-level="5.2.7.2" data-path="learning-with-target.html"><a href="learning-with-target.html#isotonic"><i class="fa fa-check"></i><b>5.2.7.2</b> Isotonic</a></li>
</ul></li>
<li class="chapter" data-level="5.2.8" data-path="learning-with-target.html"><a href="learning-with-target.html#other-regression-models"><i class="fa fa-check"></i><b>5.2.8</b> Other regression models</a>
<ul>
<li class="chapter" data-level="5.2.8.1" data-path="learning-with-target.html"><a href="learning-with-target.html#canonical-analysis"><i class="fa fa-check"></i><b>5.2.8.1</b> Canonical analysis</a></li>
<li class="chapter" data-level="5.2.8.2" data-path="learning-with-target.html"><a href="learning-with-target.html#anova-manova-ancova"><i class="fa fa-check"></i><b>5.2.8.2</b> ANOVA MANOVA ANCOVA</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="learning-with-target.html"><a href="learning-with-target.html#lda-qda"><i class="fa fa-check"></i><b>5.3</b> LDA &amp; QDA</a></li>
<li class="chapter" data-level="5.4" data-path="learning-with-target.html"><a href="learning-with-target.html#bayesian-models"><i class="fa fa-check"></i><b>5.4</b> Bayesian models</a></li>
<li class="chapter" data-level="5.5" data-path="learning-with-target.html"><a href="learning-with-target.html#trees"><i class="fa fa-check"></i><b>5.5</b> Trees</a>
<ul>
<li class="chapter" data-level="5.5.1" data-path="learning-with-target.html"><a href="learning-with-target.html#pros"><i class="fa fa-check"></i><b>5.5.1</b> pros</a></li>
<li class="chapter" data-level="5.5.2" data-path="learning-with-target.html"><a href="learning-with-target.html#cons"><i class="fa fa-check"></i><b>5.5.2</b> cons</a></li>
<li class="chapter" data-level="5.5.3" data-path="learning-with-target.html"><a href="learning-with-target.html#classification-1"><i class="fa fa-check"></i><b>5.5.3</b> Classification</a></li>
<li class="chapter" data-level="5.5.4" data-path="learning-with-target.html"><a href="learning-with-target.html#regression-1"><i class="fa fa-check"></i><b>5.5.4</b> Regression</a></li>
</ul></li>
<li class="chapter" data-level="5.6" data-path="learning-with-target.html"><a href="learning-with-target.html#svm"><i class="fa fa-check"></i><b>5.6</b> SVM</a>
<ul>
<li class="chapter" data-level="5.6.1" data-path="learning-with-target.html"><a href="learning-with-target.html#classification-2"><i class="fa fa-check"></i><b>5.6.1</b> Classification</a></li>
<li class="chapter" data-level="5.6.2" data-path="learning-with-target.html"><a href="learning-with-target.html#regression-2"><i class="fa fa-check"></i><b>5.6.2</b> Regression</a></li>
</ul></li>
<li class="chapter" data-level="5.7" data-path="learning-with-target.html"><a href="learning-with-target.html#k-nn"><i class="fa fa-check"></i><b>5.7</b> K-NN</a>
<ul>
<li class="chapter" data-level="5.7.1" data-path="learning-with-target.html"><a href="learning-with-target.html#classification-3"><i class="fa fa-check"></i><b>5.7.1</b> Classification</a></li>
<li class="chapter" data-level="5.7.2" data-path="learning-with-target.html"><a href="learning-with-target.html#regression-3"><i class="fa fa-check"></i><b>5.7.2</b> Regression</a></li>
</ul></li>
<li class="chapter" data-level="5.8" data-path="learning-with-target.html"><a href="learning-with-target.html#log-linear-model"><i class="fa fa-check"></i><b>5.8</b> Log-linear model</a></li>
<li class="chapter" data-level="5.9" data-path="learning-with-target.html"><a href="learning-with-target.html#similarity-learning"><i class="fa fa-check"></i><b>5.9</b> Similarity learning</a></li>
<li class="chapter" data-level="5.10" data-path="learning-with-target.html"><a href="learning-with-target.html#survival-models"><i class="fa fa-check"></i><b>5.10</b> Survival models</a></li>
<li class="chapter" data-level="5.11" data-path="learning-with-target.html"><a href="learning-with-target.html#ensembled-models"><i class="fa fa-check"></i><b>5.11</b> Ensembled models</a>
<ul>
<li class="chapter" data-level="5.11.1" data-path="learning-with-target.html"><a href="learning-with-target.html#bagging-and-pasting-1"><i class="fa fa-check"></i><b>5.11.1</b> Bagging and Pasting</a>
<ul>
<li class="chapter" data-level="5.11.1.1" data-path="learning-with-target.html"><a href="learning-with-target.html#random-forest"><i class="fa fa-check"></i><b>5.11.1.1</b> Random Forest</a>
<ul>
<li class="chapter" data-level="5.11.1.1.1" data-path="learning-with-target.html"><a href="learning-with-target.html#out-of-bag-error"><i class="fa fa-check"></i><b>5.11.1.1.1</b> Out of Bag Error</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5.11.2" data-path="learning-with-target.html"><a href="learning-with-target.html#boosting-1"><i class="fa fa-check"></i><b>5.11.2</b> Boosting</a>
<ul>
<li class="chapter" data-level="5.11.2.1" data-path="learning-with-target.html"><a href="learning-with-target.html#ada-boost"><i class="fa fa-check"></i><b>5.11.2.1</b> Ada Boost</a></li>
<li class="chapter" data-level="5.11.2.2" data-path="learning-with-target.html"><a href="learning-with-target.html#lightgbm"><i class="fa fa-check"></i><b>5.11.2.2</b> LightGBM</a></li>
</ul></li>
<li class="chapter" data-level="5.11.3" data-path="learning-with-target.html"><a href="learning-with-target.html#stacking-1"><i class="fa fa-check"></i><b>5.11.3</b> Stacking</a></li>
<li class="chapter" data-level="5.11.4" data-path="learning-with-target.html"><a href="learning-with-target.html#twicing"><i class="fa fa-check"></i><b>5.11.4</b> Twicing</a></li>
<li class="chapter" data-level="5.11.5" data-path="learning-with-target.html"><a href="learning-with-target.html#bandling"><i class="fa fa-check"></i><b>5.11.5</b> Bandling</a></li>
</ul></li>
<li class="chapter" data-level="5.12" data-path="learning-with-target.html"><a href="learning-with-target.html#neural-networks-2"><i class="fa fa-check"></i><b>5.12</b> Neural Networks</a>
<ul>
<li class="chapter" data-level="5.12.1" data-path="learning-with-target.html"><a href="learning-with-target.html#introduction-6"><i class="fa fa-check"></i><b>5.12.1</b> Introduction</a></li>
<li class="chapter" data-level="5.12.2" data-path="learning-with-target.html"><a href="learning-with-target.html#basics-2"><i class="fa fa-check"></i><b>5.12.2</b> Basics</a></li>
<li class="chapter" data-level="5.12.3" data-path="learning-with-target.html"><a href="learning-with-target.html#reccurent"><i class="fa fa-check"></i><b>5.12.3</b> Reccurent</a>
<ul>
<li class="chapter" data-level="5.12.3.1" data-path="learning-with-target.html"><a href="learning-with-target.html#simple-reccurent"><i class="fa fa-check"></i><b>5.12.3.1</b> Simple reccurent</a></li>
<li class="chapter" data-level="5.12.3.2" data-path="learning-with-target.html"><a href="learning-with-target.html#bidirectorial"><i class="fa fa-check"></i><b>5.12.3.2</b> Bidirectorial</a></li>
<li class="chapter" data-level="5.12.3.3" data-path="learning-with-target.html"><a href="learning-with-target.html#lstm"><i class="fa fa-check"></i><b>5.12.3.3</b> LSTM</a></li>
<li class="chapter" data-level="5.12.3.4" data-path="learning-with-target.html"><a href="learning-with-target.html#gru"><i class="fa fa-check"></i><b>5.12.3.4</b> GRU</a></li>
<li class="chapter" data-level="5.12.3.5" data-path="learning-with-target.html"><a href="learning-with-target.html#attention"><i class="fa fa-check"></i><b>5.12.3.5</b> Attention</a></li>
</ul></li>
<li class="chapter" data-level="5.12.4" data-path="learning-with-target.html"><a href="learning-with-target.html#cnn"><i class="fa fa-check"></i><b>5.12.4</b> CNN</a></li>
<li class="chapter" data-level="5.12.5" data-path="learning-with-target.html"><a href="learning-with-target.html#resnet"><i class="fa fa-check"></i><b>5.12.5</b> Resnet</a></li>
</ul></li>
<li class="chapter" data-level="5.13" data-path="learning-with-target.html"><a href="learning-with-target.html#stochastic-processes-1"><i class="fa fa-check"></i><b>5.13</b> Stochastic processes</a>
<ul>
<li class="chapter" data-level="5.13.1" data-path="learning-with-target.html"><a href="learning-with-target.html#basic-trend-models"><i class="fa fa-check"></i><b>5.13.1</b> Basic trend models</a></li>
<li class="chapter" data-level="5.13.2" data-path="learning-with-target.html"><a href="learning-with-target.html#basic-adaptative-models"><i class="fa fa-check"></i><b>5.13.2</b> Basic adaptative models</a></li>
<li class="chapter" data-level="5.13.3" data-path="learning-with-target.html"><a href="learning-with-target.html#econometric-time-series-models"><i class="fa fa-check"></i><b>5.13.3</b> Econometric time series models</a>
<ul>
<li class="chapter" data-level="5.13.3.1" data-path="learning-with-target.html"><a href="learning-with-target.html#dynamic-for-example-error-correction-models"><i class="fa fa-check"></i><b>5.13.3.1</b> dynamic (for example error correction models)</a></li>
<li class="chapter" data-level="5.13.3.2" data-path="learning-with-target.html"><a href="learning-with-target.html#sarimax"><i class="fa fa-check"></i><b>5.13.3.2</b> SARIMAX</a></li>
<li class="chapter" data-level="5.13.3.3" data-path="learning-with-target.html"><a href="learning-with-target.html#varimax"><i class="fa fa-check"></i><b>5.13.3.3</b> VARIMAX</a></li>
<li class="chapter" data-level="5.13.3.4" data-path="learning-with-target.html"><a href="learning-with-target.html#arch-class-models"><i class="fa fa-check"></i><b>5.13.3.4</b> ARCH class models</a></li>
<li class="chapter" data-level="5.13.3.5" data-path="learning-with-target.html"><a href="learning-with-target.html#cointegration-including-arld-approach"><i class="fa fa-check"></i><b>5.13.3.5</b> Cointegration (including ARLD approach)</a></li>
</ul></li>
<li class="chapter" data-level="5.13.4" data-path="learning-with-target.html"><a href="learning-with-target.html#time-series-decomposition-decomposition"><i class="fa fa-check"></i><b>5.13.4</b> Time series decomposition decomposition</a></li>
<li class="chapter" data-level="5.13.5" data-path="learning-with-target.html"><a href="learning-with-target.html#kalman-filters"><i class="fa fa-check"></i><b>5.13.5</b> Kalman filters</a></li>
<li class="chapter" data-level="5.13.6" data-path="learning-with-target.html"><a href="learning-with-target.html#neural-networks-3"><i class="fa fa-check"></i><b>5.13.6</b> Neural Networks</a>
<ul>
<li class="chapter" data-level="5.13.6.1" data-path="learning-with-target.html"><a href="learning-with-target.html#long-short-term-memory"><i class="fa fa-check"></i><b>5.13.6.1</b> Long short term memory</a></li>
<li class="chapter" data-level="5.13.6.2" data-path="learning-with-target.html"><a href="learning-with-target.html#cnn-1"><i class="fa fa-check"></i><b>5.13.6.2</b> CNN</a></li>
</ul></li>
<li class="chapter" data-level="5.13.7" data-path="learning-with-target.html"><a href="learning-with-target.html#panel-regression"><i class="fa fa-check"></i><b>5.13.7</b> Panel Regression</a></li>
<li class="chapter" data-level="5.13.8" data-path="learning-with-target.html"><a href="learning-with-target.html#gaussian-mixtures"><i class="fa fa-check"></i><b>5.13.8</b> Gaussian Mixtures</a></li>
<li class="chapter" data-level="5.13.9" data-path="learning-with-target.html"><a href="learning-with-target.html#ensembled-models-1"><i class="fa fa-check"></i><b>5.13.9</b> Ensembled models</a></li>
<li class="chapter" data-level="5.13.10" data-path="learning-with-target.html"><a href="learning-with-target.html#martingales"><i class="fa fa-check"></i><b>5.13.10</b> Martingales</a></li>
<li class="chapter" data-level="5.13.11" data-path="learning-with-target.html"><a href="learning-with-target.html#markov-process"><i class="fa fa-check"></i><b>5.13.11</b> Markov Process</a></li>
<li class="chapter" data-level="5.13.12" data-path="learning-with-target.html"><a href="learning-with-target.html#winer-process"><i class="fa fa-check"></i><b>5.13.12</b> Winer Process</a></li>
</ul></li>
<li class="chapter" data-level="5.14" data-path="learning-with-target.html"><a href="learning-with-target.html#results-diagnostics-5"><i class="fa fa-check"></i><b>5.14</b> Results diagnostics</a>
<ul>
<li class="chapter" data-level="5.14.1" data-path="learning-with-target.html"><a href="learning-with-target.html#classification-4"><i class="fa fa-check"></i><b>5.14.1</b> Classification</a>
<ul>
<li class="chapter" data-level="5.14.1.1" data-path="learning-with-target.html"><a href="learning-with-target.html#scores-calibration"><i class="fa fa-check"></i><b>5.14.1.1</b> Scores calibration</a>
<ul>
<li class="chapter" data-level="5.14.1.1.1" data-path="learning-with-target.html"><a href="learning-with-target.html#problem"><i class="fa fa-check"></i><b>5.14.1.1.1</b> Problem</a></li>
<li class="chapter" data-level="5.14.1.1.2" data-path="learning-with-target.html"><a href="learning-with-target.html#kalibracja-a-problemy-konkretnych-modeli"><i class="fa fa-check"></i><b>5.14.1.1.2</b> Kalibracja a problemy konkretnych modeli</a></li>
<li class="chapter" data-level="5.14.1.1.3" data-path="learning-with-target.html"><a href="learning-with-target.html#calibration-curve-reliability-diagram"><i class="fa fa-check"></i><b>5.14.1.1.3</b> Calibration curve (reliability diagram)</a></li>
<li class="chapter" data-level="5.14.1.1.4" data-path="learning-with-target.html"><a href="learning-with-target.html#skalowanie-platta"><i class="fa fa-check"></i><b>5.14.1.1.4</b> Skalowanie Platta</a></li>
<li class="chapter" data-level="5.14.1.1.5" data-path="learning-with-target.html"><a href="learning-with-target.html#regresja-izotoniczna"><i class="fa fa-check"></i><b>5.14.1.1.5</b> Regresja izotoniczna</a></li>
<li class="chapter" data-level="5.14.1.1.6" data-path="learning-with-target.html"><a href="learning-with-target.html#calibration-in-sklearn"><i class="fa fa-check"></i><b>5.14.1.1.6</b> Calibration in <em>sklearn</em></a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5.14.2" data-path="learning-with-target.html"><a href="learning-with-target.html#regression-4"><i class="fa fa-check"></i><b>5.14.2</b> Regression</a></li>
</ul></li>
<li class="chapter" data-level="5.15" data-path="learning-with-target.html"><a href="learning-with-target.html#elements-selection-5"><i class="fa fa-check"></i><b>5.15</b> Elements selection</a>
<ul>
<li class="chapter" data-level="5.15.1" data-path="learning-with-target.html"><a href="learning-with-target.html#feature-selection"><i class="fa fa-check"></i><b>5.15.1</b> Feature selection</a>
<ul>
<li class="chapter" data-level="5.15.1.0.1" data-path="learning-with-target.html"><a href="learning-with-target.html#feature-importance"><i class="fa fa-check"></i><b>5.15.1.0.1</b> Feature Importance</a></li>
</ul></li>
<li class="chapter" data-level="5.15.2" data-path="learning-with-target.html"><a href="learning-with-target.html#variables-exogenity"><i class="fa fa-check"></i><b>5.15.2</b> Variables exogenity</a>
<ul>
<li class="chapter" data-level="5.15.2.1" data-path="learning-with-target.html"><a href="learning-with-target.html#granger-exogenity"><i class="fa fa-check"></i><b>5.15.2.1</b> Granger Exogenity</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5.16" data-path="learning-with-target.html"><a href="learning-with-target.html#iml-5"><i class="fa fa-check"></i><b>5.16</b> IML</a></li>
<li class="chapter" data-level="5.17" data-path="learning-with-target.html"><a href="learning-with-target.html#by-problems-6"><i class="fa fa-check"></i><b>5.17</b> By problems</a>
<ul>
<li class="chapter" data-level="5.17.1" data-path="learning-with-target.html"><a href="learning-with-target.html#numerical"><i class="fa fa-check"></i><b>5.17.1</b> Numerical</a></li>
<li class="chapter" data-level="5.17.2" data-path="learning-with-target.html"><a href="learning-with-target.html#categorical"><i class="fa fa-check"></i><b>5.17.2</b> Categorical</a></li>
<li class="chapter" data-level="5.17.3" data-path="learning-with-target.html"><a href="learning-with-target.html#text"><i class="fa fa-check"></i><b>5.17.3</b> Text</a></li>
<li class="chapter" data-level="5.17.4" data-path="learning-with-target.html"><a href="learning-with-target.html#sound-1"><i class="fa fa-check"></i><b>5.17.4</b> Sound</a></li>
<li class="chapter" data-level="5.17.5" data-path="learning-with-target.html"><a href="learning-with-target.html#vision-1"><i class="fa fa-check"></i><b>5.17.5</b> Vision</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="learning-hybrid.html"><a href="learning-hybrid.html"><i class="fa fa-check"></i><b>6</b> LEARNING: HYBRID</a>
<ul>
<li class="chapter" data-level="6.1" data-path="learning-hybrid.html"><a href="learning-hybrid.html#introduction-7"><i class="fa fa-check"></i><b>6.1</b> Introduction</a></li>
<li class="chapter" data-level="6.2" data-path="learning-hybrid.html"><a href="learning-hybrid.html#semi-supervised-learning"><i class="fa fa-check"></i><b>6.2</b> Semi-supervised learning</a>
<ul>
<li class="chapter" data-level="6.2.1" data-path="learning-hybrid.html"><a href="learning-hybrid.html#em-1"><i class="fa fa-check"></i><b>6.2.1</b> EM</a></li>
<li class="chapter" data-level="6.2.2" data-path="learning-hybrid.html"><a href="learning-hybrid.html#cple"><i class="fa fa-check"></i><b>6.2.2</b> CPLE</a></li>
<li class="chapter" data-level="6.2.3" data-path="learning-hybrid.html"><a href="learning-hybrid.html#svm-and-tsvm"><i class="fa fa-check"></i><b>6.2.3</b> SVM and TSVM</a></li>
<li class="chapter" data-level="6.2.4" data-path="learning-hybrid.html"><a href="learning-hybrid.html#graphs-1"><i class="fa fa-check"></i><b>6.2.4</b> Graphs</a></li>
<li class="chapter" data-level="6.2.5" data-path="learning-hybrid.html"><a href="learning-hybrid.html#neural-networks-4"><i class="fa fa-check"></i><b>6.2.5</b> Neural Networks</a></li>
<li class="chapter" data-level="6.2.6" data-path="learning-hybrid.html"><a href="learning-hybrid.html#by-problems-7"><i class="fa fa-check"></i><b>6.2.6</b> By problems</a>
<ul>
<li class="chapter" data-level="6.2.6.1" data-path="learning-hybrid.html"><a href="learning-hybrid.html#numerical-and-categorical-1"><i class="fa fa-check"></i><b>6.2.6.1</b> Numerical and categorical</a></li>
<li class="chapter" data-level="6.2.6.2" data-path="learning-hybrid.html"><a href="learning-hybrid.html#text-data-1"><i class="fa fa-check"></i><b>6.2.6.2</b> Text data</a></li>
<li class="chapter" data-level="6.2.6.3" data-path="learning-hybrid.html"><a href="learning-hybrid.html#sound-2"><i class="fa fa-check"></i><b>6.2.6.3</b> Sound</a></li>
<li class="chapter" data-level="6.2.6.4" data-path="learning-hybrid.html"><a href="learning-hybrid.html#vision-2"><i class="fa fa-check"></i><b>6.2.6.4</b> Vision</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="learning-hybrid.html"><a href="learning-hybrid.html#self-supervised-learning"><i class="fa fa-check"></i><b>6.3</b> Self-supervised learning</a></li>
<li class="chapter" data-level="6.4" data-path="learning-hybrid.html"><a href="learning-hybrid.html#mult-instance-learning"><i class="fa fa-check"></i><b>6.4</b> Mult-instance learning</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="learning-reinforcement.html"><a href="learning-reinforcement.html"><i class="fa fa-check"></i><b>7</b> LEARNING: REINFORCEMENT</a>
<ul>
<li class="chapter" data-level="7.1" data-path="learning-reinforcement.html"><a href="learning-reinforcement.html#introduction-8"><i class="fa fa-check"></i><b>7.1</b> Introduction</a></li>
<li class="chapter" data-level="7.2" data-path="learning-reinforcement.html"><a href="learning-reinforcement.html#td"><i class="fa fa-check"></i><b>7.2</b> TD</a></li>
<li class="chapter" data-level="7.3" data-path="learning-reinforcement.html"><a href="learning-reinforcement.html#sarsa"><i class="fa fa-check"></i><b>7.3</b> SARSA</a></li>
<li class="chapter" data-level="7.4" data-path="learning-reinforcement.html"><a href="learning-reinforcement.html#q-learning"><i class="fa fa-check"></i><b>7.4</b> Q-learning</a></li>
<li class="chapter" data-level="7.5" data-path="learning-reinforcement.html"><a href="learning-reinforcement.html#by-problems-8"><i class="fa fa-check"></i><b>7.5</b> By problems</a>
<ul>
<li class="chapter" data-level="7.5.1" data-path="learning-reinforcement.html"><a href="learning-reinforcement.html#numerical-and-categorical-2"><i class="fa fa-check"></i><b>7.5.1</b> Numerical and categorical</a></li>
<li class="chapter" data-level="7.5.2" data-path="learning-reinforcement.html"><a href="learning-reinforcement.html#text-data-2"><i class="fa fa-check"></i><b>7.5.2</b> Text data</a></li>
<li class="chapter" data-level="7.5.3" data-path="learning-reinforcement.html"><a href="learning-reinforcement.html#sound-3"><i class="fa fa-check"></i><b>7.5.3</b> Sound</a></li>
<li class="chapter" data-level="7.5.4" data-path="learning-reinforcement.html"><a href="learning-reinforcement.html#vision-3"><i class="fa fa-check"></i><b>7.5.4</b> Vision</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="8" data-path="data-preprocessing.html"><a href="data-preprocessing.html"><i class="fa fa-check"></i><b>8</b> DATA PREPROCESSING</a>
<ul>
<li class="chapter" data-level="8.1" data-path="data-preprocessing.html"><a href="data-preprocessing.html#introduction-9"><i class="fa fa-check"></i><b>8.1</b> Introduction</a></li>
<li class="chapter" data-level="8.2" data-path="data-preprocessing.html"><a href="data-preprocessing.html#variables-tranformations"><i class="fa fa-check"></i><b>8.2</b> Variables tranformations</a>
<ul>
<li class="chapter" data-level="8.2.1" data-path="data-preprocessing.html"><a href="data-preprocessing.html#discretization"><i class="fa fa-check"></i><b>8.2.1</b> discretization</a></li>
<li class="chapter" data-level="8.2.2" data-path="data-preprocessing.html"><a href="data-preprocessing.html#numeric-variable-continuous-tranformations"><i class="fa fa-check"></i><b>8.2.2</b> numeric variable continuous tranformations</a></li>
<li class="chapter" data-level="8.2.3" data-path="data-preprocessing.html"><a href="data-preprocessing.html#nominal-variables-tranformations"><i class="fa fa-check"></i><b>8.2.3</b> nominal variables tranformations</a>
<ul>
<li class="chapter" data-level="8.2.3.1" data-path="data-preprocessing.html"><a href="data-preprocessing.html#encoding"><i class="fa fa-check"></i><b>8.2.3.1</b> encoding</a>
<ul>
<li class="chapter" data-level="8.2.3.1.1" data-path="data-preprocessing.html"><a href="data-preprocessing.html#one-hot"><i class="fa fa-check"></i><b>8.2.3.1.1</b> one-hot</a></li>
<li class="chapter" data-level="8.2.3.1.2" data-path="data-preprocessing.html"><a href="data-preprocessing.html#embedding"><i class="fa fa-check"></i><b>8.2.3.1.2</b> embedding</a></li>
</ul></li>
<li class="chapter" data-level="8.2.3.2" data-path="data-preprocessing.html"><a href="data-preprocessing.html#other-1"><i class="fa fa-check"></i><b>8.2.3.2</b> other</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="8.3" data-path="data-preprocessing.html"><a href="data-preprocessing.html#data-problems"><i class="fa fa-check"></i><b>8.3</b> Data Problems</a>
<ul>
<li class="chapter" data-level="8.3.1" data-path="data-preprocessing.html"><a href="data-preprocessing.html#numeric-and-categorical"><i class="fa fa-check"></i><b>8.3.1</b> Numeric and categorical</a>
<ul>
<li class="chapter" data-level="8.3.1.1" data-path="data-preprocessing.html"><a href="data-preprocessing.html#extreme-values"><i class="fa fa-check"></i><b>8.3.1.1</b> Extreme values</a></li>
<li class="chapter" data-level="8.3.1.2" data-path="data-preprocessing.html"><a href="data-preprocessing.html#missing-values"><i class="fa fa-check"></i><b>8.3.1.2</b> Missing values</a></li>
<li class="chapter" data-level="8.3.1.3" data-path="data-preprocessing.html"><a href="data-preprocessing.html#untipical-distributions-for-example-copula-models-kernel-estimators-logaritmic-transofmations-ect.-mixed-distributions"><i class="fa fa-check"></i><b>8.3.1.3</b> Untipical distributions (for example copula models, kernel estimators, logaritmic transofmations ect., mixed distributions)</a></li>
<li class="chapter" data-level="8.3.1.4" data-path="data-preprocessing.html"><a href="data-preprocessing.html#censoredtruncated-data"><i class="fa fa-check"></i><b>8.3.1.4</b> Censored/truncated data</a></li>
<li class="chapter" data-level="8.3.1.5" data-path="data-preprocessing.html"><a href="data-preprocessing.html#aggregated-date-decomposition"><i class="fa fa-check"></i><b>8.3.1.5</b> Aggregated date (decomposition)</a></li>
<li class="chapter" data-level="8.3.1.6" data-path="data-preprocessing.html"><a href="data-preprocessing.html#meassurement-error-for-example-kalman-filter-model"><i class="fa fa-check"></i><b>8.3.1.6</b> Meassurement error (for example Kalman filter model)</a></li>
<li class="chapter" data-level="8.3.1.7" data-path="data-preprocessing.html"><a href="data-preprocessing.html#granularity-of-data"><i class="fa fa-check"></i><b>8.3.1.7</b> Granularity of data</a></li>
<li class="chapter" data-level="8.3.1.8" data-path="data-preprocessing.html"><a href="data-preprocessing.html#imbalanced-categories"><i class="fa fa-check"></i><b>8.3.1.8</b> Imbalanced categories</a></li>
<li class="chapter" data-level="8.3.1.9" data-path="data-preprocessing.html"><a href="data-preprocessing.html#small-samples-problem"><i class="fa fa-check"></i><b>8.3.1.9</b> Small samples problem</a></li>
</ul></li>
<li class="chapter" data-level="8.3.2" data-path="data-preprocessing.html"><a href="data-preprocessing.html#text-1"><i class="fa fa-check"></i><b>8.3.2</b> Text</a></li>
<li class="chapter" data-level="8.3.3" data-path="data-preprocessing.html"><a href="data-preprocessing.html#visual"><i class="fa fa-check"></i><b>8.3.3</b> Visual</a></li>
<li class="chapter" data-level="8.3.4" data-path="data-preprocessing.html"><a href="data-preprocessing.html#sound-4"><i class="fa fa-check"></i><b>8.3.4</b> Sound</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="9" data-path="other-models-and-problems.html"><a href="other-models-and-problems.html"><i class="fa fa-check"></i><b>9</b> OTHER MODELS AND PROBLEMS</a>
<ul>
<li class="chapter" data-level="9.1" data-path="other-models-and-problems.html"><a href="other-models-and-problems.html#social-network"><i class="fa fa-check"></i><b>9.1</b> Social Network</a></li>
<li class="chapter" data-level="9.2" data-path="other-models-and-problems.html"><a href="other-models-and-problems.html#queuing-kolejki"><i class="fa fa-check"></i><b>9.2</b> Queuing (kolejki)</a></li>
<li class="chapter" data-level="9.3" data-path="other-models-and-problems.html"><a href="other-models-and-problems.html#spacial-model-modele-przestrzenne"><i class="fa fa-check"></i><b>9.3</b> Spacial model (modele przestrzenne)</a></li>
<li class="chapter" data-level="9.4" data-path="other-models-and-problems.html"><a href="other-models-and-problems.html#six-sigma-process-quality-control-quality-control-charts"><i class="fa fa-check"></i><b>9.4</b> SIX-Sigma (process quality control, quality control charts)</a></li>
<li class="chapter" data-level="9.5" data-path="other-models-and-problems.html"><a href="other-models-and-problems.html#process-analysis-analiza-procesu"><i class="fa fa-check"></i><b>9.5</b> Process Analysis (Analiza procesu)</a></li>
<li class="chapter" data-level="9.6" data-path="other-models-and-problems.html"><a href="other-models-and-problems.html#reliability-and-item-analysis-analiza-rzetelności"><i class="fa fa-check"></i><b>9.6</b> Reliability and Item Analysis (Analiza rzetelności)</a></li>
<li class="chapter" data-level="9.7" data-path="other-models-and-problems.html"><a href="other-models-and-problems.html#experimentla-design-planowanie-doświadczeń"><i class="fa fa-check"></i><b>9.7</b> Experimentla design (Planowanie doświadczeń)</a></li>
<li class="chapter" data-level="9.8" data-path="other-models-and-problems.html"><a href="other-models-and-problems.html#sequential-analysis"><i class="fa fa-check"></i><b>9.8</b> Sequential analysis</a></li>
<li class="chapter" data-level="9.9" data-path="other-models-and-problems.html"><a href="other-models-and-problems.html#logic-programming-programowanie-logiczne"><i class="fa fa-check"></i><b>9.9</b> Logic programming (programowanie logiczne)</a></li>
<li class="chapter" data-level="9.10" data-path="other-models-and-problems.html"><a href="other-models-and-problems.html#financial-models"><i class="fa fa-check"></i><b>9.10</b> Financial models</a>
<ul>
<li class="chapter" data-level="9.10.1" data-path="other-models-and-problems.html"><a href="other-models-and-problems.html#distance-to-default"><i class="fa fa-check"></i><b>9.10.1</b> Distance to default</a></li>
<li class="chapter" data-level="9.10.2" data-path="other-models-and-problems.html"><a href="other-models-and-problems.html#copula-methods-kopuły"><i class="fa fa-check"></i><b>9.10.2</b> Copula methods (kopuły)</a></li>
<li class="chapter" data-level="9.10.3" data-path="other-models-and-problems.html"><a href="other-models-and-problems.html#black-scholes"><i class="fa fa-check"></i><b>9.10.3</b> Black Scholes</a></li>
<li class="chapter" data-level="9.10.4" data-path="other-models-and-problems.html"><a href="other-models-and-problems.html#vasicek"><i class="fa fa-check"></i><b>9.10.4</b> Vasicek</a></li>
<li class="chapter" data-level="9.10.5" data-path="other-models-and-problems.html"><a href="other-models-and-problems.html#markovitz"><i class="fa fa-check"></i><b>9.10.5</b> Markovitz</a></li>
<li class="chapter" data-level="9.10.6" data-path="other-models-and-problems.html"><a href="other-models-and-problems.html#kmv"><i class="fa fa-check"></i><b>9.10.6</b> KMV</a></li>
<li class="chapter" data-level="9.10.7" data-path="other-models-and-problems.html"><a href="other-models-and-problems.html#credit-metrics"><i class="fa fa-check"></i><b>9.10.7</b> Credit Metrics</a></li>
<li class="chapter" data-level="9.10.8" data-path="other-models-and-problems.html"><a href="other-models-and-problems.html#credit-plus"><i class="fa fa-check"></i><b>9.10.8</b> Credit Plus</a></li>
<li class="chapter" data-level="9.10.9" data-path="other-models-and-problems.html"><a href="other-models-and-problems.html#z-scores"><i class="fa fa-check"></i><b>9.10.9</b> z-scores</a></li>
<li class="chapter" data-level="9.10.10" data-path="other-models-and-problems.html"><a href="other-models-and-problems.html#capm"><i class="fa fa-check"></i><b>9.10.10</b> CAPM</a></li>
<li class="chapter" data-level="9.10.11" data-path="other-models-and-problems.html"><a href="other-models-and-problems.html#var---value-at-risk"><i class="fa fa-check"></i><b>9.10.11</b> VaR - Value at risk</a></li>
<li class="chapter" data-level="9.10.12" data-path="other-models-and-problems.html"><a href="other-models-and-problems.html#cva"><i class="fa fa-check"></i><b>9.10.12</b> CVA</a></li>
<li class="chapter" data-level="9.10.13" data-path="other-models-and-problems.html"><a href="other-models-and-problems.html#acturial-models"><i class="fa fa-check"></i><b>9.10.13</b> Acturial models</a></li>
</ul></li>
<li class="chapter" data-level="9.11" data-path="other-models-and-problems.html"><a href="other-models-and-problems.html#biologicalmedical-models"><i class="fa fa-check"></i><b>9.11</b> Biological/Medical Models</a></li>
<li class="chapter" data-level="9.12" data-path="other-models-and-problems.html"><a href="other-models-and-problems.html#case-studies"><i class="fa fa-check"></i><b>9.12</b> Case Studies</a>
<ul>
<li class="chapter" data-level="9.12.1" data-path="other-models-and-problems.html"><a href="other-models-and-problems.html#score-cards"><i class="fa fa-check"></i><b>9.12.1</b> Score cards</a></li>
<li class="chapter" data-level="9.12.2" data-path="other-models-and-problems.html"><a href="other-models-and-problems.html#pd-models"><i class="fa fa-check"></i><b>9.12.2</b> PD models</a></li>
<li class="chapter" data-level="9.12.3" data-path="other-models-and-problems.html"><a href="other-models-and-problems.html#lgd-models"><i class="fa fa-check"></i><b>9.12.3</b> LGD models</a></li>
<li class="chapter" data-level="9.12.4" data-path="other-models-and-problems.html"><a href="other-models-and-problems.html#churn-models"><i class="fa fa-check"></i><b>9.12.4</b> Churn models</a></li>
<li class="chapter" data-level="9.12.5" data-path="other-models-and-problems.html"><a href="other-models-and-problems.html#icaap"><i class="fa fa-check"></i><b>9.12.5</b> ICAAP</a></li>
<li class="chapter" data-level="9.12.6" data-path="other-models-and-problems.html"><a href="other-models-and-problems.html#ama"><i class="fa fa-check"></i><b>9.12.6</b> AMA</a></li>
<li class="chapter" data-level="9.12.7" data-path="other-models-and-problems.html"><a href="other-models-and-problems.html#stress-tests"><i class="fa fa-check"></i><b>9.12.7</b> Stress tests</a></li>
<li class="chapter" data-level="9.12.8" data-path="other-models-and-problems.html"><a href="other-models-and-problems.html#master-scale"><i class="fa fa-check"></i><b>9.12.8</b> Master Scale</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="10" data-path="appendicies.html"><a href="appendicies.html"><i class="fa fa-check"></i><b>10</b> APPENDICIES</a>
<ul>
<li class="chapter" data-level="10.1" data-path="appendicies.html"><a href="appendicies.html#appendix-a-index-of-statistical-test"><i class="fa fa-check"></i><b>10.1</b> Appendix A INDEX OF STATISTICAL TEST</a></li>
<li class="chapter" data-level="10.2" data-path="appendicies.html"><a href="appendicies.html#appendix-b-most-important-theorems-in-statistics-and-probability-calculus"><i class="fa fa-check"></i><b>10.2</b> Appendix B Most important theorems in Statistics and probability calculus</a>
<ul>
<li class="chapter" data-level="10.2.1" data-path="appendicies.html"><a href="appendicies.html#central-limit"><i class="fa fa-check"></i><b>10.2.1</b> Central Limit</a></li>
<li class="chapter" data-level="10.2.2" data-path="appendicies.html"><a href="appendicies.html#fisher-tippett-gnedenko"><i class="fa fa-check"></i><b>10.2.2</b> Fisher-Tippett-Gnedenko</a></li>
</ul></li>
<li class="chapter" data-level="10.3" data-path="appendicies.html"><a href="appendicies.html#appendix-c-different-entries"><i class="fa fa-check"></i><b>10.3</b> Appendix C Different entries</a>
<ul>
<li class="chapter" data-level="10.3.1" data-path="appendicies.html"><a href="appendicies.html#out-of-bag-error-1"><i class="fa fa-check"></i><b>10.3.1</b> out-of-bag error</a></li>
<li class="chapter" data-level="10.3.2" data-path="appendicies.html"><a href="appendicies.html#hyperparameters"><i class="fa fa-check"></i><b>10.3.2</b> hyperparameters</a></li>
<li class="chapter" data-level="10.3.3" data-path="appendicies.html"><a href="appendicies.html#information-leakage"><i class="fa fa-check"></i><b>10.3.3</b> information leakage</a></li>
<li class="chapter" data-level="10.3.4" data-path="appendicies.html"><a href="appendicies.html#apriori-vs-aposteriori"><i class="fa fa-check"></i><b>10.3.4</b> apriori vs aposteriori</a></li>
<li class="chapter" data-level="10.3.5" data-path="appendicies.html"><a href="appendicies.html#colaborative-filtering"><i class="fa fa-check"></i><b>10.3.5</b> colaborative filtering</a></li>
<li class="chapter" data-level="10.3.6" data-path="appendicies.html"><a href="appendicies.html#embedding-1"><i class="fa fa-check"></i><b>10.3.6</b> embedding</a></li>
</ul></li>
<li class="chapter" data-level="10.4" data-path="appendicies.html"><a href="appendicies.html#appendix-d-dictionary-polish---english"><i class="fa fa-check"></i><b>10.4</b> Appendix D DICTIONARY POLISH - ENGLISH</a></li>
<li class="chapter" data-level="10.5" data-path="appendicies.html"><a href="appendicies.html#links---important"><i class="fa fa-check"></i><b>10.5</b> Links - important</a>
<ul>
<li class="chapter" data-level="10.5.1" data-path="appendicies.html"><a href="appendicies.html#books"><i class="fa fa-check"></i><b>10.5.1</b> books</a></li>
<li class="chapter" data-level="10.5.2" data-path="appendicies.html"><a href="appendicies.html#strony"><i class="fa fa-check"></i><b>10.5.2</b> strony</a></li>
<li class="chapter" data-level="10.5.3" data-path="appendicies.html"><a href="appendicies.html#youtube"><i class="fa fa-check"></i><b>10.5.3</b> youtube</a></li>
</ul></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Data Science Book</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="learning-with-target" class="section level1" number="5">
<h1><span class="header-section-number">Chapter 5</span> LEARNING: WITH TARGET</h1>
<div id="introduction-5" class="section level2" number="5.1">
<h2><span class="header-section-number">5.1</span> Introduction</h2>
<div id="classification" class="section level3" number="5.1.1">
<h3><span class="header-section-number">5.1.1</span> Classification</h3>
</div>
<div id="regression" class="section level3" number="5.1.2">
<h3><span class="header-section-number">5.1.2</span> Regression</h3>
</div>
</div>
<div id="econometrical-regression" class="section level2" number="5.2">
<h2><span class="header-section-number">5.2</span> Econometrical regression</h2>
<div id="basic-regression" class="section level3" number="5.2.1">
<h3><span class="header-section-number">5.2.1</span> Basic regression</h3>
</div>
<div id="basic-dynamic-model" class="section level3" number="5.2.2">
<h3><span class="header-section-number">5.2.2</span> Basic dynamic model</h3>
</div>
<div id="generalisations-and-constrains" class="section level3" number="5.2.3">
<h3><span class="header-section-number">5.2.3</span> Generalisations and constrains</h3>
</div>
<div id="bayesian-inference" class="section level3" number="5.2.4">
<h3><span class="header-section-number">5.2.4</span> Bayesian inference</h3>
</div>
<div id="multivariate-models" class="section level3" number="5.2.5">
<h3><span class="header-section-number">5.2.5</span> Multivariate models</h3>
</div>
<div id="models-with-effects" class="section level3" number="5.2.6">
<h3><span class="header-section-number">5.2.6</span> Models with effects</h3>
</div>
<div id="nonparametric-regression" class="section level3" number="5.2.7">
<h3><span class="header-section-number">5.2.7</span> Nonparametric regression</h3>
<div id="splines" class="section level4" number="5.2.7.1">
<h4><span class="header-section-number">5.2.7.1</span> Splines</h4>
</div>
<div id="isotonic" class="section level4" number="5.2.7.2">
<h4><span class="header-section-number">5.2.7.2</span> Isotonic</h4>
</div>
</div>
<div id="other-regression-models" class="section level3" number="5.2.8">
<h3><span class="header-section-number">5.2.8</span> Other regression models</h3>
<div id="canonical-analysis" class="section level4" number="5.2.8.1">
<h4><span class="header-section-number">5.2.8.1</span> Canonical analysis</h4>
</div>
<div id="anova-manova-ancova" class="section level4" number="5.2.8.2">
<h4><span class="header-section-number">5.2.8.2</span> ANOVA MANOVA ANCOVA</h4>
</div>
</div>
</div>
<div id="lda-qda" class="section level2" number="5.3">
<h2><span class="header-section-number">5.3</span> LDA &amp; QDA</h2>
</div>
<div id="bayesian-models" class="section level2" number="5.4">
<h2><span class="header-section-number">5.4</span> Bayesian models</h2>
</div>
<div id="trees" class="section level2" number="5.5">
<h2><span class="header-section-number">5.5</span> Trees</h2>
<p>Drzewo jest przykładem algorytmu zachłannego (greedy)</p>
<p><strong>Dlaczego w praktyce używa się tylko drzew binarnych:</strong></p>
<p><a href="https://stats.stackexchange.com/questions/12187/are-decision-trees-almost-always-binary-trees">(link:
stack_change)</a></p>
<p>The number of possible splits goes up exponentially. If you are
splitting on a continuous variable that has 1000 distinct values, there
are 999 binary splits, but 999*998 trinary splits. There are</p>
<p><span class="math inline">\(\binom{1000-1}{3-1} = 999*998/2\)</span></p>
<p>splits, actually.</p>
<div id="pros" class="section level3" number="5.5.1">
<h3><span class="header-section-number">5.5.1</span> pros</h3>
<ul>
<li><p>Nie trzeba preprocesować danych. Nie trzeba normalizować zmiennych
ciągłych. Zmiennych jakościowych nie trzeba rekodować.</p></li>
<li><p>możliwość pracy z danymi jakościowymi i ilościowymi</p></li>
<li><p>są nieparametryczne. Nie mają założeń o rozkładach</p></li>
<li><p>nie ma problemu z brakami danych. Przy analizie zmiennej na splicie
braki są prostu pomijane.</p></li>
<li><p>łatwa interpretacja</p></li>
<li><p>szybkie wyliczenie predykcji przez niską złożoność obliczeniową
O(log(m)).</p></li>
<li><p>Tak naprawdę same przeprowadzają selekcje cech (feature selection).</p></li>
</ul>
</div>
<div id="cons" class="section level3" number="5.5.2">
<h3><span class="header-section-number">5.5.2</span> cons</h3>
<ul>
<li><p>Łatwo model przetrenować. Są niestabilne. Małe zmiany w danych
generują mocno różniące się drzewa. Przez te problemy występuje duża
wariancja modelu i słabe uogólnianie.</p></li>
<li><p>są algorytmem zachłannym więc nie dają gwarancji znalezienia optimum
globalnego.</p></li>
<li><p>dosyć długo czas estymacji modelu</p></li>
<li><p>wrażliwość na rotacje danych <span class="citation">(<a href="appendicies.html#ref-Geron2018" role="doc-biblioref">Geron 2018</a>)</span> s. 184.</p></li>
</ul>
<p><a href="https://dhirajkumarblog.medium.com/top-5-advantages-and-disadvantages-of-decision-tree-algorithm-428ebd199d9a">dhirajkumarblog.medium</a></p>
</div>
<div id="classification-1" class="section level3" number="5.5.3">
<h3><span class="header-section-number">5.5.3</span> Classification</h3>
</div>
<div id="regression-1" class="section level3" number="5.5.4">
<h3><span class="header-section-number">5.5.4</span> Regression</h3>
</div>
</div>
<div id="svm" class="section level2" number="5.6">
<h2><span class="header-section-number">5.6</span> SVM</h2>
<div id="classification-2" class="section level3" number="5.6.1">
<h3><span class="header-section-number">5.6.1</span> Classification</h3>
</div>
<div id="regression-2" class="section level3" number="5.6.2">
<h3><span class="header-section-number">5.6.2</span> Regression</h3>
</div>
</div>
<div id="k-nn" class="section level2" number="5.7">
<h2><span class="header-section-number">5.7</span> K-NN</h2>
<div id="classification-3" class="section level3" number="5.7.1">
<h3><span class="header-section-number">5.7.1</span> Classification</h3>
<p><strong>Jak wyliczane jest prawdopodobieństwo w <em>sklearn</em></strong> :</p>
<p><a href="https://datascience.stackexchange.com/questions/27444/how-does-sklearn-kneighborsclassifier-compute-class-probabilites">link</a></p>
<p>The class probabilities are the normalized weighted average of
indicators for the k-nearest classes, weighted by the inverse distance.</p>
<p>For example: Say we have 6 classes, and the 5 nearest examples to our
test input have class labels ‘F,’ ‘B,’ ‘D,’ ‘A,’ and ‘B,’ with distances
2, 3, 4, 5, and 6, respectively.</p>
<p>Then the unnormalized class probabilities can by computed by:</p>
<pre><code>(1/2) * [0, 0, 0, 0, 0, 1] + (1/3) * [0, 1, 0, 0, 0, 0] + 
(1/4) * [0, 0, 0, 1, 0, 0] + (1/5) * [1, 0, 0, 0, 0, 0] + 
(1/6) * [0, 1, 0, 0, 0, 0] =

[1/5 ,1/2, 0, 1/4, 0, 1/2]</code></pre>
</div>
<div id="regression-3" class="section level3" number="5.7.2">
<h3><span class="header-section-number">5.7.2</span> Regression</h3>
</div>
</div>
<div id="log-linear-model" class="section level2" number="5.8">
<h2><span class="header-section-number">5.8</span> Log-linear model</h2>
</div>
<div id="similarity-learning" class="section level2" number="5.9">
<h2><span class="header-section-number">5.9</span> Similarity learning</h2>
</div>
<div id="survival-models" class="section level2" number="5.10">
<h2><span class="header-section-number">5.10</span> Survival models</h2>
<p><a href="https://www.theanalysisfactor.com/the-six-types-of-survival-analysis-and-challenges-in-learning-them/">modele typi
survival</a></p>
<table>
<tbody>
<tr class="odd">
<td></td>
</tr>
</tbody>
</table>
<p>+====================================================================+
+——————————————————————–+</p>
</div>
<div id="ensembled-models" class="section level2" number="5.11">
<h2><span class="header-section-number">5.11</span> Ensembled models</h2>
<div id="bagging-and-pasting-1" class="section level3" number="5.11.1">
<h3><span class="header-section-number">5.11.1</span> Bagging and Pasting</h3>
<div id="random-forest" class="section level4" number="5.11.1.1">
<h4><span class="header-section-number">5.11.1.1</span> Random Forest</h4>
<div id="out-of-bag-error" class="section level5" number="5.11.1.1.1">
<h5><span class="header-section-number">5.11.1.1.1</span> Out of Bag Error</h5>
</div>
</div>
</div>
<div id="boosting-1" class="section level3" number="5.11.2">
<h3><span class="header-section-number">5.11.2</span> Boosting</h3>
<div id="ada-boost" class="section level4" number="5.11.2.1">
<h4><span class="header-section-number">5.11.2.1</span> Ada Boost</h4>
<p>Adaptive boosting (adaptacyjne wzmacnianie).</p>
<p>Mam tutaj 2 rodzaje wag:</p>
<ol style="list-style-type: decimal">
<li><p>Wagi modeli. Im lepszy model tym będzie miał w finalnej klasyfikacji
większą wagę.
<span class="math inline">\(\alpha_t = \frac{1}{2}\ln(\frac{1-total.error}{totl.error})\)</span> .
Ponieważ funkcja nie ma wartości dla total_error równe 0 i 1
zazwyczaj dodaje się tutaj jakąś korektę dla zabezpieczenia. Total
error to suma błędów ważonych wagami obserwacji.</p></li>
<li><p>Wagi obserwacji. Obserwacje źle zaklasyfikowane przez i-ty model
mają większą wagę przy następnym modelu. Wagi mogę być używane do
losowania ważonego dla następnego modelu, albo do ważonego Ginii
index używanego do obliczania “impurity.” Wagi dla obserwacji źle
zaklasyfikowanych liczy się ze wzoru :
<span class="math inline">\(nowa.waga = stara.waga \cdot e^{waga.poprzedniego.modelu}\)</span>. Wagi
dla klasyfikacji dobrze zaklasyfikowanych liczy się ze wzoru:
<span class="math inline">\(nowa.waga = stara.waga \cdot e^{- waga.poprzedniego.modelu}\)</span> .</p>
<p>W tym wzorach można dodać współczynnik uczenia w wykładniku
liczby e. Patrz: <span class="citation">(<a href="appendicies.html#ref-Bonaccorso2019" role="doc-biblioref">Bonaccorso 2019</a>)</span> s 263.</p></li>
</ol>
<p>Ada boost:</p>
<ul>
<li><p>Zazwyczaj bazuje na drzewach. Jeżeli są to drzewa, to najczęściej
używa się <em>stumps</em> czyli drzew binarnych z tylko jednym podziałem.</p></li>
<li><p>występuje w m.in następujących wersjach:</p>
<ul>
<li><p>Bazowy AdaBoost do zagadnień binarnych.</p></li>
<li><p>M1 - podstawowy algorytm dla zagadnienia klasyfikacyjnego.
<span class="citation">(<a href="appendicies.html#ref-Raschka2019" role="doc-biblioref">Mirjalili 2019</a>)</span> s 234.</p></li>
<li><p>M2 - (porównanie z M1
<a href="https://www.programmersought.com/article/89144744462/">link</a>)</p></li>
<li><p>SUMME - jest uogólnieniem na zagadnienie wieloklasowego bez
używania podejścia jeden-przeciwko-wszystkim (One-vs-Rest).
Jeżeli robimy model binarny to podeście to redukuje się do
standardowego AdaBoost M1.</p></li>
<li><p>SUMME.R - (litera R od <em>real</em> - AdaBoost rzeczywisty)
rozwinięcie, gdzie wagi są liczone w oparciu o
prawdopodobieństwa. Pełny algorytm w <span class="citation">(<a href="#ref-Bonaccarso2019" role="doc-biblioref"><strong>Bonaccarso2019?</strong></a>)</span> s 268.</p></li>
<li><p>R2 - AdaBoost dla zagadnienia regresyjnego. Pełny algorytm w
<span class="citation">(<a href="#ref-Bonaccarso2019" role="doc-biblioref"><strong>Bonaccarso2019?</strong></a>)</span> s 271.</p></li>
</ul></li>
</ul>
<p><strong>SUMME</strong></p>
<p>W AdaBoost M1 dla przypadku binarnego, waga modelu w t-ej iteracji
zdefiniowana jako
<span class="math inline">\(\alpha_t = \frac{1}{2}\ln(\frac{1-total.error}{totl.error})\)</span> przyjmuje
wartość 0 jeżeli model jest losowy, czyli dostajemy 50% źle
zaklasyfikowanych elementów (jeżeli model zaklasyfikował poprawnie mniej
niż 50% to po prostu odwracamy jego predykcje i dostajemy model lepszy
od losowego). Jeżeli jednak mamy więcej klas to próg losowości musi być
inaczej zrobiony i zależny od ilości klas. Model gdzie jest 10
równolicznych klas i dobrze sklasyfikował 50% obserwacji jest dużo
lepszy od modelu losowego. Dlatego wzór na wagę modelu musi zostać
skorygowany.</p>
<p><strong>SUMMER.R</strong></p>
<p>Tutaj wagi modeli dla każdej iteracji są liczone w oparciu o
prawdopodobieństwa przynależności do klas. Każdy model ma inna wagą dla
każdej z klas. Nie jest tak jak w standardowym AdaBoost że jest jedna
waga dla modelu.</p>
<p>Wagi obserwacji też są liczone w oparciu o te prawdopodobieństwa. Przy
tych wagach uwzględniamy też faktyczne wartości empiryczne targetu.</p>
<p>Żeby policzyć wagę t-ego modelu dla k-tej klasy najpierw bierzemy
obserwacje w tej klasy (przynależność do klasy wynika z danych
empirycznych, a nie jest estymowana z modelu). Dla tych obserwacji
liczymy ŚREDNIE wyestymowane z modelu prawdopodobieństwo przynależenia
obserwacji do tej klasy. Przy uśrednianiu prawdopodobieństwa powinny
chyba powinny być używane wagi obserwacji.</p>
<p>Dla danej klasy jest tym większa waga modelu in wyższe jest
prawdopodobieństwo przynależenia tej klasy według modelu.</p>
<p>W modelu decyzja o klasyfikacji i-tej obserwacji jest podejmowana na
podstawie wyboru klasy dla której suma wago modelu po wszystkich
iteracjach jest największa (pamiętajmy że wagi modeli są per klasa).</p>
<p>Algorytm SUMME.R daje wyniki zbieżne do addytywnej regresji
logistycznej. Jest uważany za bardziej efektywny niż klasyczne wersja
AdaBoosta NIE oparta na prawdopodobieństwach.</p>
<p>AdaBoost w R od scratch-a:
<a href="https://rpubs.com/miguelpatricio/adaboost">link:rpubs</a></p>
<p><strong>Assumptions</strong></p>
<ul>
<li><p><strong>Quality Data</strong>: Because the ensemble method continues to attempt
to correct misclassifications in the training data, you need to be
careful that the training data is of a high-quality.</p></li>
<li><p><strong>Outliers</strong>: Outliers will force the ensemble down the rabbit hole
of working hard to correct for cases that are unrealistic. These
could be removed from the training dataset.</p></li>
<li><p><strong>Noisy Data</strong>: Noisy data, specifically noise in the output
variable can be problematic. If possible, attempt to isolate and
clean these from your training dataset.</p></li>
</ul>
<p><strong>Pros</strong></p>
<p><strong>Cons</strong></p>
<ul>
<li>Boosting technique learns progressively, it is important to ensure
that you have quality data. AdaBoost is also extremely sensitive to
Noisy data and outliers so if you do plan to use AdaBoost then it is
highly recommended to eliminate them.</li>
</ul>
<!-- -->
<ul>
<li>AdaBoost has also been proven to be slower than XGBoost.</li>
</ul>
</div>
<div id="lightgbm" class="section level4" number="5.11.2.2">
<h4><span class="header-section-number">5.11.2.2</span> LightGBM</h4>
<p><a href="https://towardsdatascience.com/what-makes-lightgbm-lightning-fast-a27cf0d9785e">link:tword_data_sience</a></p>
</div>
</div>
<div id="stacking-1" class="section level3" number="5.11.3">
<h3><span class="header-section-number">5.11.3</span> Stacking</h3>
</div>
<div id="twicing" class="section level3" number="5.11.4">
<h3><span class="header-section-number">5.11.4</span> Twicing</h3>
</div>
<div id="bandling" class="section level3" number="5.11.5">
<h3><span class="header-section-number">5.11.5</span> Bandling</h3>
</div>
</div>
<div id="neural-networks-2" class="section level2" number="5.12">
<h2><span class="header-section-number">5.12</span> Neural Networks</h2>
<div id="introduction-6" class="section level3" number="5.12.1">
<h3><span class="header-section-number">5.12.1</span> Introduction</h3>
</div>
<div id="basics-2" class="section level3" number="5.12.2">
<h3><span class="header-section-number">5.12.2</span> Basics</h3>
</div>
<div id="reccurent" class="section level3" number="5.12.3">
<h3><span class="header-section-number">5.12.3</span> Reccurent</h3>
<div id="simple-reccurent" class="section level4" number="5.12.3.1">
<h4><span class="header-section-number">5.12.3.1</span> Simple reccurent</h4>
</div>
<div id="bidirectorial" class="section level4" number="5.12.3.2">
<h4><span class="header-section-number">5.12.3.2</span> Bidirectorial</h4>
</div>
<div id="lstm" class="section level4" number="5.12.3.3">
<h4><span class="header-section-number">5.12.3.3</span> LSTM</h4>
</div>
<div id="gru" class="section level4" number="5.12.3.4">
<h4><span class="header-section-number">5.12.3.4</span> GRU</h4>
</div>
<div id="attention" class="section level4" number="5.12.3.5">
<h4><span class="header-section-number">5.12.3.5</span> Attention</h4>
</div>
</div>
<div id="cnn" class="section level3" number="5.12.4">
<h3><span class="header-section-number">5.12.4</span> CNN</h3>
</div>
<div id="resnet" class="section level3" number="5.12.5">
<h3><span class="header-section-number">5.12.5</span> Resnet</h3>
</div>
</div>
<div id="stochastic-processes-1" class="section level2" number="5.13">
<h2><span class="header-section-number">5.13</span> Stochastic processes</h2>
<div id="basic-trend-models" class="section level3" number="5.13.1">
<h3><span class="header-section-number">5.13.1</span> Basic trend models</h3>
</div>
<div id="basic-adaptative-models" class="section level3" number="5.13.2">
<h3><span class="header-section-number">5.13.2</span> Basic adaptative models</h3>
</div>
<div id="econometric-time-series-models" class="section level3" number="5.13.3">
<h3><span class="header-section-number">5.13.3</span> Econometric time series models</h3>
<div id="dynamic-for-example-error-correction-models" class="section level4" number="5.13.3.1">
<h4><span class="header-section-number">5.13.3.1</span> dynamic (for example error correction models)</h4>
</div>
<div id="sarimax" class="section level4" number="5.13.3.2">
<h4><span class="header-section-number">5.13.3.2</span> SARIMAX</h4>
</div>
<div id="varimax" class="section level4" number="5.13.3.3">
<h4><span class="header-section-number">5.13.3.3</span> VARIMAX</h4>
</div>
<div id="arch-class-models" class="section level4" number="5.13.3.4">
<h4><span class="header-section-number">5.13.3.4</span> ARCH class models</h4>
</div>
<div id="cointegration-including-arld-approach" class="section level4" number="5.13.3.5">
<h4><span class="header-section-number">5.13.3.5</span> Cointegration (including ARLD approach)</h4>
</div>
</div>
<div id="time-series-decomposition-decomposition" class="section level3" number="5.13.4">
<h3><span class="header-section-number">5.13.4</span> Time series decomposition decomposition</h3>
</div>
<div id="kalman-filters" class="section level3" number="5.13.5">
<h3><span class="header-section-number">5.13.5</span> Kalman filters</h3>
</div>
<div id="neural-networks-3" class="section level3" number="5.13.6">
<h3><span class="header-section-number">5.13.6</span> Neural Networks</h3>
<div id="long-short-term-memory" class="section level4" number="5.13.6.1">
<h4><span class="header-section-number">5.13.6.1</span> Long short term memory</h4>
</div>
<div id="cnn-1" class="section level4" number="5.13.6.2">
<h4><span class="header-section-number">5.13.6.2</span> CNN</h4>
</div>
</div>
<div id="panel-regression" class="section level3" number="5.13.7">
<h3><span class="header-section-number">5.13.7</span> Panel Regression</h3>
</div>
<div id="gaussian-mixtures" class="section level3" number="5.13.8">
<h3><span class="header-section-number">5.13.8</span> Gaussian Mixtures</h3>
</div>
<div id="ensembled-models-1" class="section level3" number="5.13.9">
<h3><span class="header-section-number">5.13.9</span> Ensembled models</h3>
</div>
<div id="martingales" class="section level3" number="5.13.10">
<h3><span class="header-section-number">5.13.10</span> Martingales</h3>
</div>
<div id="markov-process" class="section level3" number="5.13.11">
<h3><span class="header-section-number">5.13.11</span> Markov Process</h3>
</div>
<div id="winer-process" class="section level3" number="5.13.12">
<h3><span class="header-section-number">5.13.12</span> Winer Process</h3>
</div>
</div>
<div id="results-diagnostics-5" class="section level2" number="5.14">
<h2><span class="header-section-number">5.14</span> Results diagnostics</h2>
<div id="classification-4" class="section level3" number="5.14.1">
<h3><span class="header-section-number">5.14.1</span> Classification</h3>
<div id="scores-calibration" class="section level4" number="5.14.1.1">
<h4><span class="header-section-number">5.14.1.1</span> Scores calibration</h4>
<div id="problem" class="section level5" number="5.14.1.1.1">
<h5><span class="header-section-number">5.14.1.1.1</span> Problem</h5>
<p>Kalibracja dotyczy</p>
<ul>
<li>prawdopodobieństwa które nie odpowiadaj poziomom ufnosci</li>
<li>miara (scores) z modeli które nia sa prawdopodobieństwami (SVM
zwraca score jako odleglosc obserwacji o hiperplaszczyzny
separujacej, a w K-NN mozemy budowac miary oparte o odleglosci
miedzy obserwacjami - wiecej w k-NN dla klasyfikacji) ale chcemy,
aby te scory byly przerobione na prawdopodobienstwa</li>
<li>nie wiem co z przypadkiem kiedy mamy same ‘labels’ z modelu i czy
można je przeksztaca na prawdopodobieństwo. Jednak takie modele sa
rzadkoscia: Nearly every classifier - ogistic regression, a neural
net, a decision tree, a k-NN classifier, a support vector machine,
etc. — can produce a score instead of (or in addition to) a class
label.1</li>
</ul>
</div>
<div id="kalibracja-a-problemy-konkretnych-modeli" class="section level5" number="5.14.1.1.2">
<h5><span class="header-section-number">5.14.1.1.2</span> Kalibracja a problemy konkretnych modeli</h5>
<p><strong>Random Forest</strong>: RandomForestClassifier shows the opposite behavior:
the histograms <strong>show peaks at approximately 0.2 and 0.9 probability,
while probabilities close to 0 or 1 are very rare</strong>. An explanation for
this is given by Niculescu-Mizil and Caruana 1: “Methods such as bagging
and random forests that average predictions from a base set of models
can have difficulty making predictions near 0 and 1 because variance in
the underlying base models will bias predictions that should be near
zero or one away from these values. Because predictions are restricted
to the interval [0,1], errors caused by variance tend to be one-sided
near zero and one. For example, if a model should predict p = 0 for a
case, the only way bagging can achieve this is if all bagged trees
predict zero. If we add noise to the trees that bagging is averaging
over, this noise will cause some trees to predict values larger than 0
for this case, thus moving the average prediction of the bagged ensemble
away from 0. We observe this effect most strongly with random forests
because the base-level trees trained with random forests have relatively
high variance due to feature subsetting.” As a result, the calibration
curve also referred to as the reliability diagram (Wilks 1995 2) shows a
characteristic sigmoid shape, indicating that the classifier could trust
its “intuition” more and return probabilities closer to 0 or 1
typically.</p>
<p><strong>LogisticRegression</strong>: Returns well calibrated predictions by default
as it directly optimizes Log loss. In contrast, the other methods return
biased probabilities; with different biases per method:</p>
<p><strong>GaussianNB</strong>: Tends to push probabilities to 0 or 1 (note the counts
in the histograms). This is mainly because it makes the assumption that
features are conditionally independent given the class, which is not the
case in this dataset which contains 2 redundant features.</p>
<p><strong>Linear Support Vector Classification (LinearSVC)</strong>: shows an even more
sigmoid curve than RandomForestClassifier, which is typical for
maximum-margin methods (compare Niculescu-Mizil and Caruana 1), which
focus on difficult to classify samples that are close to the decision
boundary (the support vectors).</p>
</div>
<div id="calibration-curve-reliability-diagram" class="section level5" number="5.14.1.1.3">
<h5><span class="header-section-number">5.14.1.1.3</span> Calibration curve (reliability diagram)</h5>
<p><a href="https://journals.ametsoc.org/view/journals/wefo/22/3/waf993_1.xml">how to make
it</a></p>
<p>First, the forecast values are partitioned into bins Bk, k = 1, . . . ,
K (which form a partition of the unit interval into nonoverlapping
exhaustive subintervals). The Bk are often taken to be of equal width,
but if the distribution of the forecast values is nonuniform, then
choosing the bins so that they are equally populated is an attractive
alternative.</p>
<p>Next, for each i, it is established which of the K bins the forecast
value Xi falls into. For each bin Bk, let Ik be the collection of all
indices i for which Xi falls into bin Bk; that is,</p>
<p><span class="math inline">\(I_k:=\{i;X_i \in B_k\}\)</span></p>
<p>The corresponding observed relative frequency fk is the number of times
the event happens, given that Xi ∈ Bk, divided by the total number of
forecast values Xi ∈ Bk. This can be expressed as:</p>
<p><span class="math inline">\(f_k=\frac{\sum_{i \in I_k}^{}{Y_i}}{\#I_k}\)</span></p>
<p>where #Ik denotes the number of elements in Ik. Each bin Bk is
represented by a single “typical” forecast probability rk. Although the
arithmetic center of the bin is often used to represent the forecast
values in that bin, this method has a clear disadvantage: If the
forecast is reliable, the observed relative frequency for a given bin Bk
is expected to coincide with the average of the forecast values over
that bin Bk, rather than with the arithmetic center of the bin. Plotting
the observed relative frequency over the arithmetic center can cause
even a perfect reliability diagram to be off the diagonal by up to half
the width of a bin. In this paper, observed relative frequencies for a
bin Bk are plotted versus the average of the forecast values over bin
Bk. This average, denoted by rk, is:</p>
<p><span class="math inline">\(r_k:=\frac{\sum_{i \in I_k}{X_i}}{\#I_k}\)</span></p>
<p>The reliability diagram comprises a plot of <span class="math inline">\(f_k\)</span> versus rk for all bins
<span class="math inline">\(B_k\)</span>.</p>
</div>
<div id="skalowanie-platta" class="section level5" number="5.14.1.1.4">
<h5><span class="header-section-number">5.14.1.1.4</span> Skalowanie Platta</h5>
<p><a href="https://medium.com/@nupur94/calibration-of-models-45721a221da6">link</a></p>
<p><strong>Steps</strong> for applying Platt scaling</p>
<ol style="list-style-type: decimal">
<li>Split the data set into train and test data set.</li>
<li>Train the model on the training data set.</li>
<li>Apply SGD (stochstic gradient descent) Classifier to minimize hinge
loss.</li>
<li>Apply Calibrated Classifier from sklearn and take SGD classifier as
a base estimator.</li>
<li>Sort the predicted probability scores in ascending order.</li>
<li>Divide the sorted probability and actual y into multiple bins. Here,
we are taking bin size as 50.</li>
<li>Take the average of actual ‘y’ and predicted probabilities for each
bins.</li>
<li>Plot average of actual y on y-axis and average of predicted
probability on x-axis.</li>
</ol>
<p>Pros: Works well with a small dataset</p>
<p>Cons: Could produce worse probabilities calibration wise if the
assumptions do not hold</p>
<p><strong>Skalowanie dla zagadnienia multiklasowego</strong></p>
<p><a href="https://datascience.stackexchange.com/questions/45924/platts-scaling-for-multi-label-classification">platts-scaling-for-multi-label-classification</a></p>
<p>There are a few multiclass variants of Platt scaling. The easiest
approach is as you have described; simply perform one Platt scaling on
each class.</p>
<p>However, there are more sophisticated options–a very simple one to
implement is training a standard logistic regression on the logits (the
values before the softmax activation is applied). This has called matrix
scaling and can overfit pretty easily, so only use this if you have a
large calibration set. Alternatively, a fewer-parameter version called
vector scaling is relatively simple to implement, where the weights
matrix inside the logistic regression is restricted to be a diagonal
matrix. Finally, a very simple option that has been shown to work well
for neural networks is temperature scaling, where all logits are simply
scaled by a single scalar parameter.</p>
<p>You can read more about these and their application to neural networks
in Section 4.2 of “On Calibration of Modern Neural Networks” (2017) -
available <a href="https://arxiv.org/pdf/1706.04599.pdf">here</a></p>
</div>
<div id="regresja-izotoniczna" class="section level5" number="5.14.1.1.5">
<h5><span class="header-section-number">5.14.1.1.5</span> Regresja izotoniczna</h5>
<p><a href="https://medium.com/@nupur94/calibration-of-models-45721a221da6">link</a></p>
<p>Pros:</p>
<p>Makes no assumption about the input probabilities. A benefit of isotonic
regression is that it is not constrained by any functional form, such as
the linearity imposed by linear regression, as long as the function is
monotonic increasing.</p>
<p>Cons: Requires more data points to work well</p>
</div>
<div id="calibration-in-sklearn" class="section level5" number="5.14.1.1.6">
<h5><span class="header-section-number">5.14.1.1.6</span> Calibration in <em>sklearn</em></h5>
<p>There are 2 ways of using the sklearn <code>CalibratedClassifierCV</code> class :</p>
<ul>
<li><p>Pass a fitted model and thereby setting cv to prefit. It is
important to note that the data used in fitting the base estimator
and the calibrator is disjoint.</p></li>
<li><p>Fit a base estimator using k-fold cross-validation and the
probabilities for each of the folds are then averaged for
prediction.</p></li>
</ul>
</div>
</div>
</div>
<div id="regression-4" class="section level3" number="5.14.2">
<h3><span class="header-section-number">5.14.2</span> Regression</h3>
</div>
</div>
<div id="elements-selection-5" class="section level2" number="5.15">
<h2><span class="header-section-number">5.15</span> Elements selection</h2>
<div id="feature-selection" class="section level3" number="5.15.1">
<h3><span class="header-section-number">5.15.1</span> Feature selection</h3>
<div id="feature-importance" class="section level5" number="5.15.1.0.1">
<h5><span class="header-section-number">5.15.1.0.1</span> Feature Importance</h5>
<p><strong>MDI</strong></p>
<p><strong>MDA</strong></p>
<p>Mean Decrease Accuracy, MDA, also known as permutation importance.</p>
<p>The approach can be described in the following steps:</p>
<p>1. Train the baseline model and record the score (accuracy/R²/any
metric of importance) by passing the validation set (or OOB set in case
of Random Forest). This can also be done on the training set, at the
cost of sacrificing information about generalization.</p>
<p>2. Re-shuffle values from one feature in the selected dataset, pass the
dataset to the model again to obtain predictions and calculate the
metric for this modified dataset. The feature importance is the
difference between the benchmark score and the one from the modified
(permuted) dataset.</p>
</div>
</div>
<div id="variables-exogenity" class="section level3" number="5.15.2">
<h3><span class="header-section-number">5.15.2</span> Variables exogenity</h3>
<div id="granger-exogenity" class="section level4" number="5.15.2.1">
<h4><span class="header-section-number">5.15.2.1</span> Granger Exogenity</h4>
</div>
</div>
</div>
<div id="iml-5" class="section level2" number="5.16">
<h2><span class="header-section-number">5.16</span> IML</h2>
</div>
<div id="by-problems-6" class="section level2" number="5.17">
<h2><span class="header-section-number">5.17</span> By problems</h2>
<div id="numerical" class="section level3" number="5.17.1">
<h3><span class="header-section-number">5.17.1</span> Numerical</h3>
</div>
<div id="categorical" class="section level3" number="5.17.2">
<h3><span class="header-section-number">5.17.2</span> Categorical</h3>
</div>
<div id="text" class="section level3" number="5.17.3">
<h3><span class="header-section-number">5.17.3</span> Text</h3>
</div>
<div id="sound-1" class="section level3" number="5.17.4">
<h3><span class="header-section-number">5.17.4</span> Sound</h3>
</div>
<div id="vision-1" class="section level3" number="5.17.5">
<h3><span class="header-section-number">5.17.5</span> Vision</h3>

</div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="learning-patterns-discovering.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="learning-hybrid.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/rstudio/bookdown-demo/edit/master/03_TARGET.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["bookdown-demo.pdf", "bookdown-demo.epub"],
"toc": {
"collapse": "section"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
