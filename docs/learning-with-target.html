<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 5 LEARNING: WITH TARGET | Data Science Book</title>
  <meta name="description" content="Chapter 5 LEARNING: WITH TARGET | Data Science Book" />
  <meta name="generator" content="bookdown 0.21 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 5 LEARNING: WITH TARGET | Data Science Book" />
  <meta property="og:type" content="book" />
  
  
  
  <meta name="github-repo" content="rstudio/bookdown-demo" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 5 LEARNING: WITH TARGET | Data Science Book" />
  
  
  

<meta name="author" content="Łukasz Muszyński" />


<meta name="date" content="2023-04-03" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="learning-patterns-discovering.html"/>
<link rel="next" href="learning-hybrid.html"/>
<script src="libs/header-attrs-2.5/header-attrs.js"></script>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<link href="libs/anchor-sections-1.0/anchor-sections.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.0/anchor-sections.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">A Minimal Book Example</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> INTRO</a></li>
<li class="chapter" data-level="2" data-path="introduction.html"><a href="introduction.html"><i class="fa fa-check"></i><b>2</b> INTRODUCTION</a>
<ul>
<li class="chapter" data-level="2.1" data-path="introduction.html"><a href="introduction.html#to-do"><i class="fa fa-check"></i><b>2.1</b> TO DO</a></li>
<li class="chapter" data-level="2.2" data-path="introduction.html"><a href="introduction.html#draft"><i class="fa fa-check"></i><b>2.2</b> draft</a></li>
<li class="chapter" data-level="2.3" data-path="introduction.html"><a href="introduction.html#introduction-1"><i class="fa fa-check"></i><b>2.3</b> Introduction</a></li>
<li class="chapter" data-level="2.4" data-path="introduction.html"><a href="introduction.html#ai-problems-and-algorithms-classification"><i class="fa fa-check"></i><b>2.4</b> AI problems and algorithms classification</a></li>
<li class="chapter" data-level="2.5" data-path="introduction.html"><a href="introduction.html#meta-issues"><i class="fa fa-check"></i><b>2.5</b> Meta issues</a>
<ul>
<li class="chapter" data-level="2.5.1" data-path="introduction.html"><a href="introduction.html#knowledge-representation"><i class="fa fa-check"></i><b>2.5.1</b> Knowledge representation</a></li>
<li class="chapter" data-level="2.5.2" data-path="introduction.html"><a href="introduction.html#types-of-learning"><i class="fa fa-check"></i><b>2.5.2</b> Types of learning</a>
<ul>
<li class="chapter" data-level="2.5.2.1" data-path="introduction.html"><a href="introduction.html#ensemble-zespołowe"><i class="fa fa-check"></i><b>2.5.2.1</b> Ensemble (zespołowe)</a>
<ul>
<li class="chapter" data-level="2.5.2.1.1" data-path="introduction.html"><a href="introduction.html#bagging-and-pasting"><i class="fa fa-check"></i><b>2.5.2.1.1</b> Bagging and Pasting</a></li>
<li class="chapter" data-level="2.5.2.1.2" data-path="introduction.html"><a href="introduction.html#boosting"><i class="fa fa-check"></i><b>2.5.2.1.2</b> Boosting</a></li>
<li class="chapter" data-level="2.5.2.1.3" data-path="introduction.html"><a href="introduction.html#stacking"><i class="fa fa-check"></i><b>2.5.2.1.3</b> Stacking</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="2.5.3" data-path="introduction.html"><a href="introduction.html#model-complexity"><i class="fa fa-check"></i><b>2.5.3</b> Model complexity</a></li>
<li class="chapter" data-level="2.5.4" data-path="introduction.html"><a href="introduction.html#overfittng-underfitting"><i class="fa fa-check"></i><b>2.5.4</b> Overfittng / underfitting</a></li>
<li class="chapter" data-level="2.5.5" data-path="introduction.html"><a href="introduction.html#bias-variance-trade-off"><i class="fa fa-check"></i><b>2.5.5</b> Bias / Variance trade off</a></li>
<li class="chapter" data-level="2.5.6" data-path="introduction.html"><a href="introduction.html#curse-of-dimentionality"><i class="fa fa-check"></i><b>2.5.6</b> Curse of dimentionality</a></li>
<li class="chapter" data-level="2.5.7" data-path="introduction.html"><a href="introduction.html#sparious-phenomenon"><i class="fa fa-check"></i><b>2.5.7</b> Sparious phenomenon</a></li>
</ul></li>
<li class="chapter" data-level="2.6" data-path="introduction.html"><a href="introduction.html#rozne-podzialy-algorytmow"><i class="fa fa-check"></i><b>2.6</b> Rozne podzialy algorytmow</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="auxiliary-fields.html"><a href="auxiliary-fields.html"><i class="fa fa-check"></i><b>3</b> AUXILIARY FIELDS</a>
<ul>
<li class="chapter" data-level="3.1" data-path="auxiliary-fields.html"><a href="auxiliary-fields.html#introduction-2"><i class="fa fa-check"></i><b>3.1</b> Introduction</a></li>
<li class="chapter" data-level="3.2" data-path="auxiliary-fields.html"><a href="auxiliary-fields.html#philosophy"><i class="fa fa-check"></i><b>3.2</b> Philosophy</a></li>
<li class="chapter" data-level="3.3" data-path="auxiliary-fields.html"><a href="auxiliary-fields.html#logic"><i class="fa fa-check"></i><b>3.3</b> Logic</a></li>
<li class="chapter" data-level="3.4" data-path="auxiliary-fields.html"><a href="auxiliary-fields.html#psychology"><i class="fa fa-check"></i><b>3.4</b> Psychology</a></li>
<li class="chapter" data-level="3.5" data-path="auxiliary-fields.html"><a href="auxiliary-fields.html#linguistics"><i class="fa fa-check"></i><b>3.5</b> Linguistics</a></li>
<li class="chapter" data-level="3.6" data-path="auxiliary-fields.html"><a href="auxiliary-fields.html#cybernetics-control-theory"><i class="fa fa-check"></i><b>3.6</b> Cybernetics (control theory)</a></li>
<li class="chapter" data-level="3.7" data-path="auxiliary-fields.html"><a href="auxiliary-fields.html#math_1-probability"><i class="fa fa-check"></i><b>3.7</b> Math_1 – Probability</a>
<ul>
<li class="chapter" data-level="3.7.1" data-path="auxiliary-fields.html"><a href="auxiliary-fields.html#basics"><i class="fa fa-check"></i><b>3.7.1</b> Basics</a></li>
<li class="chapter" data-level="3.7.2" data-path="auxiliary-fields.html"><a href="auxiliary-fields.html#univariate-distributions"><i class="fa fa-check"></i><b>3.7.2</b> Univariate distributions</a></li>
<li class="chapter" data-level="3.7.3" data-path="auxiliary-fields.html"><a href="auxiliary-fields.html#multivariate-distributions"><i class="fa fa-check"></i><b>3.7.3</b> Multivariate distributions</a></li>
<li class="chapter" data-level="3.7.4" data-path="auxiliary-fields.html"><a href="auxiliary-fields.html#stochastic-processes"><i class="fa fa-check"></i><b>3.7.4</b> Stochastic processes</a></li>
</ul></li>
<li class="chapter" data-level="3.8" data-path="auxiliary-fields.html"><a href="auxiliary-fields.html#math_2-statistics"><i class="fa fa-check"></i><b>3.8</b> Math_2 – Statistics</a>
<ul>
<li class="chapter" data-level="3.8.1" data-path="auxiliary-fields.html"><a href="auxiliary-fields.html#descriptive-statistics"><i class="fa fa-check"></i><b>3.8.1</b> Descriptive statistics</a>
<ul>
<li class="chapter" data-level="3.8.1.1" data-path="auxiliary-fields.html"><a href="auxiliary-fields.html#univariate"><i class="fa fa-check"></i><b>3.8.1.1</b> Univariate</a></li>
<li class="chapter" data-level="3.8.1.2" data-path="auxiliary-fields.html"><a href="auxiliary-fields.html#multivariate"><i class="fa fa-check"></i><b>3.8.1.2</b> Multivariate</a>
<ul>
<li class="chapter" data-level="3.8.1.2.1" data-path="auxiliary-fields.html"><a href="auxiliary-fields.html#correlation"><i class="fa fa-check"></i><b>3.8.1.2.1</b> Correlation</a></li>
<li class="chapter" data-level="3.8.1.2.2" data-path="auxiliary-fields.html"><a href="auxiliary-fields.html#autocerrelation"><i class="fa fa-check"></i><b>3.8.1.2.2</b> Autocerrelation</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3.8.2" data-path="auxiliary-fields.html"><a href="auxiliary-fields.html#statistical-and-ecometrical-inference"><i class="fa fa-check"></i><b>3.8.2</b> Statistical and ecometrical inference</a>
<ul>
<li class="chapter" data-level="3.8.2.1" data-path="auxiliary-fields.html"><a href="auxiliary-fields.html#basics-1"><i class="fa fa-check"></i><b>3.8.2.1</b> Basics</a></li>
<li class="chapter" data-level="3.8.2.2" data-path="auxiliary-fields.html"><a href="auxiliary-fields.html#pameters-estimation-algorithms"><i class="fa fa-check"></i><b>3.8.2.2</b> Pameters estimation algorithms</a>
<ul>
<li class="chapter" data-level="3.8.2.2.1" data-path="auxiliary-fields.html"><a href="auxiliary-fields.html#general-moments-methods"><i class="fa fa-check"></i><b>3.8.2.2.1</b> General moments methods</a></li>
<li class="chapter" data-level="3.8.2.2.2" data-path="auxiliary-fields.html"><a href="auxiliary-fields.html#maxium-likehood"><i class="fa fa-check"></i><b>3.8.2.2.2</b> Maxium likehood</a></li>
<li class="chapter" data-level="3.8.2.2.3" data-path="auxiliary-fields.html"><a href="auxiliary-fields.html#nonparametric-techniques"><i class="fa fa-check"></i><b>3.8.2.2.3</b> Nonparametric techniques</a></li>
</ul></li>
<li class="chapter" data-level="3.8.2.3" data-path="auxiliary-fields.html"><a href="auxiliary-fields.html#sampling-techniques"><i class="fa fa-check"></i><b>3.8.2.3</b> Sampling techniques</a>
<ul>
<li class="chapter" data-level="3.8.2.3.1" data-path="auxiliary-fields.html"><a href="auxiliary-fields.html#holdout"><i class="fa fa-check"></i><b>3.8.2.3.1</b> Holdout</a></li>
<li class="chapter" data-level="3.8.2.3.2" data-path="auxiliary-fields.html"><a href="auxiliary-fields.html#boostrap"><i class="fa fa-check"></i><b>3.8.2.3.2</b> Boostrap</a></li>
<li class="chapter" data-level="3.8.2.3.3" data-path="auxiliary-fields.html"><a href="auxiliary-fields.html#jacknife"><i class="fa fa-check"></i><b>3.8.2.3.3</b> Jacknife</a></li>
<li class="chapter" data-level="3.8.2.3.4" data-path="auxiliary-fields.html"><a href="auxiliary-fields.html#permutation"><i class="fa fa-check"></i><b>3.8.2.3.4</b> Permutation</a></li>
<li class="chapter" data-level="3.8.2.3.5" data-path="auxiliary-fields.html"><a href="auxiliary-fields.html#cross-validation"><i class="fa fa-check"></i><b>3.8.2.3.5</b> Cross validation</a></li>
<li class="chapter" data-level="3.8.2.3.6" data-path="auxiliary-fields.html"><a href="auxiliary-fields.html#monte-carlo"><i class="fa fa-check"></i><b>3.8.2.3.6</b> Monte Carlo</a></li>
<li class="chapter" data-level="3.8.2.3.7" data-path="auxiliary-fields.html"><a href="auxiliary-fields.html#stratified-sampling"><i class="fa fa-check"></i><b>3.8.2.3.7</b> Stratified sampling</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3.8.3" data-path="auxiliary-fields.html"><a href="auxiliary-fields.html#other-issues"><i class="fa fa-check"></i><b>3.8.3</b> Other issues</a>
<ul>
<li class="chapter" data-level="3.8.3.1" data-path="auxiliary-fields.html"><a href="auxiliary-fields.html#similarity-and-dissimilarity-meassures-for-observations"><i class="fa fa-check"></i><b>3.8.3.1</b> Similarity and dissimilarity meassures for observations</a></li>
<li class="chapter" data-level="3.8.3.2" data-path="auxiliary-fields.html"><a href="auxiliary-fields.html#similarity-and-dissimilarity-meassures-for-distributions"><i class="fa fa-check"></i><b>3.8.3.2</b> Similarity and dissimilarity meassures for distributions</a></li>
<li class="chapter" data-level="3.8.3.3" data-path="auxiliary-fields.html"><a href="auxiliary-fields.html#measures-of-disorderrandomness"><i class="fa fa-check"></i><b>3.8.3.3</b> Measures of disorder/randomness</a></li>
<li class="chapter" data-level="3.8.3.4" data-path="auxiliary-fields.html"><a href="auxiliary-fields.html#conformal-prediction"><i class="fa fa-check"></i><b>3.8.3.4</b> Conformal prediction</a>
<ul>
<li class="chapter" data-level="3.8.3.4.1" data-path="auxiliary-fields.html"><a href="auxiliary-fields.html#przykład-knn-dla-random-forest-klasyfikacja-i-regresja"><i class="fa fa-check"></i><b>3.8.3.4.1</b> Przykład knn dla random forest (klasyfikacja i regresja)</a></li>
<li class="chapter" data-level="3.8.3.4.2" data-path="auxiliary-fields.html"><a href="auxiliary-fields.html#przykład-dla-knn-dla-klasyfikacji-link"><i class="fa fa-check"></i><b>3.8.3.4.2</b> Przykład dla knn dla klasyfikacji (<span>link</span>)</a></li>
</ul></li>
<li class="chapter" data-level="3.8.3.5" data-path="auxiliary-fields.html"><a href="auxiliary-fields.html#paradoxes"><i class="fa fa-check"></i><b>3.8.3.5</b> Paradoxes</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3.9" data-path="auxiliary-fields.html"><a href="auxiliary-fields.html#math_3---deep-learning"><i class="fa fa-check"></i><b>3.9</b> Math_3 - Deep Learning</a>
<ul>
<li class="chapter" data-level="3.9.1" data-path="auxiliary-fields.html"><a href="auxiliary-fields.html#różne-uwagi"><i class="fa fa-check"></i><b>3.9.1</b> Różne uwagi</a>
<ul>
<li class="chapter" data-level="3.9.1.1" data-path="auxiliary-fields.html"><a href="auxiliary-fields.html#ogólnie-o-sieciach"><i class="fa fa-check"></i><b>3.9.1.1</b> Ogólnie o sieciach</a></li>
<li class="chapter" data-level="3.9.1.2" data-path="auxiliary-fields.html"><a href="auxiliary-fields.html#funkcje-aktywacyjne"><i class="fa fa-check"></i><b>3.9.1.2</b> Funkcje aktywacyjne</a></li>
<li class="chapter" data-level="3.9.1.3" data-path="auxiliary-fields.html"><a href="auxiliary-fields.html#rnn"><i class="fa fa-check"></i><b>3.9.1.3</b> RNN</a></li>
<li class="chapter" data-level="3.9.1.4" data-path="auxiliary-fields.html"><a href="auxiliary-fields.html#cnn-dwuwymiarowe"><i class="fa fa-check"></i><b>3.9.1.4</b> CNN dwuwymiarowe:</a>
<ul>
<li class="chapter" data-level="3.9.1.4.1" data-path="auxiliary-fields.html"><a href="auxiliary-fields.html#r-cnn-region-cnn"><i class="fa fa-check"></i><b>3.9.1.4.1</b> R-CNN (Region-CNN)</a></li>
<li class="chapter" data-level="3.9.1.4.2" data-path="auxiliary-fields.html"><a href="auxiliary-fields.html#fast-r-cnn"><i class="fa fa-check"></i><b>3.9.1.4.2</b> Fast R-CNN</a></li>
<li class="chapter" data-level="3.9.1.4.3" data-path="auxiliary-fields.html"><a href="auxiliary-fields.html#fast-er-r-cnn"><i class="fa fa-check"></i><b>3.9.1.4.3</b> Fast-er R-CNN</a></li>
<li class="chapter" data-level="3.9.1.4.4" data-path="auxiliary-fields.html"><a href="auxiliary-fields.html#yolo"><i class="fa fa-check"></i><b>3.9.1.4.4</b> Yolo</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3.9.2" data-path="auxiliary-fields.html"><a href="auxiliary-fields.html#embedding"><i class="fa fa-check"></i><b>3.9.2</b> Embedding</a></li>
</ul></li>
<li class="chapter" data-level="3.10" data-path="auxiliary-fields.html"><a href="auxiliary-fields.html#math_4-game-theory"><i class="fa fa-check"></i><b>3.10</b> Math_4 – Game theory</a></li>
<li class="chapter" data-level="3.11" data-path="auxiliary-fields.html"><a href="auxiliary-fields.html#math_5-optimisation"><i class="fa fa-check"></i><b>3.11</b> Math_5 – Optimisation</a>
<ul>
<li class="chapter" data-level="3.11.1" data-path="auxiliary-fields.html"><a href="auxiliary-fields.html#functions-optimum"><i class="fa fa-check"></i><b>3.11.1</b> Functions optimum</a></li>
<li class="chapter" data-level="3.11.2" data-path="auxiliary-fields.html"><a href="auxiliary-fields.html#functions-optimum-constrained"><i class="fa fa-check"></i><b>3.11.2</b> Functions optimum – constrained</a>
<ul>
<li class="chapter" data-level="3.11.2.1" data-path="auxiliary-fields.html"><a href="auxiliary-fields.html#lagrange-multipliers"><i class="fa fa-check"></i><b>3.11.2.1</b> Lagrange Multipliers</a></li>
<li class="chapter" data-level="3.11.2.2" data-path="auxiliary-fields.html"><a href="auxiliary-fields.html#linear-programming"><i class="fa fa-check"></i><b>3.11.2.2</b> Linear programming</a></li>
<li class="chapter" data-level="3.11.2.3" data-path="auxiliary-fields.html"><a href="auxiliary-fields.html#nonlinear-programming"><i class="fa fa-check"></i><b>3.11.2.3</b> Nonlinear programming</a></li>
<li class="chapter" data-level="3.11.2.4" data-path="auxiliary-fields.html"><a href="auxiliary-fields.html#regularization"><i class="fa fa-check"></i><b>3.11.2.4</b> Regularization</a></li>
</ul></li>
<li class="chapter" data-level="3.11.3" data-path="auxiliary-fields.html"><a href="auxiliary-fields.html#functional-optimum"><i class="fa fa-check"></i><b>3.11.3</b> Functional optimum</a>
<ul>
<li class="chapter" data-level="3.11.3.1" data-path="auxiliary-fields.html"><a href="auxiliary-fields.html#dynamic-programming"><i class="fa fa-check"></i><b>3.11.3.1</b> Dynamic programming</a></li>
<li class="chapter" data-level="3.11.3.2" data-path="auxiliary-fields.html"><a href="auxiliary-fields.html#calculus-of-variations"><i class="fa fa-check"></i><b>3.11.3.2</b> Calculus of variations</a></li>
</ul></li>
<li class="chapter" data-level="3.11.4" data-path="auxiliary-fields.html"><a href="auxiliary-fields.html#cost-functions"><i class="fa fa-check"></i><b>3.11.4</b> Cost functions</a></li>
<li class="chapter" data-level="3.11.5" data-path="auxiliary-fields.html"><a href="auxiliary-fields.html#back-propagation"><i class="fa fa-check"></i><b>3.11.5</b> Back propagation</a></li>
<li class="chapter" data-level="3.11.6" data-path="auxiliary-fields.html"><a href="auxiliary-fields.html#heuristic-algorithms"><i class="fa fa-check"></i><b>3.11.6</b> Heuristic algorithms</a>
<ul>
<li class="chapter" data-level="3.11.6.1" data-path="auxiliary-fields.html"><a href="auxiliary-fields.html#swarm-algorithm"><i class="fa fa-check"></i><b>3.11.6.1</b> Swarm algorithm</a></li>
<li class="chapter" data-level="3.11.6.2" data-path="auxiliary-fields.html"><a href="auxiliary-fields.html#ants-algorithm"><i class="fa fa-check"></i><b>3.11.6.2</b> Ants algorithm</a></li>
<li class="chapter" data-level="3.11.6.3" data-path="auxiliary-fields.html"><a href="auxiliary-fields.html#genetics-algorithms"><i class="fa fa-check"></i><b>3.11.6.3</b> Genetics algorithms</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3.12" data-path="auxiliary-fields.html"><a href="auxiliary-fields.html#math_5-other-issues"><i class="fa fa-check"></i><b>3.12</b> Math_5 – Other issues</a>
<ul>
<li class="chapter" data-level="3.12.1" data-path="auxiliary-fields.html"><a href="auxiliary-fields.html#functions-usefull-in-data-science"><i class="fa fa-check"></i><b>3.12.1</b> Functions usefull in Data Science</a></li>
<li class="chapter" data-level="3.12.2" data-path="auxiliary-fields.html"><a href="auxiliary-fields.html#useful-tricks"><i class="fa fa-check"></i><b>3.12.2</b> Useful tricks</a></li>
<li class="chapter" data-level="3.12.3" data-path="auxiliary-fields.html"><a href="auxiliary-fields.html#linear-algebra"><i class="fa fa-check"></i><b>3.12.3</b> Linear algebra</a></li>
<li class="chapter" data-level="3.12.4" data-path="auxiliary-fields.html"><a href="auxiliary-fields.html#combinatorics"><i class="fa fa-check"></i><b>3.12.4</b> Combinatorics</a></li>
<li class="chapter" data-level="3.12.5" data-path="auxiliary-fields.html"><a href="auxiliary-fields.html#numerical-methods"><i class="fa fa-check"></i><b>3.12.5</b> Numerical methods</a></li>
<li class="chapter" data-level="3.12.6" data-path="auxiliary-fields.html"><a href="auxiliary-fields.html#equations"><i class="fa fa-check"></i><b>3.12.6</b> Equations</a>
<ul>
<li class="chapter" data-level="3.12.6.1" data-path="auxiliary-fields.html"><a href="auxiliary-fields.html#x-as-number"><i class="fa fa-check"></i><b>3.12.6.1</b> x as number</a></li>
<li class="chapter" data-level="3.12.6.2" data-path="auxiliary-fields.html"><a href="auxiliary-fields.html#x-as-derivative-differential-and-difference-equations"><i class="fa fa-check"></i><b>3.12.6.2</b> X as derivative: differential and difference equations</a></li>
<li class="chapter" data-level="3.12.6.3" data-path="auxiliary-fields.html"><a href="auxiliary-fields.html#choas"><i class="fa fa-check"></i><b>3.12.6.3</b> Choas</a>
<ul>
<li class="chapter" data-level="3.12.6.3.1" data-path="auxiliary-fields.html"><a href="auxiliary-fields.html#logistic-map"><i class="fa fa-check"></i><b>3.12.6.3.1</b> logistic map</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3.12.7" data-path="auxiliary-fields.html"><a href="auxiliary-fields.html#fuzzy-logic"><i class="fa fa-check"></i><b>3.12.7</b> Fuzzy logic</a></li>
<li class="chapter" data-level="3.12.8" data-path="auxiliary-fields.html"><a href="auxiliary-fields.html#graphs"><i class="fa fa-check"></i><b>3.12.8</b> Graphs</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html"><i class="fa fa-check"></i><b>4</b> LEARNING: PATTERNS DISCOVERING</a>
<ul>
<li class="chapter" data-level="4.1" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#introduction-3"><i class="fa fa-check"></i><b>4.1</b> Introduction</a></li>
<li class="chapter" data-level="4.2" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#clustering"><i class="fa fa-check"></i><b>4.2</b> Clustering</a>
<ul>
<li class="chapter" data-level="4.2.1" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#section"><i class="fa fa-check"></i><b>4.2.1</b> <img src="02_PATTERNS/figures/miary_odleglosci_klastrow.PNG" /></a></li>
<li class="chapter" data-level="4.2.2" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#introduction-4"><i class="fa fa-check"></i><b>4.2.2</b> Introduction</a></li>
<li class="chapter" data-level="4.2.3" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#hierarchical-connectivity-based"><i class="fa fa-check"></i><b>4.2.3</b> Hierarchical (Connectivity-based)</a>
<ul>
<li class="chapter" data-level="4.2.3.1" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#agglomerativedivisive"><i class="fa fa-check"></i><b>4.2.3.1</b> Agglomerative/Divisive</a></li>
<li class="chapter" data-level="4.2.3.2" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#chameleon"><i class="fa fa-check"></i><b>4.2.3.2</b> CHAMELEON</a></li>
<li class="chapter" data-level="4.2.3.3" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#birch"><i class="fa fa-check"></i><b>4.2.3.3</b> BIRCH</a></li>
<li class="chapter" data-level="4.2.3.4" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#hdbscan"><i class="fa fa-check"></i><b>4.2.3.4</b> HDBSCAN</a></li>
<li class="chapter" data-level="4.2.3.5" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#rock"><i class="fa fa-check"></i><b>4.2.3.5</b> ROCK</a></li>
<li class="chapter" data-level="4.2.3.6" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#echidna"><i class="fa fa-check"></i><b>4.2.3.6</b> Echidna</a></li>
<li class="chapter" data-level="4.2.3.7" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#diana"><i class="fa fa-check"></i><b>4.2.3.7</b> Diana</a></li>
<li class="chapter" data-level="4.2.3.8" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#agnes"><i class="fa fa-check"></i><b>4.2.3.8</b> Agnes</a></li>
</ul></li>
<li class="chapter" data-level="4.2.4" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#partititonal"><i class="fa fa-check"></i><b>4.2.4</b> Partititonal</a>
<ul>
<li class="chapter" data-level="4.2.4.1" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#k-methods"><i class="fa fa-check"></i><b>4.2.4.1</b> k-methods</a>
<ul>
<li class="chapter" data-level="4.2.4.1.1" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#k-means"><i class="fa fa-check"></i><b>4.2.4.1.1</b> k-means</a></li>
<li class="chapter" data-level="4.2.4.1.2" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#k-means-1"><i class="fa fa-check"></i><b>4.2.4.1.2</b> k-means ++</a></li>
<li class="chapter" data-level="4.2.4.1.3" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#k-means-scalable"><i class="fa fa-check"></i><b>4.2.4.1.3</b> k-means ++ scalable</a></li>
<li class="chapter" data-level="4.2.4.1.4" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#c-fuzzy-means"><i class="fa fa-check"></i><b>4.2.4.1.4</b> c-fuzzy means</a></li>
<li class="chapter" data-level="4.2.4.1.5" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#k-medoids"><i class="fa fa-check"></i><b>4.2.4.1.5</b> k-medoids</a></li>
<li class="chapter" data-level="4.2.4.1.6" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#k-medians"><i class="fa fa-check"></i><b>4.2.4.1.6</b> k-medians</a></li>
<li class="chapter" data-level="4.2.4.1.7" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#k-modes"><i class="fa fa-check"></i><b>4.2.4.1.7</b> k-modes</a></li>
<li class="chapter" data-level="4.2.4.1.8" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#k-prototypes"><i class="fa fa-check"></i><b>4.2.4.1.8</b> k-prototypes</a></li>
<li class="chapter" data-level="4.2.4.1.9" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#k-means-sgd-stochastic-gradient-descent"><i class="fa fa-check"></i><b>4.2.4.1.9</b> k-means SGD (stochastic gradient descent)</a></li>
<li class="chapter" data-level="4.2.4.1.10" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#k-mini-batches"><i class="fa fa-check"></i><b>4.2.4.1.10</b> k-mini-batches</a></li>
</ul></li>
<li class="chapter" data-level="4.2.4.2" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#claranas"><i class="fa fa-check"></i><b>4.2.4.2</b> CLARANAS</a></li>
<li class="chapter" data-level="4.2.4.3" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#clara"><i class="fa fa-check"></i><b>4.2.4.3</b> CLARA</a></li>
<li class="chapter" data-level="4.2.4.4" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#fcm"><i class="fa fa-check"></i><b>4.2.4.4</b> FCM</a></li>
<li class="chapter" data-level="4.2.4.5" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#fcmdc"><i class="fa fa-check"></i><b>4.2.4.5</b> FCMdC</a></li>
<li class="chapter" data-level="4.2.4.6" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#fanny"><i class="fa fa-check"></i><b>4.2.4.6</b> Fanny</a></li>
</ul></li>
<li class="chapter" data-level="4.2.5" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#density-latent-distibutions"><i class="fa fa-check"></i><b>4.2.5</b> Density /Latent distibutions</a>
<ul>
<li class="chapter" data-level="4.2.5.1" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#dbscan"><i class="fa fa-check"></i><b>4.2.5.1</b> DBSCAN</a></li>
<li class="chapter" data-level="4.2.5.2" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#optics"><i class="fa fa-check"></i><b>4.2.5.2</b> OPTICS</a></li>
<li class="chapter" data-level="4.2.5.3" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#predecon"><i class="fa fa-check"></i><b>4.2.5.3</b> PreDeCon</a></li>
<li class="chapter" data-level="4.2.5.4" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#subclu"><i class="fa fa-check"></i><b>4.2.5.4</b> SUBCLU</a></li>
<li class="chapter" data-level="4.2.5.5" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#denclue"><i class="fa fa-check"></i><b>4.2.5.5</b> DENCLUE</a></li>
<li class="chapter" data-level="4.2.5.6" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#dbclasd"><i class="fa fa-check"></i><b>4.2.5.6</b> DBCLASD</a></li>
<li class="chapter" data-level="4.2.5.7" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#graph-based-clustering"><i class="fa fa-check"></i><b>4.2.5.7</b> Graph based clustering</a>
<ul>
<li class="chapter" data-level="4.2.5.7.1" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#spectral-clustering"><i class="fa fa-check"></i><b>4.2.5.7.1</b> Spectral clustering</a></li>
</ul></li>
<li class="chapter" data-level="4.2.5.8" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#mean-shift"><i class="fa fa-check"></i><b>4.2.5.8</b> Mean Shift</a></li>
<li class="chapter" data-level="4.2.5.9" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#substractive-methods"><i class="fa fa-check"></i><b>4.2.5.9</b> Substractive Methods</a></li>
</ul></li>
<li class="chapter" data-level="4.2.6" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#grids"><i class="fa fa-check"></i><b>4.2.6</b> Grids</a>
<ul>
<li class="chapter" data-level="4.2.6.1" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#sting"><i class="fa fa-check"></i><b>4.2.6.1</b> STING</a></li>
<li class="chapter" data-level="4.2.6.2" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#clique"><i class="fa fa-check"></i><b>4.2.6.2</b> CLIQUE</a></li>
<li class="chapter" data-level="4.2.6.3" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#wavecluster"><i class="fa fa-check"></i><b>4.2.6.3</b> WaveCluster</a></li>
<li class="chapter" data-level="4.2.6.4" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#optigrid"><i class="fa fa-check"></i><b>4.2.6.4</b> OptiGrid</a></li>
</ul></li>
<li class="chapter" data-level="4.2.7" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#model-based"><i class="fa fa-check"></i><b>4.2.7</b> Model Based</a>
<ul>
<li class="chapter" data-level="4.2.7.1" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#classit"><i class="fa fa-check"></i><b>4.2.7.1</b> CLASSIT</a></li>
<li class="chapter" data-level="4.2.7.2" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#soms"><i class="fa fa-check"></i><b>4.2.7.2</b> SOMs</a></li>
<li class="chapter" data-level="4.2.7.3" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#cobweb"><i class="fa fa-check"></i><b>4.2.7.3</b> COBWEB</a></li>
<li class="chapter" data-level="4.2.7.4" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#neural-networks"><i class="fa fa-check"></i><b>4.2.7.4</b> Neural Networks</a></li>
</ul></li>
<li class="chapter" data-level="4.2.8" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#other"><i class="fa fa-check"></i><b>4.2.8</b> Other</a>
<ul>
<li class="chapter" data-level="4.2.8.1" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#affinity-propagation"><i class="fa fa-check"></i><b>4.2.8.1</b> Affinity propagation</a></li>
<li class="chapter" data-level="4.2.8.2" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#random-foreset"><i class="fa fa-check"></i><b>4.2.8.2</b> Random Foreset</a></li>
</ul></li>
<li class="chapter" data-level="4.2.9" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#consensus"><i class="fa fa-check"></i><b>4.2.9</b> Consensus</a>
<ul>
<li class="chapter" data-level="4.2.9.1" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#monti-consensus"><i class="fa fa-check"></i><b>4.2.9.1</b> Monti Consensus</a></li>
<li class="chapter" data-level="4.2.9.2" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#rand-index"><i class="fa fa-check"></i><b>4.2.9.2</b> Rand Index</a></li>
</ul></li>
<li class="chapter" data-level="4.2.10" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#by-problems"><i class="fa fa-check"></i><b>4.2.10</b> By problems</a>
<ul>
<li class="chapter" data-level="4.2.10.1" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#numerical-and-categorical"><i class="fa fa-check"></i><b>4.2.10.1</b> Numerical and categorical</a></li>
<li class="chapter" data-level="4.2.10.2" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#text-data"><i class="fa fa-check"></i><b>4.2.10.2</b> Text data</a>
<ul>
<li class="chapter" data-level="4.2.10.2.1" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#latent-dirichlet-allocation"><i class="fa fa-check"></i><b>4.2.10.2.1</b> Latent Dirichlet allocation</a></li>
</ul></li>
<li class="chapter" data-level="4.2.10.3" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#sound"><i class="fa fa-check"></i><b>4.2.10.3</b> Sound</a></li>
<li class="chapter" data-level="4.2.10.4" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#vision"><i class="fa fa-check"></i><b>4.2.10.4</b> Vision</a></li>
</ul></li>
<li class="chapter" data-level="4.2.11" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#results-diagnostics"><i class="fa fa-check"></i><b>4.2.11</b> Results diagnostics</a>
<ul>
<li class="chapter" data-level="4.2.11.1" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#bicaic"><i class="fa fa-check"></i><b>4.2.11.1</b> BIC/AIC</a></li>
<li class="chapter" data-level="4.2.11.2" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#metoda-łokcia-elbow."><i class="fa fa-check"></i><b>4.2.11.2</b> Metoda łokcia (elbow).</a></li>
<li class="chapter" data-level="4.2.11.3" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#silhouette-link"><i class="fa fa-check"></i><b>4.2.11.3</b> silhouette: <span>link</span></a></li>
<li class="chapter" data-level="4.2.11.4" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#celinski-harabasz-indeks"><i class="fa fa-check"></i><b>4.2.11.4</b> Celinski Harabasz indeks</a></li>
<li class="chapter" data-level="4.2.11.5" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#davies-bouldin-index"><i class="fa fa-check"></i><b>4.2.11.5</b> <strong>Davies-Bouldin Index</strong></a></li>
</ul></li>
<li class="chapter" data-level="4.2.12" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#elements-selection"><i class="fa fa-check"></i><b>4.2.12</b> Elements selection</a></li>
<li class="chapter" data-level="4.2.13" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#iml"><i class="fa fa-check"></i><b>4.2.13</b> IML</a></li>
<li class="chapter" data-level="4.2.14" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#by-problems-1"><i class="fa fa-check"></i><b>4.2.14</b> By problems</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#association"><i class="fa fa-check"></i><b>4.3</b> Association</a>
<ul>
<li class="chapter" data-level="4.3.1" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#apriori"><i class="fa fa-check"></i><b>4.3.1</b> Apriori</a></li>
<li class="chapter" data-level="4.3.2" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#euclat"><i class="fa fa-check"></i><b>4.3.2</b> Euclat</a></li>
<li class="chapter" data-level="4.3.3" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#fp-growth"><i class="fa fa-check"></i><b>4.3.3</b> FP-growth</a></li>
<li class="chapter" data-level="4.3.4" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#assoc"><i class="fa fa-check"></i><b>4.3.4</b> ASSOC</a></li>
<li class="chapter" data-level="4.3.5" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#opus"><i class="fa fa-check"></i><b>4.3.5</b> OPUS</a></li>
<li class="chapter" data-level="4.3.6" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#neural-networks-1"><i class="fa fa-check"></i><b>4.3.6</b> Neural Networks</a></li>
<li class="chapter" data-level="4.3.7" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#results-diagnostics-1"><i class="fa fa-check"></i><b>4.3.7</b> Results diagnostics</a></li>
<li class="chapter" data-level="4.3.8" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#elements-selection-1"><i class="fa fa-check"></i><b>4.3.8</b> Elements selection</a></li>
<li class="chapter" data-level="4.3.9" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#iml-1"><i class="fa fa-check"></i><b>4.3.9</b> IML</a></li>
<li class="chapter" data-level="4.3.10" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#by-problems-2"><i class="fa fa-check"></i><b>4.3.10</b> By problems</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#dimentionality-reduction"><i class="fa fa-check"></i><b>4.4</b> Dimentionality reduction</a>
<ul>
<li class="chapter" data-level="4.4.1" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#unsupervised"><i class="fa fa-check"></i><b>4.4.1</b> Unsupervised</a>
<ul>
<li class="chapter" data-level="4.4.1.1" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#pca"><i class="fa fa-check"></i><b>4.4.1.1</b> PCA</a>
<ul>
<li class="chapter" data-level="4.4.1.1.1" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#basic-pca"><i class="fa fa-check"></i><b>4.4.1.1.1</b> Basic PCA</a></li>
<li class="chapter" data-level="4.4.1.1.2" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#incremental-pca"><i class="fa fa-check"></i><b>4.4.1.1.2</b> Incremental PCA</a></li>
<li class="chapter" data-level="4.4.1.1.3" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#randomized-pca"><i class="fa fa-check"></i><b>4.4.1.1.3</b> Randomized PCA</a></li>
<li class="chapter" data-level="4.4.1.1.4" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#kernel-pca"><i class="fa fa-check"></i><b>4.4.1.1.4</b> kernel PCA</a></li>
</ul></li>
<li class="chapter" data-level="4.4.1.2" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#t-sne"><i class="fa fa-check"></i><b>4.4.1.2</b> t-SNE</a></li>
<li class="chapter" data-level="4.4.1.3" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#local-linear-embedding-lle"><i class="fa fa-check"></i><b>4.4.1.3</b> Local Linear Embedding (LLE)</a></li>
<li class="chapter" data-level="4.4.1.4" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#isomap"><i class="fa fa-check"></i><b>4.4.1.4</b> Isomap</a></li>
<li class="chapter" data-level="4.4.1.5" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#lda-as-dimentional-reduction"><i class="fa fa-check"></i><b>4.4.1.5</b> LDA as dimentional reduction</a></li>
<li class="chapter" data-level="4.4.1.6" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#partial-least-squares"><i class="fa fa-check"></i><b>4.4.1.6</b> Partial Least Squares</a></li>
<li class="chapter" data-level="4.4.1.7" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#multidimentional-scaling"><i class="fa fa-check"></i><b>4.4.1.7</b> Multidimentional Scaling</a></li>
<li class="chapter" data-level="4.4.1.8" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#correspondence-analysis"><i class="fa fa-check"></i><b>4.4.1.8</b> Correspondence Analysis</a></li>
<li class="chapter" data-level="4.4.1.9" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#kohonen-networks"><i class="fa fa-check"></i><b>4.4.1.9</b> Kohonen Networks</a></li>
<li class="chapter" data-level="4.4.1.10" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#neural-networks-other-than-kohonen"><i class="fa fa-check"></i><b>4.4.1.10</b> Neural Networks (other than Kohonen)</a></li>
<li class="chapter" data-level="4.4.1.11" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#factor-analysis"><i class="fa fa-check"></i><b>4.4.1.11</b> Factor Analysis</a></li>
<li class="chapter" data-level="4.4.1.12" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#latent-semantic-analysis"><i class="fa fa-check"></i><b>4.4.1.12</b> Latent semantic analysis</a></li>
<li class="chapter" data-level="4.4.1.13" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#autoencoders"><i class="fa fa-check"></i><b>4.4.1.13</b> Autoencoders</a></li>
<li class="chapter" data-level="4.4.1.14" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#analiza-glownych-skladowych-pca-principal-component-analysis"><i class="fa fa-check"></i><b>4.4.1.14</b> Analiza glownych skladowych (PCA) [Principal Component Analysis]</a></li>
<li class="chapter" data-level="4.4.1.15" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#analiza-glownych-wspolrzednych-pcoa-principal-coordinates-analysis"><i class="fa fa-check"></i><b>4.4.1.15</b> Analiza glownych wspolrzednych (PCoA) [Principal Coordinates Analysis]</a></li>
<li class="chapter" data-level="4.4.1.16" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#analiza-korespondencji-ca-correspondenca-analysis"><i class="fa fa-check"></i><b>4.4.1.16</b> Analiza korespondencji (CA) [Correspondenca Analysis]</a></li>
<li class="chapter" data-level="4.4.1.17" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#asymetryczna-analiza-korespondencji-aca-non-symmetric-correspondence-analysis"><i class="fa fa-check"></i><b>4.4.1.17</b> Asymetryczna analiza korespondencji (ACA) [Non-symmetric correspondence analysis]</a></li>
<li class="chapter" data-level="4.4.1.18" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#kanoniczna-analiza-korespondencji-cca-canonical-correspondence-analysis"><i class="fa fa-check"></i><b>4.4.1.18</b> Kanoniczna analiza korespondencji (CCA) [Canonical correspondence analysis]</a></li>
<li class="chapter" data-level="4.4.1.19" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#laczna-analiza-korespondencji-jca-joint-correspondence-analysis"><i class="fa fa-check"></i><b>4.4.1.19</b> Laczna analiza korespondencji (JCA) [Joint Correspondence Analysis]</a></li>
<li class="chapter" data-level="4.4.1.20" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#odwrocona-analiza-korespondencji-invca-inverse-correspondence-analysis"><i class="fa fa-check"></i><b>4.4.1.20</b> Odwrocona analiza korespondencji (InvCA) [Inverse correspondence analysis]</a></li>
<li class="chapter" data-level="4.4.1.21" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#taksowkowa-analiza-korespondencji-tca-taxicab-correspondence-analysis"><i class="fa fa-check"></i><b>4.4.1.21</b> Taksowkowa analiza korespondencji (TCA) [Taxicab Correspondence Analysis]</a></li>
<li class="chapter" data-level="4.4.1.22" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#rozmyta-analiza-korespondencji-fca-fuzzy-correspondence-analysis"><i class="fa fa-check"></i><b>4.4.1.22</b> Rozmyta analiza korespondencji (FCA) [Fuzzy correspondence analysis]</a></li>
<li class="chapter" data-level="4.4.1.23" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#wieloraka-analiza-korespondencji-mca-multiple-correspondence-analysis"><i class="fa fa-check"></i><b>4.4.1.23</b> Wieloraka analiza korespondencji (MCA) [Multiple correspondence analysis]</a></li>
<li class="chapter" data-level="4.4.1.24" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#regularyzowana-wieloraka-analiza-korespondencji-rmca-regularized-multiple-correspondence-analysis"><i class="fa fa-check"></i><b>4.4.1.24</b> Regularyzowana wieloraka analiza korespondencji (RMCA) [Regularized Multiple Correspondence Analysis]</a></li>
<li class="chapter" data-level="4.4.1.25" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#analiza-czynnikowa-fa-factor-analysis"><i class="fa fa-check"></i><b>4.4.1.25</b> Analiza czynnikowa (FA) <span>Factor analysis</span></a></li>
<li class="chapter" data-level="4.4.1.26" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#wieloraka-analiza-czynnikowa-mfa-multiple-factor-analysis"><i class="fa fa-check"></i><b>4.4.1.26</b> Wieloraka analiza czynnikowa (MFA) [Multiple Factor Analysis]</a></li>
<li class="chapter" data-level="4.4.1.27" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#analiza-skladowych-niezaleznych-ica-independent-component-analysis"><i class="fa fa-check"></i><b>4.4.1.27</b> Analiza skladowych niezaleznych (ICA) [Independent component analysis ]</a></li>
<li class="chapter" data-level="4.4.1.28" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#dca-detreded-correspondence-analysis"><i class="fa fa-check"></i><b>4.4.1.28</b> (DCA) [Detreded Correspondence Analysis]</a></li>
<li class="chapter" data-level="4.4.1.29" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#nieliniowa-analiza-korespondencji-npca-nonlinear-principal-components-analysis"><i class="fa fa-check"></i><b>4.4.1.29</b> Nieliniowa Analiza Korespondencji (NPCA) [Nonlinear Principal Components Analysis]</a></li>
<li class="chapter" data-level="4.4.1.30" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#mds-non-metric-multidimensional-scaling"><i class="fa fa-check"></i><b>4.4.1.30</b> (MDS) [Non-Metric Multidimensional Scaling]</a></li>
<li class="chapter" data-level="4.4.1.31" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#umap"><i class="fa fa-check"></i><b>4.4.1.31</b> UMAP</a></li>
<li class="chapter" data-level="4.4.1.32" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#trimap"><i class="fa fa-check"></i><b>4.4.1.32</b> <strong>TriMAP</strong></a></li>
<li class="chapter" data-level="4.4.1.33" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#pacmap"><i class="fa fa-check"></i><b>4.4.1.33</b> PaCMAP</a></li>
</ul></li>
<li class="chapter" data-level="4.4.2" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#supervised"><i class="fa fa-check"></i><b>4.4.2</b> Supervised</a>
<ul>
<li class="chapter" data-level="4.4.2.1" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#lda"><i class="fa fa-check"></i><b>4.4.2.1</b> LDA</a></li>
<li class="chapter" data-level="4.4.2.2" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#partial-least-squares-1"><i class="fa fa-check"></i><b>4.4.2.2</b> Partial Least Squares</a></li>
</ul></li>
<li class="chapter" data-level="4.4.3" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#results-diagnostics-2"><i class="fa fa-check"></i><b>4.4.3</b> Results diagnostics</a></li>
<li class="chapter" data-level="4.4.4" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#elements-selection-2"><i class="fa fa-check"></i><b>4.4.4</b> Elements selection</a></li>
<li class="chapter" data-level="4.4.5" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#iml-2"><i class="fa fa-check"></i><b>4.4.5</b> IML</a></li>
<li class="chapter" data-level="4.4.6" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#by-problems-3"><i class="fa fa-check"></i><b>4.4.6</b> By problems</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#casuality-analysis"><i class="fa fa-check"></i><b>4.5</b> Casuality analysis</a>
<ul>
<li class="chapter" data-level="4.5.1" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#sem"><i class="fa fa-check"></i><b>4.5.1</b> SEM</a>
<ul>
<li class="chapter" data-level="4.5.1.1" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#confirmatory-factor-analysis"><i class="fa fa-check"></i><b>4.5.1.1</b> Confirmatory factor analysis</a></li>
<li class="chapter" data-level="4.5.1.2" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#confirmatory-composite-analysis"><i class="fa fa-check"></i><b>4.5.1.2</b> Confirmatory composite analysis</a></li>
<li class="chapter" data-level="4.5.1.3" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#path-analysis"><i class="fa fa-check"></i><b>4.5.1.3</b> Path analysis</a></li>
<li class="chapter" data-level="4.5.1.4" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#partial-least-squares-path-modeling"><i class="fa fa-check"></i><b>4.5.1.4</b> Partial least squares path modeling</a></li>
<li class="chapter" data-level="4.5.1.5" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#latent-growth-modeling"><i class="fa fa-check"></i><b>4.5.1.5</b> Latent growth modeling</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4.6" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#dimentions-decomoposition"><i class="fa fa-check"></i><b>4.6</b> Dimentions decomoposition</a>
<ul>
<li class="chapter" data-level="4.6.1" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#results-diagnostics-3"><i class="fa fa-check"></i><b>4.6.1</b> Results diagnostics</a></li>
<li class="chapter" data-level="4.6.2" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#elements-selection-3"><i class="fa fa-check"></i><b>4.6.2</b> Elements selection</a></li>
<li class="chapter" data-level="4.6.3" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#iml-3"><i class="fa fa-check"></i><b>4.6.3</b> IML</a></li>
<li class="chapter" data-level="4.6.4" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#by-problems-4"><i class="fa fa-check"></i><b>4.6.4</b> By problems</a></li>
</ul></li>
<li class="chapter" data-level="4.7" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#generative-models"><i class="fa fa-check"></i><b>4.7</b> Generative models</a>
<ul>
<li class="chapter" data-level="4.7.1" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#results-diagnostics-4"><i class="fa fa-check"></i><b>4.7.1</b> Results diagnostics</a></li>
<li class="chapter" data-level="4.7.2" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#elements-selection-4"><i class="fa fa-check"></i><b>4.7.2</b> Elements selection</a></li>
<li class="chapter" data-level="4.7.3" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#iml-4"><i class="fa fa-check"></i><b>4.7.3</b> IML</a></li>
<li class="chapter" data-level="4.7.4" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#by-problems-5"><i class="fa fa-check"></i><b>4.7.4</b> By problems</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="learning-with-target.html"><a href="learning-with-target.html"><i class="fa fa-check"></i><b>5</b> LEARNING: WITH TARGET</a>
<ul>
<li class="chapter" data-level="5.1" data-path="learning-with-target.html"><a href="learning-with-target.html#introduction-5"><i class="fa fa-check"></i><b>5.1</b> Introduction</a>
<ul>
<li class="chapter" data-level="5.1.1" data-path="learning-with-target.html"><a href="learning-with-target.html#classification"><i class="fa fa-check"></i><b>5.1.1</b> Classification</a></li>
<li class="chapter" data-level="5.1.2" data-path="learning-with-target.html"><a href="learning-with-target.html#regression"><i class="fa fa-check"></i><b>5.1.2</b> Regression</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="learning-with-target.html"><a href="learning-with-target.html#econometrical-regression"><i class="fa fa-check"></i><b>5.2</b> Econometrical regression</a>
<ul>
<li class="chapter" data-level="5.2.1" data-path="learning-with-target.html"><a href="learning-with-target.html#basic-regression"><i class="fa fa-check"></i><b>5.2.1</b> Basic regression</a></li>
<li class="chapter" data-level="5.2.2" data-path="learning-with-target.html"><a href="learning-with-target.html#basic-dynamic-model"><i class="fa fa-check"></i><b>5.2.2</b> Basic dynamic model</a></li>
<li class="chapter" data-level="5.2.3" data-path="learning-with-target.html"><a href="learning-with-target.html#generalisations-and-constrains"><i class="fa fa-check"></i><b>5.2.3</b> Generalisations and constrains</a>
<ul>
<li class="chapter" data-level="5.2.3.1" data-path="learning-with-target.html"><a href="learning-with-target.html#glm"><i class="fa fa-check"></i><b>5.2.3.1</b> GLM</a>
<ul>
<li class="chapter" data-level="5.2.3.1.1" data-path="learning-with-target.html"><a href="learning-with-target.html#logisti-regression"><i class="fa fa-check"></i><b>5.2.3.1.1</b> logisti regression</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5.2.4" data-path="learning-with-target.html"><a href="learning-with-target.html#bayesian-inference"><i class="fa fa-check"></i><b>5.2.4</b> Bayesian inference</a></li>
<li class="chapter" data-level="5.2.5" data-path="learning-with-target.html"><a href="learning-with-target.html#multivariate-models"><i class="fa fa-check"></i><b>5.2.5</b> Multivariate models</a></li>
<li class="chapter" data-level="5.2.6" data-path="learning-with-target.html"><a href="learning-with-target.html#models-with-effects"><i class="fa fa-check"></i><b>5.2.6</b> Models with effects</a></li>
<li class="chapter" data-level="5.2.7" data-path="learning-with-target.html"><a href="learning-with-target.html#nonparametric-regression"><i class="fa fa-check"></i><b>5.2.7</b> Nonparametric regression</a>
<ul>
<li class="chapter" data-level="5.2.7.1" data-path="learning-with-target.html"><a href="learning-with-target.html#mars-splines"><i class="fa fa-check"></i><b>5.2.7.1</b> MARS Splines</a></li>
</ul></li>
<li class="chapter" data-level="5.2.8" data-path="learning-with-target.html"><a href="learning-with-target.html#pros"><i class="fa fa-check"></i><b>5.2.8</b> Pros</a></li>
<li class="chapter" data-level="5.2.9" data-path="learning-with-target.html"><a href="learning-with-target.html#cons"><i class="fa fa-check"></i><b>5.2.9</b> Cons</a>
<ul>
<li class="chapter" data-level="5.2.9.1" data-path="learning-with-target.html"><a href="learning-with-target.html#isotonic"><i class="fa fa-check"></i><b>5.2.9.1</b> Isotonic</a></li>
</ul></li>
<li class="chapter" data-level="5.2.10" data-path="learning-with-target.html"><a href="learning-with-target.html#other-regression-models"><i class="fa fa-check"></i><b>5.2.10</b> Other regression models</a>
<ul>
<li class="chapter" data-level="5.2.10.1" data-path="learning-with-target.html"><a href="learning-with-target.html#canonical-analysis"><i class="fa fa-check"></i><b>5.2.10.1</b> Canonical analysis</a></li>
<li class="chapter" data-level="5.2.10.2" data-path="learning-with-target.html"><a href="learning-with-target.html#anova-manova-ancova"><i class="fa fa-check"></i><b>5.2.10.2</b> ANOVA MANOVA ANCOVA</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="learning-with-target.html"><a href="learning-with-target.html#lda-qda"><i class="fa fa-check"></i><b>5.3</b> LDA &amp; QDA</a></li>
<li class="chapter" data-level="5.4" data-path="learning-with-target.html"><a href="learning-with-target.html#bayesian-models"><i class="fa fa-check"></i><b>5.4</b> Bayesian models</a></li>
<li class="chapter" data-level="5.5" data-path="learning-with-target.html"><a href="learning-with-target.html#trees"><i class="fa fa-check"></i><b>5.5</b> Trees</a>
<ul>
<li class="chapter" data-level="5.5.1" data-path="learning-with-target.html"><a href="learning-with-target.html#pros-1"><i class="fa fa-check"></i><b>5.5.1</b> pros</a></li>
<li class="chapter" data-level="5.5.2" data-path="learning-with-target.html"><a href="learning-with-target.html#cons-1"><i class="fa fa-check"></i><b>5.5.2</b> cons</a></li>
<li class="chapter" data-level="5.5.3" data-path="learning-with-target.html"><a href="learning-with-target.html#classification-1"><i class="fa fa-check"></i><b>5.5.3</b> Classification</a></li>
<li class="chapter" data-level="5.5.4" data-path="learning-with-target.html"><a href="learning-with-target.html#regression-1"><i class="fa fa-check"></i><b>5.5.4</b> Regression</a></li>
</ul></li>
<li class="chapter" data-level="5.6" data-path="learning-with-target.html"><a href="learning-with-target.html#svm"><i class="fa fa-check"></i><b>5.6</b> SVM</a>
<ul>
<li class="chapter" data-level="5.6.1" data-path="learning-with-target.html"><a href="learning-with-target.html#classification-2"><i class="fa fa-check"></i><b>5.6.1</b> Classification</a></li>
<li class="chapter" data-level="5.6.2" data-path="learning-with-target.html"><a href="learning-with-target.html#regression-2"><i class="fa fa-check"></i><b>5.6.2</b> Regression</a></li>
</ul></li>
<li class="chapter" data-level="5.7" data-path="learning-with-target.html"><a href="learning-with-target.html#k-nn"><i class="fa fa-check"></i><b>5.7</b> K-NN</a>
<ul>
<li class="chapter" data-level="5.7.1" data-path="learning-with-target.html"><a href="learning-with-target.html#classification-3"><i class="fa fa-check"></i><b>5.7.1</b> Classification</a>
<ul>
<li class="chapter" data-level="5.7.1.1" data-path="learning-with-target.html"><a href="learning-with-target.html#kd---tree"><i class="fa fa-check"></i><b>5.7.1.1</b> KD - tree</a></li>
<li class="chapter" data-level="5.7.1.2" data-path="learning-with-target.html"><a href="learning-with-target.html#ball-tree"><i class="fa fa-check"></i><b>5.7.1.2</b> Ball tree</a></li>
<li class="chapter" data-level="5.7.1.3" data-path="learning-with-target.html"><a href="learning-with-target.html#condensing-hart-algorithm"><i class="fa fa-check"></i><b>5.7.1.3</b> Condensing (Hart algorithm)</a></li>
<li class="chapter" data-level="5.7.1.4" data-path="learning-with-target.html"><a href="learning-with-target.html#editing"><i class="fa fa-check"></i><b>5.7.1.4</b> <strong>Editing</strong></a></li>
<li class="chapter" data-level="5.7.1.5" data-path="learning-with-target.html"><a href="learning-with-target.html#reducing"><i class="fa fa-check"></i><b>5.7.1.5</b> Reducing</a></li>
</ul></li>
<li class="chapter" data-level="5.7.2" data-path="learning-with-target.html"><a href="learning-with-target.html#regression-3"><i class="fa fa-check"></i><b>5.7.2</b> Regression</a></li>
</ul></li>
<li class="chapter" data-level="5.8" data-path="learning-with-target.html"><a href="learning-with-target.html#log-linear-model"><i class="fa fa-check"></i><b>5.8</b> Log-linear model</a></li>
<li class="chapter" data-level="5.9" data-path="learning-with-target.html"><a href="learning-with-target.html#similarity-learning"><i class="fa fa-check"></i><b>5.9</b> Similarity learning</a></li>
<li class="chapter" data-level="5.10" data-path="learning-with-target.html"><a href="learning-with-target.html#survival-models"><i class="fa fa-check"></i><b>5.10</b> Survival models</a>
<ul>
<li class="chapter" data-level="5.10.1" data-path="learning-with-target.html"><a href="learning-with-target.html#podstawowe-pojęcia"><i class="fa fa-check"></i><b>5.10.1</b> <strong>Podstawowe pojęcia</strong></a></li>
<li class="chapter" data-level="5.10.2" data-path="learning-with-target.html"><a href="learning-with-target.html#estymatory-standardowe-nieparametryczne"><i class="fa fa-check"></i><b>5.10.2</b> <strong>Estymatory standardowe-nieparametryczne</strong></a>
<ul>
<li class="chapter" data-level="5.10.2.1" data-path="learning-with-target.html"><a href="learning-with-target.html#tablice-trwania-życia-life-table"><i class="fa fa-check"></i><b>5.10.2.1</b> Tablice trwania życia (life table)</a></li>
<li class="chapter" data-level="5.10.2.2" data-path="learning-with-target.html"><a href="learning-with-target.html#kaplan-mayer"><i class="fa fa-check"></i><b>5.10.2.2</b> Kaplan Mayer</a></li>
<li class="chapter" data-level="5.10.2.3" data-path="learning-with-target.html"><a href="learning-with-target.html#nelson-aalen"><i class="fa fa-check"></i><b>5.10.2.3</b> Nelson Aalen</a></li>
</ul></li>
<li class="chapter" data-level="5.10.3" data-path="learning-with-target.html"><a href="learning-with-target.html#estymatora-standardowe-parametryczne"><i class="fa fa-check"></i><b>5.10.3</b> <strong>Estymatora standardowe parametryczne</strong></a></li>
<li class="chapter" data-level="5.10.4" data-path="learning-with-target.html"><a href="learning-with-target.html#estymatory-standardowe-semi-parametryczne"><i class="fa fa-check"></i><b>5.10.4</b> Estymatory standardowe semi-parametryczne</a>
<ul>
<li class="chapter" data-level="5.10.4.1" data-path="learning-with-target.html"><a href="learning-with-target.html#cox"><i class="fa fa-check"></i><b>5.10.4.1</b> <strong>Cox</strong></a></li>
</ul></li>
<li class="chapter" data-level="5.10.5" data-path="learning-with-target.html"><a href="learning-with-target.html#estymatory-inne"><i class="fa fa-check"></i><b>5.10.5</b> Estymatory inne</a>
<ul>
<li class="chapter" data-level="5.10.5.1" data-path="learning-with-target.html"><a href="learning-with-target.html#random-survival-forest"><i class="fa fa-check"></i><b>5.10.5.1</b> Random Survival Forest</a></li>
<li class="chapter" data-level="5.10.5.2" data-path="learning-with-target.html"><a href="learning-with-target.html#deepsurv"><i class="fa fa-check"></i><b>5.10.5.2</b> <strong>DeepSurv</strong></a></li>
</ul></li>
<li class="chapter" data-level="5.10.6" data-path="learning-with-target.html"><a href="learning-with-target.html#performence"><i class="fa fa-check"></i><b>5.10.6</b> <strong>Performence</strong></a></li>
</ul></li>
<li class="chapter" data-level="5.11" data-path="learning-with-target.html"><a href="learning-with-target.html#ensembled-models"><i class="fa fa-check"></i><b>5.11</b> Ensembled models</a>
<ul>
<li class="chapter" data-level="5.11.1" data-path="learning-with-target.html"><a href="learning-with-target.html#bagging-and-pasting-1"><i class="fa fa-check"></i><b>5.11.1</b> Bagging and Pasting</a>
<ul>
<li class="chapter" data-level="5.11.1.1" data-path="learning-with-target.html"><a href="learning-with-target.html#random-forest"><i class="fa fa-check"></i><b>5.11.1.1</b> Random Forest</a>
<ul>
<li class="chapter" data-level="5.11.1.1.1" data-path="learning-with-target.html"><a href="learning-with-target.html#out-of-bag-error"><i class="fa fa-check"></i><b>5.11.1.1.1</b> Out of Bag Error</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5.11.2" data-path="learning-with-target.html"><a href="learning-with-target.html#boosting-1"><i class="fa fa-check"></i><b>5.11.2</b> Boosting</a>
<ul>
<li class="chapter" data-level="5.11.2.1" data-path="learning-with-target.html"><a href="learning-with-target.html#ada-boost"><i class="fa fa-check"></i><b>5.11.2.1</b> Ada Boost</a></li>
<li class="chapter" data-level="5.11.2.2" data-path="learning-with-target.html"><a href="learning-with-target.html#gradient-boost"><i class="fa fa-check"></i><b>5.11.2.2</b> Gradient Boost</a></li>
<li class="chapter" data-level="5.11.2.3" data-path="learning-with-target.html"><a href="learning-with-target.html#xgboost"><i class="fa fa-check"></i><b>5.11.2.3</b> XGBoost</a></li>
<li class="chapter" data-level="5.11.2.4" data-path="learning-with-target.html"><a href="learning-with-target.html#catboost"><i class="fa fa-check"></i><b>5.11.2.4</b> CatBoost</a></li>
<li class="chapter" data-level="5.11.2.5" data-path="learning-with-target.html"><a href="learning-with-target.html#lightgbm"><i class="fa fa-check"></i><b>5.11.2.5</b> LightGBM</a></li>
</ul></li>
<li class="chapter" data-level="5.11.3" data-path="learning-with-target.html"><a href="learning-with-target.html#stacking-1"><i class="fa fa-check"></i><b>5.11.3</b> Stacking</a></li>
<li class="chapter" data-level="5.11.4" data-path="learning-with-target.html"><a href="learning-with-target.html#twicing"><i class="fa fa-check"></i><b>5.11.4</b> Twicing</a></li>
<li class="chapter" data-level="5.11.5" data-path="learning-with-target.html"><a href="learning-with-target.html#bandling"><i class="fa fa-check"></i><b>5.11.5</b> Bandling</a></li>
</ul></li>
<li class="chapter" data-level="5.12" data-path="learning-with-target.html"><a href="learning-with-target.html#neural-networks-2"><i class="fa fa-check"></i><b>5.12</b> Neural Networks</a>
<ul>
<li class="chapter" data-level="5.12.1" data-path="learning-with-target.html"><a href="learning-with-target.html#introduction-6"><i class="fa fa-check"></i><b>5.12.1</b> Introduction</a></li>
<li class="chapter" data-level="5.12.2" data-path="learning-with-target.html"><a href="learning-with-target.html#basics-2"><i class="fa fa-check"></i><b>5.12.2</b> Basics</a></li>
<li class="chapter" data-level="5.12.3" data-path="learning-with-target.html"><a href="learning-with-target.html#reccurent"><i class="fa fa-check"></i><b>5.12.3</b> Reccurent</a>
<ul>
<li class="chapter" data-level="5.12.3.1" data-path="learning-with-target.html"><a href="learning-with-target.html#simple-reccurent"><i class="fa fa-check"></i><b>5.12.3.1</b> Simple reccurent</a></li>
<li class="chapter" data-level="5.12.3.2" data-path="learning-with-target.html"><a href="learning-with-target.html#bidirectorial"><i class="fa fa-check"></i><b>5.12.3.2</b> Bidirectorial</a></li>
<li class="chapter" data-level="5.12.3.3" data-path="learning-with-target.html"><a href="learning-with-target.html#lstm"><i class="fa fa-check"></i><b>5.12.3.3</b> LSTM</a></li>
<li class="chapter" data-level="5.12.3.4" data-path="learning-with-target.html"><a href="learning-with-target.html#gru"><i class="fa fa-check"></i><b>5.12.3.4</b> GRU</a></li>
<li class="chapter" data-level="5.12.3.5" data-path="learning-with-target.html"><a href="learning-with-target.html#attention"><i class="fa fa-check"></i><b>5.12.3.5</b> Attention</a></li>
</ul></li>
<li class="chapter" data-level="5.12.4" data-path="learning-with-target.html"><a href="learning-with-target.html#cnn"><i class="fa fa-check"></i><b>5.12.4</b> CNN</a></li>
<li class="chapter" data-level="5.12.5" data-path="learning-with-target.html"><a href="learning-with-target.html#resnet"><i class="fa fa-check"></i><b>5.12.5</b> Resnet</a></li>
</ul></li>
<li class="chapter" data-level="5.13" data-path="learning-with-target.html"><a href="learning-with-target.html#stochastic-processes-1"><i class="fa fa-check"></i><b>5.13</b> Stochastic processes</a>
<ul>
<li class="chapter" data-level="5.13.1" data-path="learning-with-target.html"><a href="learning-with-target.html#basic-trend-models"><i class="fa fa-check"></i><b>5.13.1</b> Basic trend models</a></li>
<li class="chapter" data-level="5.13.2" data-path="learning-with-target.html"><a href="learning-with-target.html#basic-adaptative-models"><i class="fa fa-check"></i><b>5.13.2</b> Basic adaptative models</a></li>
<li class="chapter" data-level="5.13.3" data-path="learning-with-target.html"><a href="learning-with-target.html#econometric-time-series-models"><i class="fa fa-check"></i><b>5.13.3</b> Econometric time series models</a>
<ul>
<li class="chapter" data-level="5.13.3.1" data-path="learning-with-target.html"><a href="learning-with-target.html#dynamic-for-example-error-correction-models"><i class="fa fa-check"></i><b>5.13.3.1</b> dynamic (for example error correction models)</a></li>
<li class="chapter" data-level="5.13.3.2" data-path="learning-with-target.html"><a href="learning-with-target.html#sarimax"><i class="fa fa-check"></i><b>5.13.3.2</b> SARIMAX</a></li>
<li class="chapter" data-level="5.13.3.3" data-path="learning-with-target.html"><a href="learning-with-target.html#varimax"><i class="fa fa-check"></i><b>5.13.3.3</b> VARIMAX</a></li>
<li class="chapter" data-level="5.13.3.4" data-path="learning-with-target.html"><a href="learning-with-target.html#arch-class-models"><i class="fa fa-check"></i><b>5.13.3.4</b> ARCH class models</a></li>
<li class="chapter" data-level="5.13.3.5" data-path="learning-with-target.html"><a href="learning-with-target.html#cointegration-including-arld-approach"><i class="fa fa-check"></i><b>5.13.3.5</b> Cointegration (including ARLD approach)</a></li>
</ul></li>
<li class="chapter" data-level="5.13.4" data-path="learning-with-target.html"><a href="learning-with-target.html#time-series-decomposition-decomposition"><i class="fa fa-check"></i><b>5.13.4</b> Time series decomposition decomposition</a></li>
<li class="chapter" data-level="5.13.5" data-path="learning-with-target.html"><a href="learning-with-target.html#kalman-filters"><i class="fa fa-check"></i><b>5.13.5</b> Kalman filters</a></li>
<li class="chapter" data-level="5.13.6" data-path="learning-with-target.html"><a href="learning-with-target.html#neural-networks-3"><i class="fa fa-check"></i><b>5.13.6</b> Neural Networks</a>
<ul>
<li class="chapter" data-level="5.13.6.1" data-path="learning-with-target.html"><a href="learning-with-target.html#long-short-term-memory"><i class="fa fa-check"></i><b>5.13.6.1</b> Long short term memory</a></li>
<li class="chapter" data-level="5.13.6.2" data-path="learning-with-target.html"><a href="learning-with-target.html#cnn-1"><i class="fa fa-check"></i><b>5.13.6.2</b> CNN</a></li>
</ul></li>
<li class="chapter" data-level="5.13.7" data-path="learning-with-target.html"><a href="learning-with-target.html#panel-regression"><i class="fa fa-check"></i><b>5.13.7</b> Panel Regression</a></li>
<li class="chapter" data-level="5.13.8" data-path="learning-with-target.html"><a href="learning-with-target.html#gaussian-process"><i class="fa fa-check"></i><b>5.13.8</b> Gaussian Process</a></li>
<li class="chapter" data-level="5.13.9" data-path="learning-with-target.html"><a href="learning-with-target.html#ensembled-models-1"><i class="fa fa-check"></i><b>5.13.9</b> Ensembled models</a></li>
<li class="chapter" data-level="5.13.10" data-path="learning-with-target.html"><a href="learning-with-target.html#martingales"><i class="fa fa-check"></i><b>5.13.10</b> Martingales</a></li>
<li class="chapter" data-level="5.13.11" data-path="learning-with-target.html"><a href="learning-with-target.html#markov-process"><i class="fa fa-check"></i><b>5.13.11</b> Markov Process</a></li>
<li class="chapter" data-level="5.13.12" data-path="learning-with-target.html"><a href="learning-with-target.html#winer-process"><i class="fa fa-check"></i><b>5.13.12</b> Winer Process</a></li>
</ul></li>
<li class="chapter" data-level="5.14" data-path="learning-with-target.html"><a href="learning-with-target.html#results-diagnostics-5"><i class="fa fa-check"></i><b>5.14</b> Results diagnostics</a>
<ul>
<li class="chapter" data-level="5.14.1" data-path="learning-with-target.html"><a href="learning-with-target.html#classification-4"><i class="fa fa-check"></i><b>5.14.1</b> Classification</a>
<ul>
<li class="chapter" data-level="5.14.1.1" data-path="learning-with-target.html"><a href="learning-with-target.html#measures"><i class="fa fa-check"></i><b>5.14.1.1</b> Measures</a>
<ul>
<li class="chapter" data-level="5.14.1.1.1" data-path="learning-with-target.html"><a href="learning-with-target.html#negative-log-likelihood"><i class="fa fa-check"></i><b>5.14.1.1.1</b> Negative log likelihood</a></li>
<li class="chapter" data-level="5.14.1.1.2" data-path="learning-with-target.html"><a href="learning-with-target.html#cross-entrophy"><i class="fa fa-check"></i><b>5.14.1.1.2</b> Cross entrophy</a></li>
</ul></li>
<li class="chapter" data-level="5.14.1.2" data-path="learning-with-target.html"><a href="learning-with-target.html#scores-calibration"><i class="fa fa-check"></i><b>5.14.1.2</b> Scores calibration</a>
<ul>
<li class="chapter" data-level="5.14.1.2.1" data-path="learning-with-target.html"><a href="learning-with-target.html#problem"><i class="fa fa-check"></i><b>5.14.1.2.1</b> Problem</a></li>
<li class="chapter" data-level="5.14.1.2.2" data-path="learning-with-target.html"><a href="learning-with-target.html#kalibracja-a-problemy-konkretnych-modeli"><i class="fa fa-check"></i><b>5.14.1.2.2</b> Kalibracja a problemy konkretnych modeli</a></li>
<li class="chapter" data-level="5.14.1.2.3" data-path="learning-with-target.html"><a href="learning-with-target.html#calibration-curve-reliability-diagram"><i class="fa fa-check"></i><b>5.14.1.2.3</b> Calibration curve (reliability diagram)</a></li>
<li class="chapter" data-level="5.14.1.2.4" data-path="learning-with-target.html"><a href="learning-with-target.html#skalowanie-platta"><i class="fa fa-check"></i><b>5.14.1.2.4</b> Skalowanie Platta</a></li>
<li class="chapter" data-level="5.14.1.2.5" data-path="learning-with-target.html"><a href="learning-with-target.html#regresja-izotoniczna"><i class="fa fa-check"></i><b>5.14.1.2.5</b> Regresja izotoniczna</a></li>
<li class="chapter" data-level="5.14.1.2.6" data-path="learning-with-target.html"><a href="learning-with-target.html#calibration-in-sklearn"><i class="fa fa-check"></i><b>5.14.1.2.6</b> Calibration in <em>sklearn</em></a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5.14.2" data-path="learning-with-target.html"><a href="learning-with-target.html#regression-4"><i class="fa fa-check"></i><b>5.14.2</b> Regression</a></li>
</ul></li>
<li class="chapter" data-level="5.15" data-path="learning-with-target.html"><a href="learning-with-target.html#elements-selection-5"><i class="fa fa-check"></i><b>5.15</b> Elements selection</a>
<ul>
<li class="chapter" data-level="5.15.1" data-path="learning-with-target.html"><a href="learning-with-target.html#feature-selection"><i class="fa fa-check"></i><b>5.15.1</b> Feature selection</a>
<ul>
<li class="chapter" data-level="5.15.1.0.1" data-path="learning-with-target.html"><a href="learning-with-target.html#feature-importance"><i class="fa fa-check"></i><b>5.15.1.0.1</b> Feature Importance</a></li>
<li class="chapter" data-level="5.15.1.0.2" data-path="learning-with-target.html"><a href="learning-with-target.html#boruta"><i class="fa fa-check"></i><b>5.15.1.0.2</b> Boruta</a></li>
</ul></li>
<li class="chapter" data-level="5.15.2" data-path="learning-with-target.html"><a href="learning-with-target.html#variables-exogenity"><i class="fa fa-check"></i><b>5.15.2</b> Variables exogenity</a>
<ul>
<li class="chapter" data-level="5.15.2.1" data-path="learning-with-target.html"><a href="learning-with-target.html#granger-exogenity"><i class="fa fa-check"></i><b>5.15.2.1</b> Granger Exogenity</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5.16" data-path="learning-with-target.html"><a href="learning-with-target.html#iml-5"><i class="fa fa-check"></i><b>5.16</b> IML</a>
<ul>
<li class="chapter" data-level="5.16.1" data-path="learning-with-target.html"><a href="learning-with-target.html#partial-dependence-plot"><i class="fa fa-check"></i><b>5.16.1</b> Partial Dependence Plot</a></li>
<li class="chapter" data-level="5.16.2" data-path="learning-with-target.html"><a href="learning-with-target.html#m-plot"><i class="fa fa-check"></i><b>5.16.2</b> M-plot</a></li>
<li class="chapter" data-level="5.16.3" data-path="learning-with-target.html"><a href="learning-with-target.html#ale---accumulated-local-effects"><i class="fa fa-check"></i><b>5.16.3</b> ALE - Accumulated Local Effects</a></li>
<li class="chapter" data-level="5.16.4" data-path="learning-with-target.html"><a href="learning-with-target.html#h-statistics"><i class="fa fa-check"></i><b>5.16.4</b> H-statistics</a></li>
<li class="chapter" data-level="5.16.5" data-path="learning-with-target.html"><a href="learning-with-target.html#lime-local-surrogate"><i class="fa fa-check"></i><b>5.16.5</b> LIME (Local surrogate)</a></li>
<li class="chapter" data-level="5.16.6" data-path="learning-with-target.html"><a href="learning-with-target.html#shapley-value"><i class="fa fa-check"></i><b>5.16.6</b> Shapley value</a></li>
</ul></li>
<li class="chapter" data-level="5.17" data-path="learning-with-target.html"><a href="learning-with-target.html#by-problems-6"><i class="fa fa-check"></i><b>5.17</b> By problems</a>
<ul>
<li class="chapter" data-level="5.17.1" data-path="learning-with-target.html"><a href="learning-with-target.html#numerical"><i class="fa fa-check"></i><b>5.17.1</b> Numerical</a></li>
<li class="chapter" data-level="5.17.2" data-path="learning-with-target.html"><a href="learning-with-target.html#categorical"><i class="fa fa-check"></i><b>5.17.2</b> Categorical</a></li>
<li class="chapter" data-level="5.17.3" data-path="learning-with-target.html"><a href="learning-with-target.html#text"><i class="fa fa-check"></i><b>5.17.3</b> Text</a></li>
<li class="chapter" data-level="5.17.4" data-path="learning-with-target.html"><a href="learning-with-target.html#sound-1"><i class="fa fa-check"></i><b>5.17.4</b> Sound</a></li>
<li class="chapter" data-level="5.17.5" data-path="learning-with-target.html"><a href="learning-with-target.html#vision-1"><i class="fa fa-check"></i><b>5.17.5</b> Vision</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="learning-hybrid.html"><a href="learning-hybrid.html"><i class="fa fa-check"></i><b>6</b> LEARNING: HYBRID</a>
<ul>
<li class="chapter" data-level="6.1" data-path="learning-hybrid.html"><a href="learning-hybrid.html#introduction-7"><i class="fa fa-check"></i><b>6.1</b> Introduction</a></li>
<li class="chapter" data-level="6.2" data-path="learning-hybrid.html"><a href="learning-hybrid.html#semi-supervised-learning"><i class="fa fa-check"></i><b>6.2</b> Semi-supervised learning</a>
<ul>
<li class="chapter" data-level="6.2.1" data-path="learning-hybrid.html"><a href="learning-hybrid.html#em"><i class="fa fa-check"></i><b>6.2.1</b> EM</a></li>
<li class="chapter" data-level="6.2.2" data-path="learning-hybrid.html"><a href="learning-hybrid.html#cple"><i class="fa fa-check"></i><b>6.2.2</b> CPLE</a></li>
<li class="chapter" data-level="6.2.3" data-path="learning-hybrid.html"><a href="learning-hybrid.html#svm-and-tsvm"><i class="fa fa-check"></i><b>6.2.3</b> SVM and TSVM</a></li>
<li class="chapter" data-level="6.2.4" data-path="learning-hybrid.html"><a href="learning-hybrid.html#graphs-1"><i class="fa fa-check"></i><b>6.2.4</b> Graphs</a></li>
<li class="chapter" data-level="6.2.5" data-path="learning-hybrid.html"><a href="learning-hybrid.html#neural-networks-4"><i class="fa fa-check"></i><b>6.2.5</b> Neural Networks</a></li>
<li class="chapter" data-level="6.2.6" data-path="learning-hybrid.html"><a href="learning-hybrid.html#by-problems-7"><i class="fa fa-check"></i><b>6.2.6</b> By problems</a>
<ul>
<li class="chapter" data-level="6.2.6.1" data-path="learning-hybrid.html"><a href="learning-hybrid.html#numerical-and-categorical-1"><i class="fa fa-check"></i><b>6.2.6.1</b> Numerical and categorical</a></li>
<li class="chapter" data-level="6.2.6.2" data-path="learning-hybrid.html"><a href="learning-hybrid.html#text-data-1"><i class="fa fa-check"></i><b>6.2.6.2</b> Text data</a></li>
<li class="chapter" data-level="6.2.6.3" data-path="learning-hybrid.html"><a href="learning-hybrid.html#sound-2"><i class="fa fa-check"></i><b>6.2.6.3</b> Sound</a></li>
<li class="chapter" data-level="6.2.6.4" data-path="learning-hybrid.html"><a href="learning-hybrid.html#vision-2"><i class="fa fa-check"></i><b>6.2.6.4</b> Vision</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="learning-hybrid.html"><a href="learning-hybrid.html#self-supervised-learning"><i class="fa fa-check"></i><b>6.3</b> Self-supervised learning</a></li>
<li class="chapter" data-level="6.4" data-path="learning-hybrid.html"><a href="learning-hybrid.html#mult-instance-learning"><i class="fa fa-check"></i><b>6.4</b> Mult-instance learning</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="learning-reinforcement.html"><a href="learning-reinforcement.html"><i class="fa fa-check"></i><b>7</b> LEARNING: REINFORCEMENT</a>
<ul>
<li class="chapter" data-level="7.1" data-path="learning-reinforcement.html"><a href="learning-reinforcement.html#introduction-8"><i class="fa fa-check"></i><b>7.1</b> Introduction</a></li>
<li class="chapter" data-level="7.2" data-path="learning-reinforcement.html"><a href="learning-reinforcement.html#td"><i class="fa fa-check"></i><b>7.2</b> TD</a></li>
<li class="chapter" data-level="7.3" data-path="learning-reinforcement.html"><a href="learning-reinforcement.html#sarsa"><i class="fa fa-check"></i><b>7.3</b> SARSA</a></li>
<li class="chapter" data-level="7.4" data-path="learning-reinforcement.html"><a href="learning-reinforcement.html#q-learning"><i class="fa fa-check"></i><b>7.4</b> Q-learning</a></li>
<li class="chapter" data-level="7.5" data-path="learning-reinforcement.html"><a href="learning-reinforcement.html#by-problems-8"><i class="fa fa-check"></i><b>7.5</b> By problems</a>
<ul>
<li class="chapter" data-level="7.5.1" data-path="learning-reinforcement.html"><a href="learning-reinforcement.html#numerical-and-categorical-2"><i class="fa fa-check"></i><b>7.5.1</b> Numerical and categorical</a></li>
<li class="chapter" data-level="7.5.2" data-path="learning-reinforcement.html"><a href="learning-reinforcement.html#text-data-2"><i class="fa fa-check"></i><b>7.5.2</b> Text data</a></li>
<li class="chapter" data-level="7.5.3" data-path="learning-reinforcement.html"><a href="learning-reinforcement.html#sound-3"><i class="fa fa-check"></i><b>7.5.3</b> Sound</a></li>
<li class="chapter" data-level="7.5.4" data-path="learning-reinforcement.html"><a href="learning-reinforcement.html#vision-3"><i class="fa fa-check"></i><b>7.5.4</b> Vision</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="8" data-path="data-preprocessing.html"><a href="data-preprocessing.html"><i class="fa fa-check"></i><b>8</b> DATA PREPROCESSING</a>
<ul>
<li class="chapter" data-level="8.1" data-path="data-preprocessing.html"><a href="data-preprocessing.html#introduction-9"><i class="fa fa-check"></i><b>8.1</b> Introduction</a></li>
<li class="chapter" data-level="8.2" data-path="data-preprocessing.html"><a href="data-preprocessing.html#variables-tranformations"><i class="fa fa-check"></i><b>8.2</b> Variables tranformations</a>
<ul>
<li class="chapter" data-level="8.2.1" data-path="data-preprocessing.html"><a href="data-preprocessing.html#discretization"><i class="fa fa-check"></i><b>8.2.1</b> discretization</a></li>
<li class="chapter" data-level="8.2.2" data-path="data-preprocessing.html"><a href="data-preprocessing.html#numeric-variable-continuous-tranformations"><i class="fa fa-check"></i><b>8.2.2</b> numeric variable continuous tranformations</a></li>
<li class="chapter" data-level="8.2.3" data-path="data-preprocessing.html"><a href="data-preprocessing.html#nominal-variables-tranformations"><i class="fa fa-check"></i><b>8.2.3</b> nominal variables tranformations</a>
<ul>
<li class="chapter" data-level="8.2.3.1" data-path="data-preprocessing.html"><a href="data-preprocessing.html#encoding"><i class="fa fa-check"></i><b>8.2.3.1</b> encoding</a>
<ul>
<li class="chapter" data-level="8.2.3.1.1" data-path="data-preprocessing.html"><a href="data-preprocessing.html#one-hot"><i class="fa fa-check"></i><b>8.2.3.1.1</b> one-hot</a></li>
<li class="chapter" data-level="8.2.3.1.2" data-path="data-preprocessing.html"><a href="data-preprocessing.html#embedding-1"><i class="fa fa-check"></i><b>8.2.3.1.2</b> embedding</a></li>
</ul></li>
<li class="chapter" data-level="8.2.3.2" data-path="data-preprocessing.html"><a href="data-preprocessing.html#other-1"><i class="fa fa-check"></i><b>8.2.3.2</b> other</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="8.3" data-path="data-preprocessing.html"><a href="data-preprocessing.html#data-problems"><i class="fa fa-check"></i><b>8.3</b> Data Problems</a>
<ul>
<li class="chapter" data-level="8.3.1" data-path="data-preprocessing.html"><a href="data-preprocessing.html#numeric-and-categorical"><i class="fa fa-check"></i><b>8.3.1</b> Numeric and categorical</a>
<ul>
<li class="chapter" data-level="8.3.1.1" data-path="data-preprocessing.html"><a href="data-preprocessing.html#extreme-values"><i class="fa fa-check"></i><b>8.3.1.1</b> Extreme values</a>
<ul>
<li class="chapter" data-level="8.3.1.1.1" data-path="data-preprocessing.html"><a href="data-preprocessing.html#lof-local-outlier-factor"><i class="fa fa-check"></i><b>8.3.1.1.1</b> LOF (local outlier factor)</a></li>
<li class="chapter" data-level="8.3.1.1.2" data-path="data-preprocessing.html"><a href="data-preprocessing.html#angle"><i class="fa fa-check"></i><b>8.3.1.1.2</b> Angle</a></li>
<li class="chapter" data-level="8.3.1.1.3" data-path="data-preprocessing.html"><a href="data-preprocessing.html#knn"><i class="fa fa-check"></i><b>8.3.1.1.3</b> knn</a></li>
<li class="chapter" data-level="8.3.1.1.4" data-path="data-preprocessing.html"><a href="data-preprocessing.html#one-class-svm"><i class="fa fa-check"></i><b>8.3.1.1.4</b> One class SVM</a></li>
<li class="chapter" data-level="8.3.1.1.5" data-path="data-preprocessing.html"><a href="data-preprocessing.html#z-score"><i class="fa fa-check"></i><b>8.3.1.1.5</b> z-score</a></li>
<li class="chapter" data-level="8.3.1.1.6" data-path="data-preprocessing.html"><a href="data-preprocessing.html#pca-1"><i class="fa fa-check"></i><b>8.3.1.1.6</b> PCA</a></li>
<li class="chapter" data-level="8.3.1.1.7" data-path="data-preprocessing.html"><a href="data-preprocessing.html#autoencoders-1"><i class="fa fa-check"></i><b>8.3.1.1.7</b> Autoencoders</a></li>
<li class="chapter" data-level="8.3.1.1.8" data-path="data-preprocessing.html"><a href="data-preprocessing.html#elliptic-envelope"><i class="fa fa-check"></i><b>8.3.1.1.8</b> <strong>Elliptic Envelope</strong></a></li>
<li class="chapter" data-level="8.3.1.1.9" data-path="data-preprocessing.html"><a href="data-preprocessing.html#copod"><i class="fa fa-check"></i><b>8.3.1.1.9</b> COPOD</a></li>
<li class="chapter" data-level="8.3.1.1.10" data-path="data-preprocessing.html"><a href="data-preprocessing.html#isolation-forest"><i class="fa fa-check"></i><b>8.3.1.1.10</b> Isolation Forest</a></li>
</ul></li>
<li class="chapter" data-level="8.3.1.2" data-path="data-preprocessing.html"><a href="data-preprocessing.html#missing-values"><i class="fa fa-check"></i><b>8.3.1.2</b> Missing values</a></li>
<li class="chapter" data-level="8.3.1.3" data-path="data-preprocessing.html"><a href="data-preprocessing.html#untipical-distributions-for-example-copula-models-kernel-estimators-logaritmic-transofmations-ect.-mixed-distributions"><i class="fa fa-check"></i><b>8.3.1.3</b> Untipical distributions (for example copula models, kernel estimators, logaritmic transofmations ect., mixed distributions)</a></li>
<li class="chapter" data-level="8.3.1.4" data-path="data-preprocessing.html"><a href="data-preprocessing.html#censoredtruncated-data"><i class="fa fa-check"></i><b>8.3.1.4</b> Censored/truncated data</a></li>
<li class="chapter" data-level="8.3.1.5" data-path="data-preprocessing.html"><a href="data-preprocessing.html#aggregated-date-decomposition"><i class="fa fa-check"></i><b>8.3.1.5</b> Aggregated date (decomposition)</a></li>
<li class="chapter" data-level="8.3.1.6" data-path="data-preprocessing.html"><a href="data-preprocessing.html#meassurement-error-for-example-kalman-filter-model"><i class="fa fa-check"></i><b>8.3.1.6</b> Meassurement error (for example Kalman filter model)</a></li>
<li class="chapter" data-level="8.3.1.7" data-path="data-preprocessing.html"><a href="data-preprocessing.html#granularity-of-data"><i class="fa fa-check"></i><b>8.3.1.7</b> Granularity of data</a></li>
<li class="chapter" data-level="8.3.1.8" data-path="data-preprocessing.html"><a href="data-preprocessing.html#imbalanced-categories"><i class="fa fa-check"></i><b>8.3.1.8</b> Imbalanced categories</a>
<ul>
<li class="chapter" data-level="8.3.1.8.1" data-path="data-preprocessing.html"><a href="data-preprocessing.html#non-synthetic-methods"><i class="fa fa-check"></i><b>8.3.1.8.1</b> Non synthetic methods</a></li>
<li class="chapter" data-level="8.3.1.8.2" data-path="data-preprocessing.html"><a href="data-preprocessing.html#synthetic-methods"><i class="fa fa-check"></i><b>8.3.1.8.2</b> Synthetic methods</a></li>
</ul></li>
<li class="chapter" data-level="8.3.1.9" data-path="data-preprocessing.html"><a href="data-preprocessing.html#imbalanced-values"><i class="fa fa-check"></i><b>8.3.1.9</b> Imbalanced values</a></li>
<li class="chapter" data-level="8.3.1.10" data-path="data-preprocessing.html"><a href="data-preprocessing.html#small-samples-problem"><i class="fa fa-check"></i><b>8.3.1.10</b> Small samples problem</a></li>
</ul></li>
<li class="chapter" data-level="8.3.2" data-path="data-preprocessing.html"><a href="data-preprocessing.html#text-1"><i class="fa fa-check"></i><b>8.3.2</b> Text</a>
<ul>
<li class="chapter" data-level="8.3.2.1" data-path="data-preprocessing.html"><a href="data-preprocessing.html#tf-idf"><i class="fa fa-check"></i><b>8.3.2.1</b> TF-IDF</a></li>
</ul></li>
<li class="chapter" data-level="8.3.3" data-path="data-preprocessing.html"><a href="data-preprocessing.html#visual"><i class="fa fa-check"></i><b>8.3.3</b> Visual</a>
<ul>
<li class="chapter" data-level="8.3.3.1" data-path="data-preprocessing.html"><a href="data-preprocessing.html#wykrywanie-krewedzi"><i class="fa fa-check"></i><b>8.3.3.1</b> Wykrywanie krewedzi</a>
<ul>
<li class="chapter" data-level="8.3.3.1.1" data-path="data-preprocessing.html"><a href="data-preprocessing.html#hough"><i class="fa fa-check"></i><b>8.3.3.1.1</b> Hough</a></li>
</ul></li>
<li class="chapter" data-level="8.3.3.2" data-path="data-preprocessing.html"><a href="data-preprocessing.html#wykrywanie-elementów"><i class="fa fa-check"></i><b>8.3.3.2</b> Wykrywanie elementów</a>
<ul>
<li class="chapter" data-level="8.3.3.2.1" data-path="data-preprocessing.html"><a href="data-preprocessing.html#haar-cascade"><i class="fa fa-check"></i><b>8.3.3.2.1</b> Haar Cascade</a></li>
<li class="chapter" data-level="8.3.3.2.2" data-path="data-preprocessing.html"><a href="data-preprocessing.html#orb"><i class="fa fa-check"></i><b>8.3.3.2.2</b> ORB</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="8.3.4" data-path="data-preprocessing.html"><a href="data-preprocessing.html#sound-4"><i class="fa fa-check"></i><b>8.3.4</b> Sound</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="9" data-path="other-models-and-problems.html"><a href="other-models-and-problems.html"><i class="fa fa-check"></i><b>9</b> OTHER MODELS AND PROBLEMS</a>
<ul>
<li class="chapter" data-level="9.1" data-path="other-models-and-problems.html"><a href="other-models-and-problems.html#hyperparameters-tunning"><i class="fa fa-check"></i><b>9.1</b> Hyperparameters tunning</a>
<ul>
<li class="chapter" data-level="9.1.1" data-path="other-models-and-problems.html"><a href="other-models-and-problems.html#bayesian-methods"><i class="fa fa-check"></i><b>9.1.1</b> Bayesian methods</a>
<ul>
<li class="chapter" data-level="9.1.1.1" data-path="other-models-and-problems.html"><a href="other-models-and-problems.html#tree-structured-parzen-estimator-tpe"><i class="fa fa-check"></i><b>9.1.1.1</b> <strong>Tree-structured Parzen Estimator (TPE)</strong></a></li>
</ul></li>
<li class="chapter" data-level="9.1.2" data-path="other-models-and-problems.html"><a href="other-models-and-problems.html#successive-halving"><i class="fa fa-check"></i><b>9.1.2</b> <strong>Successive Halving</strong></a></li>
<li class="chapter" data-level="9.1.3" data-path="other-models-and-problems.html"><a href="other-models-and-problems.html#hyperband"><i class="fa fa-check"></i><b>9.1.3</b> Hyperband</a></li>
<li class="chapter" data-level="9.1.4" data-path="other-models-and-problems.html"><a href="other-models-and-problems.html#fabolas"><i class="fa fa-check"></i><b>9.1.4</b> <strong>Fabolas</strong></a></li>
<li class="chapter" data-level="9.1.5" data-path="other-models-and-problems.html"><a href="other-models-and-problems.html#bohb"><i class="fa fa-check"></i><b>9.1.5</b> <strong>BOHB</strong></a></li>
<li class="chapter" data-level="9.1.6" data-path="other-models-and-problems.html"><a href="other-models-and-problems.html#population-based-training-ptb"><i class="fa fa-check"></i><b>9.1.6</b> <strong>Population-based training (PTB)</strong></a></li>
</ul></li>
<li class="chapter" data-level="9.2" data-path="other-models-and-problems.html"><a href="other-models-and-problems.html#social-network"><i class="fa fa-check"></i><b>9.2</b> Social Network</a></li>
<li class="chapter" data-level="9.3" data-path="other-models-and-problems.html"><a href="other-models-and-problems.html#queuing-kolejki"><i class="fa fa-check"></i><b>9.3</b> Queuing (kolejki)</a></li>
<li class="chapter" data-level="9.4" data-path="other-models-and-problems.html"><a href="other-models-and-problems.html#spacial-model-modele-przestrzenne"><i class="fa fa-check"></i><b>9.4</b> Spacial model (modele przestrzenne)</a></li>
<li class="chapter" data-level="9.5" data-path="other-models-and-problems.html"><a href="other-models-and-problems.html#six-sigma-process-quality-control-quality-control-charts"><i class="fa fa-check"></i><b>9.5</b> SIX-Sigma (process quality control, quality control charts)</a></li>
<li class="chapter" data-level="9.6" data-path="other-models-and-problems.html"><a href="other-models-and-problems.html#process-analysis-analiza-procesu"><i class="fa fa-check"></i><b>9.6</b> Process Analysis (Analiza procesu)</a></li>
<li class="chapter" data-level="9.7" data-path="other-models-and-problems.html"><a href="other-models-and-problems.html#reliability-and-item-analysis-analiza-rzetelności"><i class="fa fa-check"></i><b>9.7</b> Reliability and Item Analysis (Analiza rzetelności)</a></li>
<li class="chapter" data-level="9.8" data-path="other-models-and-problems.html"><a href="other-models-and-problems.html#experimentla-design-planowanie-doświadczeń"><i class="fa fa-check"></i><b>9.8</b> Experimentla design (Planowanie doświadczeń)</a></li>
<li class="chapter" data-level="9.9" data-path="other-models-and-problems.html"><a href="other-models-and-problems.html#sequential-analysis"><i class="fa fa-check"></i><b>9.9</b> Sequential analysis</a></li>
<li class="chapter" data-level="9.10" data-path="other-models-and-problems.html"><a href="other-models-and-problems.html#logic-programming-programowanie-logiczne"><i class="fa fa-check"></i><b>9.10</b> Logic programming (programowanie logiczne)</a></li>
<li class="chapter" data-level="9.11" data-path="other-models-and-problems.html"><a href="other-models-and-problems.html#financial-models"><i class="fa fa-check"></i><b>9.11</b> Financial models</a>
<ul>
<li class="chapter" data-level="9.11.1" data-path="other-models-and-problems.html"><a href="other-models-and-problems.html#distance-to-default"><i class="fa fa-check"></i><b>9.11.1</b> Distance to default</a></li>
<li class="chapter" data-level="9.11.2" data-path="other-models-and-problems.html"><a href="other-models-and-problems.html#copula-methods-kopuły"><i class="fa fa-check"></i><b>9.11.2</b> Copula methods (kopuły)</a></li>
<li class="chapter" data-level="9.11.3" data-path="other-models-and-problems.html"><a href="other-models-and-problems.html#black-scholes"><i class="fa fa-check"></i><b>9.11.3</b> Black Scholes</a></li>
<li class="chapter" data-level="9.11.4" data-path="other-models-and-problems.html"><a href="other-models-and-problems.html#vasicek"><i class="fa fa-check"></i><b>9.11.4</b> Vasicek</a></li>
<li class="chapter" data-level="9.11.5" data-path="other-models-and-problems.html"><a href="other-models-and-problems.html#markovitz"><i class="fa fa-check"></i><b>9.11.5</b> Markovitz</a></li>
<li class="chapter" data-level="9.11.6" data-path="other-models-and-problems.html"><a href="other-models-and-problems.html#kmv"><i class="fa fa-check"></i><b>9.11.6</b> KMV</a></li>
<li class="chapter" data-level="9.11.7" data-path="other-models-and-problems.html"><a href="other-models-and-problems.html#credit-metrics"><i class="fa fa-check"></i><b>9.11.7</b> Credit Metrics</a></li>
<li class="chapter" data-level="9.11.8" data-path="other-models-and-problems.html"><a href="other-models-and-problems.html#credit-plus"><i class="fa fa-check"></i><b>9.11.8</b> Credit Plus</a></li>
<li class="chapter" data-level="9.11.9" data-path="other-models-and-problems.html"><a href="other-models-and-problems.html#z-scores"><i class="fa fa-check"></i><b>9.11.9</b> z-scores</a></li>
<li class="chapter" data-level="9.11.10" data-path="other-models-and-problems.html"><a href="other-models-and-problems.html#capm"><i class="fa fa-check"></i><b>9.11.10</b> CAPM</a></li>
<li class="chapter" data-level="9.11.11" data-path="other-models-and-problems.html"><a href="other-models-and-problems.html#var---value-at-risk"><i class="fa fa-check"></i><b>9.11.11</b> VaR - Value at risk</a></li>
<li class="chapter" data-level="9.11.12" data-path="other-models-and-problems.html"><a href="other-models-and-problems.html#cva"><i class="fa fa-check"></i><b>9.11.12</b> CVA</a></li>
<li class="chapter" data-level="9.11.13" data-path="other-models-and-problems.html"><a href="other-models-and-problems.html#acturial-models"><i class="fa fa-check"></i><b>9.11.13</b> Acturial models</a></li>
</ul></li>
<li class="chapter" data-level="9.12" data-path="other-models-and-problems.html"><a href="other-models-and-problems.html#biologicalmedical-models"><i class="fa fa-check"></i><b>9.12</b> Biological/Medical Models</a></li>
<li class="chapter" data-level="9.13" data-path="other-models-and-problems.html"><a href="other-models-and-problems.html#case-studies"><i class="fa fa-check"></i><b>9.13</b> Case Studies</a>
<ul>
<li class="chapter" data-level="9.13.1" data-path="other-models-and-problems.html"><a href="other-models-and-problems.html#score-cards"><i class="fa fa-check"></i><b>9.13.1</b> Score cards</a></li>
<li class="chapter" data-level="9.13.2" data-path="other-models-and-problems.html"><a href="other-models-and-problems.html#pd-models"><i class="fa fa-check"></i><b>9.13.2</b> PD models</a></li>
<li class="chapter" data-level="9.13.3" data-path="other-models-and-problems.html"><a href="other-models-and-problems.html#lgd-models"><i class="fa fa-check"></i><b>9.13.3</b> LGD models</a></li>
<li class="chapter" data-level="9.13.4" data-path="other-models-and-problems.html"><a href="other-models-and-problems.html#churn-models"><i class="fa fa-check"></i><b>9.13.4</b> Churn models</a></li>
<li class="chapter" data-level="9.13.5" data-path="other-models-and-problems.html"><a href="other-models-and-problems.html#icaap"><i class="fa fa-check"></i><b>9.13.5</b> ICAAP</a></li>
<li class="chapter" data-level="9.13.6" data-path="other-models-and-problems.html"><a href="other-models-and-problems.html#ama"><i class="fa fa-check"></i><b>9.13.6</b> AMA</a></li>
<li class="chapter" data-level="9.13.7" data-path="other-models-and-problems.html"><a href="other-models-and-problems.html#stress-tests"><i class="fa fa-check"></i><b>9.13.7</b> Stress tests</a></li>
<li class="chapter" data-level="9.13.8" data-path="other-models-and-problems.html"><a href="other-models-and-problems.html#master-scale"><i class="fa fa-check"></i><b>9.13.8</b> Master Scale</a></li>
<li class="chapter" data-level="9.13.9" data-path="other-models-and-problems.html"><a href="other-models-and-problems.html#model-summer"><i class="fa fa-check"></i><b>9.13.9</b> Model summer</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="10" data-path="appendicies.html"><a href="appendicies.html"><i class="fa fa-check"></i><b>10</b> APPENDICIES</a>
<ul>
<li class="chapter" data-level="10.1" data-path="appendicies.html"><a href="appendicies.html#appendix-a-index-of-statistical-test"><i class="fa fa-check"></i><b>10.1</b> Appendix A INDEX OF STATISTICAL TEST</a></li>
<li class="chapter" data-level="10.2" data-path="appendicies.html"><a href="appendicies.html#appendix-b-most-important-theorems-in-statistics-and-probability-calculus"><i class="fa fa-check"></i><b>10.2</b> Appendix B Most important theorems in Statistics and probability calculus</a>
<ul>
<li class="chapter" data-level="10.2.1" data-path="appendicies.html"><a href="appendicies.html#central-limit"><i class="fa fa-check"></i><b>10.2.1</b> Central Limit</a></li>
<li class="chapter" data-level="10.2.2" data-path="appendicies.html"><a href="appendicies.html#fisher-tippett-gnedenko"><i class="fa fa-check"></i><b>10.2.2</b> Fisher-Tippett-Gnedenko</a></li>
</ul></li>
<li class="chapter" data-level="10.3" data-path="appendicies.html"><a href="appendicies.html#appendix-c-different-entries"><i class="fa fa-check"></i><b>10.3</b> Appendix C Different entries</a>
<ul>
<li class="chapter" data-level="10.3.1" data-path="appendicies.html"><a href="appendicies.html#out-of-bag-error-1"><i class="fa fa-check"></i><b>10.3.1</b> out-of-bag error</a></li>
<li class="chapter" data-level="10.3.2" data-path="appendicies.html"><a href="appendicies.html#hyperparameters"><i class="fa fa-check"></i><b>10.3.2</b> hyperparameters</a></li>
<li class="chapter" data-level="10.3.3" data-path="appendicies.html"><a href="appendicies.html#information-leakage"><i class="fa fa-check"></i><b>10.3.3</b> information leakage</a></li>
<li class="chapter" data-level="10.3.4" data-path="appendicies.html"><a href="appendicies.html#apriori-vs-aposteriori"><i class="fa fa-check"></i><b>10.3.4</b> apriori vs aposteriori</a></li>
<li class="chapter" data-level="10.3.5" data-path="appendicies.html"><a href="appendicies.html#colaborative-filtering"><i class="fa fa-check"></i><b>10.3.5</b> colaborative filtering</a></li>
<li class="chapter" data-level="10.3.6" data-path="appendicies.html"><a href="appendicies.html#embedding-2"><i class="fa fa-check"></i><b>10.3.6</b> embedding</a></li>
</ul></li>
<li class="chapter" data-level="10.4" data-path="appendicies.html"><a href="appendicies.html#appendix-d-dictionary-polish---english"><i class="fa fa-check"></i><b>10.4</b> Appendix D DICTIONARY POLISH - ENGLISH</a></li>
<li class="chapter" data-level="10.5" data-path="appendicies.html"><a href="appendicies.html#links---important"><i class="fa fa-check"></i><b>10.5</b> Links - important</a>
<ul>
<li class="chapter" data-level="10.5.1" data-path="appendicies.html"><a href="appendicies.html#books"><i class="fa fa-check"></i><b>10.5.1</b> books</a></li>
<li class="chapter" data-level="10.5.2" data-path="appendicies.html"><a href="appendicies.html#strony"><i class="fa fa-check"></i><b>10.5.2</b> strony</a></li>
<li class="chapter" data-level="10.5.3" data-path="appendicies.html"><a href="appendicies.html#youtube"><i class="fa fa-check"></i><b>10.5.3</b> youtube</a></li>
<li class="chapter" data-level="10.5.4" data-path="appendicies.html"><a href="appendicies.html#narzedzia"><i class="fa fa-check"></i><b>10.5.4</b> narzedzia</a></li>
</ul></li>
<li class="chapter" data-level="10.6" data-path="appendicies.html"><a href="appendicies.html#ściąga-latex"><i class="fa fa-check"></i><b>10.6</b> <strong>Ściąga latex</strong></a></li>
<li class="chapter" data-level="10.7" data-path="appendicies.html"><a href="appendicies.html#courses-notes"><i class="fa fa-check"></i><b>10.7</b> Courses notes</a>
<ul>
<li class="chapter" data-level="10.7.1" data-path="appendicies.html"><a href="appendicies.html#udacity"><i class="fa fa-check"></i><b>10.7.1</b> Udacity</a></li>
</ul></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Data Science Book</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="learning-with-target" class="section level1" number="5">
<h1><span class="header-section-number">Chapter 5</span> LEARNING: WITH TARGET</h1>
<div id="introduction-5" class="section level2" number="5.1">
<h2><span class="header-section-number">5.1</span> Introduction</h2>
<div id="classification" class="section level3" number="5.1.1">
<h3><span class="header-section-number">5.1.1</span> Classification</h3>
</div>
<div id="regression" class="section level3" number="5.1.2">
<h3><span class="header-section-number">5.1.2</span> Regression</h3>
</div>
</div>
<div id="econometrical-regression" class="section level2" number="5.2">
<h2><span class="header-section-number">5.2</span> Econometrical regression</h2>
<div id="basic-regression" class="section level3" number="5.2.1">
<h3><span class="header-section-number">5.2.1</span> Basic regression</h3>
</div>
<div id="basic-dynamic-model" class="section level3" number="5.2.2">
<h3><span class="header-section-number">5.2.2</span> Basic dynamic model</h3>
</div>
<div id="generalisations-and-constrains" class="section level3" number="5.2.3">
<h3><span class="header-section-number">5.2.3</span> Generalisations and constrains</h3>
<div id="glm" class="section level4" number="5.2.3.1">
<h4><span class="header-section-number">5.2.3.1</span> GLM</h4>
<p>Szczegółowo o założeniach i problemach:
<a href="https://towardsdatascience.com/generalized-linear-models-9ec4dfe3dc3f">link</a></p>
<p>Interpretacja parametrów w modelach GLM:
<a href="http://environmentalcomputing.net/interpreting-coefficients-in-glms/">link</a></p>
<p>Założenia różnych modeli (źrodło:
<a href="https://www.casact.org/sites/default/files/presentation/rpm_2009_handouts_havlicek.pdf">link</a>)</p>
<p>Rodzaje reszt w modelach GLM:
<a href="https://www.datascienceblog.net/post/machine-learning/interpreting_generalized_linear_models/">link</a></p>
<p>Podstawowe cechy modeli regresyjnych:</p>
<ul>
<li><p>Traditional Linear Model</p>
<ul>
<li><p>response variable: a continuous variable</p></li>
<li><p>error distribution: normal</p></li>
<li><p>link function: identity</p></li>
</ul></li>
<li><p>Logistic Regression</p>
<ul>
<li><p>response variable: a proportion</p></li>
<li><p>error distribution: binomial</p></li>
<li><p>link function: logit</p></li>
</ul></li>
<li><p>Poisson Regression in Log Linear Model</p>
<ul>
<li><p>response variable: a count</p></li>
<li><p>error distribution: Poisson</p></li>
<li><p>link function: log</p></li>
</ul></li>
<li><p>Gamma Model with Log Link</p>
<ul>
<li><p>response variable: a positive, continuous variable</p></li>
<li><p>error distribution: gamma</p></li>
<li><p>link function: log</p></li>
</ul></li>
</ul>
<p>W modelach GLM nie zapisuje się składnika losowego bo:</p>
<p>model modeluje nie wartość y ale parametr (np. p jako prawdopodobieństwo
w rozkładzie Bernulliego). Reszty możemy sobie dodatkowo doliczyć.</p>
<div id="logisti-regression" class="section level5" number="5.2.3.1.1">
<h5><span class="header-section-number">5.2.3.1.1</span> logisti regression</h5>
<p>W przypadku regresji logistycznej parametry mają chyba rozkład normalny.</p>
<p>Czym są reszty w regresji logistycznej:
<a href="https://stats.stackexchange.com/questions/1432/what-do-the-residuals-in-a-logistic-regression-mean">link</a></p>
<p>Dlaczego nie ma <em>error term</em>:
<a href="https://stats.stackexchange.com/questions/124818/logistic-regression-error-term-and-its-distribution">link</a>,
<a href="https://www.theanalysisfactor.com/link-functions-and-errors-in-logistic-regression/">link</a></p>
</div>
</div>
</div>
<div id="bayesian-inference" class="section level3" number="5.2.4">
<h3><span class="header-section-number">5.2.4</span> Bayesian inference</h3>
</div>
<div id="multivariate-models" class="section level3" number="5.2.5">
<h3><span class="header-section-number">5.2.5</span> Multivariate models</h3>
</div>
<div id="models-with-effects" class="section level3" number="5.2.6">
<h3><span class="header-section-number">5.2.6</span> Models with effects</h3>
<p>Załóżmy, że mamy model regresji liniowej ze zmiennymi przełącznikowymi
(zmienne zero-jeden). Te zmienne “przełączają” wartość wyrazu wolnego
pomiędzy różnymi podzbiorami obserwacji. Podobne przełączniki możemy
mieć na parametrach kierunkowych. Jeżeli założymy że te zróżnicowane
efekty nie są losowe, to mamy model efektami stałymi. Zazwyczaj można je
estymować MKN. Jeżeli założymy że te przełączniki są losowane z jakiegoś
rozkładu to mamy efekty losowe. Wtedy używamy innych technik estymacji.
Są też modele gdzie mamy efekty mieszane, czyli zarówno losowe jak i
nielosowe. Warto dodać że efekty można też zagnieżdżać.</p>
<p>To czy efekty są losowe czy nielosowe można próbować zweryfikować
<strong>testem</strong> <strong>Hausman-a</strong>.</p>
<p><strong>Modele panelowe</strong></p>
<p>Modele panelowe są szczególnym przypadkiem modelu z efektami. Mamy tutaj
dane przekrojowa w czasie. Dla badanych obiektów (np. przedsiębiorstw),
mamy szeregi czasowe. Więc mamy wiele obserwacji na obiekt. Przełączniki
działając miedzy obiektami. Na każdy przełącznik mamy kilka obserwacji
więc jesteśmy w stanie je wyestymować.</p>
<p>Modele panelowe występują w wersji dynamicznej (zmiennymi objaśniającymi
jest opóźniona zmienna objaśniana) oraz w wersji wielorównaniowej).</p>
</div>
<div id="nonparametric-regression" class="section level3" number="5.2.7">
<h3><span class="header-section-number">5.2.7</span> Nonparametric regression</h3>
<div id="mars-splines" class="section level4" number="5.2.7.1">
<h4><span class="header-section-number">5.2.7.1</span> MARS Splines</h4>
<p>Mars jest techniką jednowymiarową (ma jedenowymiarowy output). Jego
uogólnieniem wulowymiarowym (wielowymiarowy output) jest Polymars.
Załóżmy że mamy jedną zmienną predykcyjną. MARS polega na tym aby
zmienną x podzielić na segmenty i następnie w ramach segmentów poprzez
np. Metodą Najmniejszych Kwadradów dopasować wielomian. W najprostszym
przypadku może to być stała (wtedy dostaniemy schodki). Punkty
rodzielające segmenty to węzły (knots). W przypadki wielomianów wyższych
stopni chcemy żeby krzywe co najmniej się łączyły (regresje liniowe) w
węzłąch <span class="math inline">\(f_k(x_k)=f_{k+1}(x_k)\)</span>, albo jeżeli to możliwe żeby w węzłach
była zachowana ciągłość. Ogólniej mówiąc na wielomian stopnia M nakłada
się warunek ciągłości w węzłach stopnia M-1 (czyli pochodne do stopnia
M-1 muszą być równe w węźle dla sąsiadujących segmentów). Aby to
osiągnąć na algorytm dopasowujący wielomiany (np. MKN) trzeba nałożyć
dodatkowe warunki ograniczające.</p>
<p>W modelu musimy zatem z góry ustalić:</p>
<ul>
<li><p>ilość węzłów i ich położenie</p></li>
<li><p>stopień wielomianu</p></li>
</ul>
</div>
</div>
<div id="pros" class="section level3" number="5.2.8">
<h3><span class="header-section-number">5.2.8</span> Pros</h3>
<ul>
<li><p>Works well with a large number of predictor variables</p></li>
<li><p>Automatically detects interactions between variables</p></li>
<li><p>It is an efficient and fast algorithm, despite its complexity</p></li>
<li><p>Robust to outliers<br />
<br />
</p></li>
</ul>
</div>
<div id="cons" class="section level3" number="5.2.9">
<h3><span class="header-section-number">5.2.9</span> Cons</h3>
<ul>
<li><p>Susceptible to overfitting</p></li>
<li><p>More difficult to understand and interpret than other methods</p></li>
<li><p>Not good with missing data</p></li>
</ul>
<div id="isotonic" class="section level4" number="5.2.9.1">
<h4><span class="header-section-number">5.2.9.1</span> Isotonic</h4>
<p>Linki:</p>
<p>Przykład numeryczny z algorytmem PAVA: <a href="http://idss.cs.put.poznan.pl/site/fileadmin/seminaria/2016/2017-idss.pdf">Online isotonic regression
Wojciech
Kotłowski</a></p>
<p>Opis algorytmu:
<a href="https://www.analyticsvidhya.com/blog/2021/02/isotonic-regression-and-the-pava-algorithm/">analyticsvidhya</a></p>
<p>Staramy się zminimalizować:</p>
<p><span class="math display">\[
\text{argmin}_x |y - x |^2 \\\text{subject to } x_0 \leq x_1 \leq \cdots \leq x_n
\]</span></p>
<p>Najczęściej osiąga się to dzięki algorytmowi PAVA (Pool Adjacent
Violators Algorithm).</p>
<p>Wizualizacja działania algorytmu PAVA:</p>
<p><img src="03_TARGET/figures/isotonic_regression.gif" /></p>
</div>
</div>
<div id="other-regression-models" class="section level3" number="5.2.10">
<h3><span class="header-section-number">5.2.10</span> Other regression models</h3>
<div id="canonical-analysis" class="section level4" number="5.2.10.1">
<h4><span class="header-section-number">5.2.10.1</span> Canonical analysis</h4>
</div>
<div id="anova-manova-ancova" class="section level4" number="5.2.10.2">
<h4><span class="header-section-number">5.2.10.2</span> ANOVA MANOVA ANCOVA</h4>
</div>
</div>
</div>
<div id="lda-qda" class="section level2" number="5.3">
<h2><span class="header-section-number">5.3</span> LDA &amp; QDA</h2>
</div>
<div id="bayesian-models" class="section level2" number="5.4">
<h2><span class="header-section-number">5.4</span> Bayesian models</h2>
</div>
<div id="trees" class="section level2" number="5.5">
<h2><span class="header-section-number">5.5</span> Trees</h2>
<p>Drzewo jest przykładem algorytmu zachłannego (greedy)</p>
<p><strong>Dlaczego w praktyce używa się tylko drzew binarnych:</strong></p>
<p><a href="https://stats.stackexchange.com/questions/12187/are-decision-trees-almost-always-binary-trees">(link:
stack_change)</a></p>
<p>The number of possible splits goes up exponentially. If you are
splitting on a continuous variable that has 1000 distinct values, there
are 999 binary splits, but 999*998 trinary splits. There are:</p>
<p><span class="math inline">\(\binom{1000-1}{3-1} = 999*998/2\)</span></p>
<p>splits, actually.</p>
<div id="pros-1" class="section level3" number="5.5.1">
<h3><span class="header-section-number">5.5.1</span> pros</h3>
<ul>
<li><p>Nie trzeba preprocesować danych. Nie trzeba normalizować zmiennych
ciągłych. Zmiennych jakościowych nie trzeba rekodować.</p></li>
<li><p>możliwość pracy z danymi jakościowymi i ilościowymi</p></li>
<li><p>są nieparametryczne. Nie mają założeń o rozkładach</p></li>
<li><p>nie ma problemu z brakami danych. Przy analizie zmiennej na splicie
braki są prostu pomijane.</p></li>
<li><p>łatwa interpretacja</p></li>
<li><p>szybkie wyliczenie predykcji przez niską złożoność obliczeniową
O(log(m)).</p></li>
<li><p>Tak naprawdę same przeprowadzają selekcje cech (feature selection).</p></li>
</ul>
</div>
<div id="cons-1" class="section level3" number="5.5.2">
<h3><span class="header-section-number">5.5.2</span> cons</h3>
<ul>
<li><p>Łatwo model przetrenować. Są niestabilne. Małe zmiany w danych
generują mocno różniące się drzewa. Przez te problemy występuje duża
wariancja modelu i słabe uogólnianie.</p></li>
<li><p>są algorytmem zachłannym więc nie dają gwarancji znalezienia optimum
globalnego.</p></li>
<li><p>dosyć długo czas estymacji modelu</p></li>
<li><p>wrażliwość na rotacje danych <span class="citation">(<a href="appendicies.html#ref-Geron2018" role="doc-biblioref">Geron 2018</a>)</span> s. 184.</p></li>
</ul>
<p><a href="https://dhirajkumarblog.medium.com/top-5-advantages-and-disadvantages-of-decision-tree-algorithm-428ebd199d9a">dhirajkumarblog.medium</a></p>
</div>
<div id="classification-1" class="section level3" number="5.5.3">
<h3><span class="header-section-number">5.5.3</span> Classification</h3>
</div>
<div id="regression-1" class="section level3" number="5.5.4">
<h3><span class="header-section-number">5.5.4</span> Regression</h3>
</div>
</div>
<div id="svm" class="section level2" number="5.6">
<h2><span class="header-section-number">5.6</span> SVM</h2>
<div id="classification-2" class="section level3" number="5.6.1">
<h3><span class="header-section-number">5.6.1</span> Classification</h3>
<p><strong>Linki</strong>:</p>
<p>Fajny opis na “kapitał ludzki”: <a href="https://brain.fuw.edu.pl/edu/index.php/Uczenie_maszynowe_i_sztuczne_sieci_neuronowe/Wyk%C5%82ad_8">czesc
1</a>
<a href="https://brain.fuw.edu.pl/edu/index.php/Uczenie_maszynowe_i_sztuczne_sieci_neuronowe/Wyk%C5%82ad_9#:~:text=O(m).-,Twierdzenie%20Mercera,miar%C4%85%20podobie%C5%84stwa%20pomi%C4%99dzy%20wektorami%20cech.&amp;text=Id%C4%85c%20tym%20tropem%20mo%C5%BCemy%20zapostulowa%C4%87,stanowi%C4%87%20miar%C4%99%20podobie%C5%84stwa%20mi%C4%99dzy%20wektorami.">czesc
2</a></p>
<p>Załóżmy że mamy 2-wymiarowe dane, które dodatkowo mają 2 klasy 1 i -1.
Dokładamy 3 wymiar na którym możemy odłożyć wartości przypisane klasom
<span class="citation">(<a href="appendicies.html#ref-Geron2018" role="doc-biblioref">Geron 2018</a>)</span> s 166. Mając 3 wymiary tworzymy hiperpłaszczyznę. Jej
równanie to :</p>
<p><span class="math inline">\(y=\textbf{w}^T\cdot \textbf{x} + b\)</span></p>
<p>Przejdźmy z powrotem do 2 wymiarów. Hiperpłaszczyzna w pewnym miejscy
przecina nasze 2 wyjściowe wymiary danych (y=0, czarna linie poniżej).
Dodatkowo na te 2 wymiary zrzutujemy 2 linie dla których wartości
hiperpłaszczyzny wynoszą 1 i -1 (linie niebieska i różowa):</p>
<p><img src="03_TARGET/figures/svm_1.png" /></p>
<p>Obszar między liniami niebieską i różową stanową margines. Chcemy
stworzyć tak żeby:</p>
<ol style="list-style-type: decimal">
<li>był jak najszerszy.</li>
<li>był umieszczony w takim miejscu żeby jak najlepiej separował
obserwacje.</li>
</ol>
<p>Szerokość marginesu jest pochodną nachylenia hiperpłaszczyzny, zatem
jest funkcją parametrów tej hiperpłaszczyzny i jest równa długości
długości wektora tych parametrów: ||w||. To jest wartość którą
maksymalizujemy. Ze względu na uproszenie związane z liczeniem
pochodnych maksymalizujemy:</p>
<p><span class="math inline">\(\frac{1}{2}||\textbf{w}||^2\)</span> Aby spełnić drugi warunek (separowanie
obserwacji) na powyższą funkcję celu musimy dodać warunki ograniczające:</p>
<p>$t<sup>{(i)}(</sup>T ^{(i)}+b ) $</p>
<p><span class="math inline">\(t^{(i)}\)</span> równa się -1 dla obserwacji przypisanych do klasy -1 o równa
się 1 do obserwacji przypisanych do klasy 1 (1 * 1 = 1 oraz -1 * -1 =
1). Pozyżej mamy ten problem że mamy tu doczynienia z twardym
merginesami.</p>
<p>Z powyższym jest taki problem że mamy tutaj twarde marginesy, a zatem
staramy się zrobić idealną separację. Problem optymalizacyjny jest tak
sfomułowany że nie dopuszcza błędnych klasyfikacji. Żeby załagodzić temu
możemy wprowadzić <em>slack variables</em>. Jeżeli do wartości y przypisanej
obserwacji na hiperpłaszczyźnie dodamy w warunku zmienną <span class="math inline">\(\zeta\)</span>, to ta
zmienna spowoduje że nawet jeżeli wartość y będzie nieodpowiednia to po
dodaniu zmiennej <span class="math inline">\(\zeta\)</span> warunek jednak będzie spełniony. To właśnie nam
luzuje ograniczenie.</p>
<p>Zatem nowa funkcja celu:</p>
<p><span class="math inline">\(\frac{1}{2}||\textbf{w}||^2 + C\sum_{i=1}^{m}{\zeta^{(i)}}\)</span></p>
<p>$t<sup>{(i)}(</sup>T ^{(i)}+b ) , 
, , dla , , i = 1, 2, …m $</p>
<p>W pierwszym równaniu drugi element sumy jest stały. Jeżeli zwiększamy C
to suma slack variables się zmniejsza i na odwrót. Zatem mały C to duże
slack variables i duża tolerancja na błędy klasyfikacji, czyli szeroki
margines.</p>
<p>Powyższe zagadnienie optymalizacyjne to zadanie programowania
kwadratowego. Zadanie to jest sprowadzone z tzw. problemu pierwotnego do
problemu dualnego. Warto zauważyć że w celu przechodzenia pomiędzy
wynikami rozwiązania problemu dualnego i pierwotnego nasze problem
powinien spełniać warunki Karush-Kuhn-Tucker’a (KKT). Ostateczne
rozwiązanie związane jest z przeliczeniem iloczynów skalarnych
obserwacji, co jest ważną uwagą dla rozważań o maszynach
kernelizowanych.</p>
<p><strong>Maszyny kernelizowane</strong></p>
<p>Żeby obserwacje ze względu na klasy było łatwiej separować, lepiej
przenieść je do przestrzeni o większej liczbie wymiarów przy pomocy
odpowiedniej funkcji. Do tego celu jest wykorzystywanych kilka
najbardziej popularnych przekształceń. Jak wspomniano wcześniej,
rozwiązania zadania optymalizacyjnego dla SVM opiera się o iloczyny
skalarne obserwacji. Przekształcanie obserwacji do przestrzeni o większe
ilości wymiarów i obliczanie iloczynów skalarnych z nowej przestrzeni
jest obliczeniochłonne. Dlatego możemy zastosować <em>kernel trick</em>. Jeżeli
nasze funkcja przekształcająca <span class="math inline">\(\Phi\)</span> spełnia warunki Mercera to możemy
zastosować twierdzenie Mercera i stworzyć tzw. funkcje jądrową. Funkcja
ta umożliwia uzyskanie wyników iloczynu skalarnego obserwacji (wektorów)
w przestrzeni o wyższej liczbie wymiarów bez konieczności
przekształcania wektorów do tej przestrzeni (funkcja pracuje na
pierwotnych wektorach). Zatem iloczyn skalarny liczmy nie przez
<span class="math inline">\(&lt;\Phi(a),\Phi(b)&gt;\)</span> (gdzie musimy na wektorach pierwotnych a i b
zastosować przekształcenie <span class="math inline">\(\Phi\)</span>, żeby uzyskać nowe wektory w
przestrzeni o większej ilości wymiarów), ale mamy prostszą funkcję
jądrową K(a,b) działającą bezpośredni na wektorach a i b.</p>
</div>
<div id="regression-2" class="section level3" number="5.6.2">
<h3><span class="header-section-number">5.6.2</span> Regression</h3>
</div>
</div>
<div id="k-nn" class="section level2" number="5.7">
<h2><span class="header-section-number">5.7</span> K-NN</h2>
<div id="classification-3" class="section level3" number="5.7.1">
<h3><span class="header-section-number">5.7.1</span> Classification</h3>
<p><strong>Jak wyliczane jest prawdopodobieństwo w <em>sklearn</em></strong> :</p>
<p><a href="https://datascience.stackexchange.com/questions/27444/how-does-sklearn-kneighborsclassifier-compute-class-probabilites">link</a></p>
<p>The class probabilities are the normalized weighted average of
indicators for the k-nearest classes, weighted by the inverse distance.</p>
<p>For example: Say we have 6 classes, and the 5 nearest examples to our
test input have class labels ‘F,’ ‘B,’ ‘D,’ ‘A,’ and ‘B,’ with distances
2, 3, 4, 5, and 6, respectively.</p>
<p>Then the unnormalized class probabilities can by computed by:</p>
<pre><code>(1/2) * [0, 0, 0, 0, 0, 1] + (1/3) * [0, 1, 0, 0, 0, 0] + 
(1/4) * [0, 0, 0, 1, 0, 0] + (1/5) * [1, 0, 0, 0, 0, 0] + 
(1/6) * [0, 1, 0, 0, 0, 0] =

[1/5 ,1/2, 0, 1/4, 0, 1/2]</code></pre>
<div id="kd---tree" class="section level4" number="5.7.1.1">
<h4><span class="header-section-number">5.7.1.1</span> KD - tree</h4>
<p>Jest to algorytm do partycjonowania przestrzeni.</p>
<p><strong>Pseudoalgorytm</strong> na budowę drzewa KD (mój intuicyjny):</p>
<p>Są jego różne wersje. Jedna z nich jest taka:</p>
<ol style="list-style-type: decimal">
<li>Na początek wybierz losowy wymiar <em>x</em>. Dla tego wymiaru policz
mediane po wszystkich punktach. Znajdź punkt najbliższy do mediany
ze względu na analizowany wymiar. W ten sposób otrzymamy punkt
medianowy. Podziel przestrzeń na dwie części (binarny podział) w
oparciu o ten punkt.</li>
<li>Wybierz losowo kolejny wymiar. Dla każdej podprzestrzeni (mamy już
podział z poprzedniego kroku), znowu policz mediany znajdź punkty
medianowe i znowu dziel przestrzeń binarnie dla dla każdego punktu
medianowego.</li>
<li>Kontynuujemy do momentu, aż w węzłach ilość obserwacji spadnie do
ustalonego minimum. Węzły w których przerywamy liczenie stają się
liśćmi drzewa.</li>
</ol>
<p>Alternatywnie zamiast wybierać wymiary losowo możemy wybierać je
cyklicznie (dla 3 wymiarów <em>x,y,z</em> wymieramy je po kolei na przemian:
<em>x,y,z; x,y,z; x,y,z; x,y,z</em>.</p>
<p>Poprzez podział dostaje podział przestrzeni na podprzestrzenie (pierwszy
rysunek poniżej). Ponieważ robiliśmy to hierarchicznie to ten podział
można zaprezentować w postaci drzewa binarnego (drugi rysunek poniżej).
Każdy węzeł drzewa to jeden podział podprzestrzeni.</p>
<p><img src="03_TARGET/figures/KD_tree.PNG" /></p>
<p><strong>Pseudoalgorytm</strong> na szukanie najbliższego sąsiada w drzewie KD (mój
intuicyjny).</p>
<p>Mam nową obserwacje i chce poszukać który spośród punktów (precyzyjniej
mówiąc węzłów) drzewa jest najbliższy.</p>
<ol style="list-style-type: decimal">
<li><p>Lokalizuje w którym liściu jest punkt poprzez przeszukanie drzewa od
root.</p></li>
<li><p>Liczę odległość do najbliższego punktu wewnątrz tego liścia. Jeżeli
list byłby pusty to liczę odległość do węzła tworzącego podział
który określa ten liść. W ten sposób wyznaczam pierwszy proponowany
najbliższy punkt dla nowej obserwacji.</p></li>
<li><p>Następnie rysuje koło którego środkiem jest nowy punkt a jego
średnicę wyznacza odległość nowego punktu od punktu który jest
proponowany jako najbliższy. Jeżeli koło przecina inne sąsiadujące
podziały (wyznaczone przez węzły) to muszę je też przeanalizować. Od
razu wyliczam odległość do tych podziałów od mojego nowego punktu
(od podziałów a nie od węzłów będących obserwacjami tworzącymi te
podziały. Patrz rysunek poniżej jak liczony jest <span class="math inline">\(dist_3\)</span> i
<span class="math inline">\(dist_4\)</span>)</p>
<p><img src="03_TARGET/figures/KD_tree_node_dist.PNG" /></p></li>
</ol>
<p>Dla tych podziałów szukam odpowiadające im węzły na drzewie. Jeżeli
podziałów do przeanalizowania jest kilka to zaczynam od najbliższego. Od
tego podziału schodzę po drzewie w dół (kryterium takie, że w pierwszej
kolejności staram się iść taką ścieżką jak bym chciał się zbliżać do
mojego nowego punktu . Inne alternatywy też sprawdzam (oddalanie się),
ale w drugiej kolejności) i sprawdzam czy którychś z węzłów nie zawiera
punktu który jest bliżej niż dotychczas zaproponowany najbliższy punkt.
Jeżeli taki węzeł znajduje, to aktualizuje moje koło ze środkiem w nowym
punkcie. Nowe koło będzie oczywiście mniejsze. Wtedy znowu sprawdzam
które podziały przecinają się z kołem (koło jest mniejsze więc powinno
być ich mniej ).</p>
<p>Ta metoda ma wady dla przestrzeni wielowymiarowych. Przy dużej liczbie
wymiarów prawie na pewno mój nowy element nie będzie w środku liścia ,
ale blisko jakiegoś podziału. Więc rysując koło najprawdopodobniej okażę
się że trzeba sprawdzać dodatkowe węzły. Dodatkowo im mamy więcej
wymiarów tym więcej wezłów/podziałów ze sobą sąsiaduje. Tak więc koło
będzie przecinało wiele podziałów i algorytm zaczyna tracić efektywność.
Aby temu zapobiec zaproponowano algorytm <em>ball tree</em>.</p>
</div>
<div id="ball-tree" class="section level4" number="5.7.1.2">
<h4><span class="header-section-number">5.7.1.2</span> Ball tree</h4>
<p>Ball tree radzą sobie lepiej niż KD-tree w przestrzeniach o dużej
liczbie wymiarów.</p>
<p>Pseudoalgorytm budowy ball tree (mój intuicyjny):</p>
<ol style="list-style-type: decimal">
<li><p>Szukam dwóch najbardziej odległych punktów. Jednak aby nie sprawdzać
wszystkich możliwych kombinacji (każdy punkt z każdym) stosuje
trick. Wybieram losowy punkt i szukam pierwszego punktu który leży
najdalej i potem drugiego który leży najdalej od tego pierwszego.
Ilość sprawdzanych kombinacji mocno spada, a prawdopodobieństwo, że
uzyskane tym sposobem dwa punkty są jednymi z najbardziej
oddalonych, jest bardzo duże. Te 2 nowe punkt łączę linią i
wyznaczam środek tej linii. Ten środek i punkty wyznaczają mi kulę.
To jest pierwsza kula.</p></li>
<li><p>Linia którą narysowałem aby połączyć 2 odległe punkty powinna
wyznaczać kierunek w którym wariancja zbioru jest największa. Zatem
rysując płaszczyznę prostopadłą do tej linii mogę wyznaczyć sensowny
podział zbioru na 2 mniejsze. Dla każdego z tych dwóch podzbiorów
wyznaczam środek (coś na zasadzie centroidu). Dodatkowo metodą z
punktu pierwszego w dla każdego z podzbiorów wyznaczam
najodleglejsze punkty. Tak więc mogę teraz narysować 2 kolejne koła.</p></li>
<li><p>Powyższą procedurę kontynuuje aż liczebność obserwacji w kilach
zbliży się do ustalonego minimum.</p></li>
</ol>
<p>Sam schemat powstaje hierarchicznie i dlatego można przestawić go jako
drzewo. Chociaż trzeba pamiętać że kula na tym samym poziomie hierarchii
mogą się częściowo nakładać. Wydaje mi się że w wyniku podziału prawie
każdy punkt powinien się ostatecznie znaleźć w jakimś liściu drzewa. Ale
przez to że wybór najdalszych punktów w zbiorze jest przybliżony może
nie zawsze tak być w 100%. Taki punkty potem przy wybieraniu
najbliższego sąsiada chyba i tak są pomijane.</p>
<p><img src="03_TARGET/figures/ball_tree.PNG" /></p>
<p>Pseudoalgorytm na szukanie najbliższego sąsiada w ball tree (mój
intuicyjny - knn seach).</p>
<ol style="list-style-type: decimal">
<li>Mam nowy punkt który dla którego chce poszukać najbliższego sąsiada.</li>
<li>Sprawdzam czy punkt jest w jakimś klastrze będącym liściem
(najmniejsze klastry które już nie były bardziej dzielone). Jeżeli
jest wewnątrz, to szukam najbliższego sąsiada w tym klastrze. Potem
rysuje koło i sprawdzam czy nie jest czasem bliżej do granic innych
klastrów. Jeżeli tak jest, to też je przeszukuje. Tutaj działa taki
schemat poruszania się po drzewie jak przy KD-tree.</li>
<li>Jeżeli nowy punkt jest na zewnątrz liści, to sprawdzam do centrum
którego klastra jest mu najbliżej. Jeżeli to klaster liść to z tego
najbliższego klastra wybieram mu sąsiada. Jeżeli to jest duży
klaster zawierający podklastry to muszę dalej szukać w tym dużym
klastrze najbliższym podklastrów, aż zejdę to klastra liścia. (tutaj
też mamy do czynienia z poruszaniem się w duł drzewa po kolejnych
klastrach czyli węzłach, coś podobnego do kd-tree).</li>
</ol>
</div>
<div id="condensing-hart-algorithm" class="section level4" number="5.7.1.3">
<h4><span class="header-section-number">5.7.1.3</span> Condensing (Hart algorithm)</h4>
<p>Ideą jest żeby ze zbioru treningowego Z tworzę podzbiorów <em>S</em> w taki
sposób że elementy które nie mają wpływ na klasyfikację ( nie są
położone na granicach klas) usunąć.</p>
<p>Oznaczenia:</p>
<p>T(x) - Prawdziwa klasyfikacja elementu x ze względu na klasę</p>
<p>S(x) - Klasyfikacja elementu x ze względu na decyzję podjętą w oparciu o
<strong>nowy</strong> budowany podzbiór S.</p>
<p>Z(x) - Klasyfikacja elementu x ze względu na decyzję podjętą w oparciu o
<strong>pełny</strong> zbiór Z.</p>
<p>k - ilość najbliższych sąsiadów uwzględnianych w klasyfikacji metodą
knn.</p>
<ol style="list-style-type: decimal">
<li>Na początku zbiór S jest pusty. Losuję k elementów z zbioru Z i
dodaje do zbioru S.</li>
<li>Wybieram losowy punkt x ze zbioru Z nie należący do zbioru S.
Przeprowadzam klasyfikację dla x regułą k-nn ze względu na zbiór Z i
S (czyli liczę Z(x) i S(x)). Jeżeli wynik obu klasyfikacji jest taki
sam to pomijam ten punkt i losuje następny. Jeżeli jednak wynik Z(x)
i S(x) jest różny to sprawdzam czy klasyfikacja S(x) jest taka sama
jak T(x). Jeżeli tak, to dodaje element do zbioru S. Jeżeli nie to
szukam spośród elementów Z nie należących do S elementu najbliższego
w stosunku do x który należy do tej samej klasy co Z(x). Dzięki temu
dodam punkt który raczej poprawi zdolność klasyfikacji niż pogorszy.
Inaczej dodałbym punkt źle zaklasyfikowany w oparciu o Z i raczej
podniosłoby błąd predykcji.</li>
<li>Powtarzam tą procedują, aż nie będzie sytuacji że dla punktu x
należącego dla Z a nie należącego do S będzie spełnione Z(x) !=
S(x).</li>
</ol>
<p>Bardziej szczegółowy opis:</p>
<p>Wybieram po kolei punkty ze zbioru x.</p>
<ol style="list-style-type: decimal">
<li><p>Scan all elements of X, looking for an element x whose nearest
prototype from S has a different label than x</p></li>
<li><p>Remove x from X and add it to S</p></li>
<li><p>Repeat the scan until no more prototypes are added to S</p></li>
</ol>
<p>S used instead of X for kNN classification.</p>
</div>
<div id="editing" class="section level4" number="5.7.1.4">
<h4><span class="header-section-number">5.7.1.4</span> <strong>Editing</strong></h4>
</div>
<div id="reducing" class="section level4" number="5.7.1.5">
<h4><span class="header-section-number">5.7.1.5</span> Reducing</h4>
</div>
</div>
<div id="regression-3" class="section level3" number="5.7.2">
<h3><span class="header-section-number">5.7.2</span> Regression</h3>
</div>
</div>
<div id="log-linear-model" class="section level2" number="5.8">
<h2><span class="header-section-number">5.8</span> Log-linear model</h2>
</div>
<div id="similarity-learning" class="section level2" number="5.9">
<h2><span class="header-section-number">5.9</span> Similarity learning</h2>
</div>
<div id="survival-models" class="section level2" number="5.10">
<h2><span class="header-section-number">5.10</span> Survival models</h2>
<p><a href="https://www.theanalysisfactor.com/the-six-types-of-survival-analysis-and-challenges-in-learning-them/">modele typy
survival</a></p>
<div id="podstawowe-pojęcia" class="section level3" number="5.10.1">
<h3><span class="header-section-number">5.10.1</span> <strong>Podstawowe pojęcia</strong></h3>
<p>Linki:</p>
<p><a href="https://humboldt-wi.github.io/blog/research/information_systems_1920/group2_survivalanalysis/">link</a></p>
<p><strong>Obserwacje cenzurowane</strong></p>
<p>Cenzurowanie jest problemem odpowiednikiem problemu braku danych w
analizie przeżycia.</p>
<p>Cenzurowanie wynika zasadniczo z dwóch przyczyn.</p>
<ol style="list-style-type: decimal">
<li>Okres “życia” obserwacji wykracza poza okres analizowany (np. kredyt
jest dalej spłacany po końcu analizowanego okresu i nie wiemy czy
ostatecznie został spłacony czy nie). Tutaj mamy sytuacje
prawostronnego cenzurowania</li>
<li>Obserwujemy obserwacje od pewnego momentu i nie wiemy co się z nią
działo wcześniej (np. nie wiemy jak długo był spłacany kredyt). To
jest cenzurowanie lewostronne.</li>
<li>Wiemy że zdarzenie zaszło w jakimś momencie, ale nie wiemy dokładnie
kiedy. Wiemy tylko w jakim przedziale czasowym to było (interaval
censoring).</li>
<li>Od pewnego momentu w czasie trwania analizy nie mamy informacji o
obserwacji (pacjent wycofał się z badania, utraciliśmy z nim
kontakt, w bazie jest brak danych o tym co się działo z kredytem od
pewnego momentu). Jest to kolejny przykład cenzurowania
prawostronnego. Tutaj występuje problem informatywności. Może być
tak że, u pacjentów u których leczenie zadziałało bardzo dobrze,
może być wyższe ryzyko wycofania się z badania. Wtedy wycofanie się
oznacza też mniejsze ryzyko zgonu. Czyli cenzorowanie danych jest
skorelowane z ryzykiem zdarzenia.</li>
</ol>
<p>Jest jeszcze sytuacji kiedy badamy kredyty np. od stycznia 2020 a pewnie
kredyt został wypłacony z marciu 2020. Mamy o nim pełne informacje (nie
ma cenzurowania). Kredyt też być spłacony przed końcem czasu badania
(nie było zdarzenia defaultu). Wtedy też nie ma cenzurowania.</p>
<p>Co robić z problemem cenzurowania:</p>
<ol style="list-style-type: decimal">
<li>Można usunąć takie obserwacje.</li>
<li>Można wykonać imputacje.</li>
</ol>
<p>W analizie kredytów występuje też problem też że kredyt po defaulcie
może z powrotem ożyć, co narusza założenia większości modeli analizy
przeżycia. Wtedy ozdrowione kredyty możemy traktować jako nowe
obserwacje. Jednak powoduje to pewne obciążenie wyników.</p>
<p><strong>Obserwacje obcięte</strong></p>
<p>Nie do końca rozumiem czym są obserwacje ucięte i czym się różnią od
cenzurowanych. Trzeba to doczytać</p>
<p><strong>Zdarzenie (event)</strong></p>
<p>np. śmierć pacjenta, defalut kredytu.</p>
<p><strong>Funkcja gęstości prawdopodobieństwa f(t)</strong></p>
<p>Określa prawdopodobieństwo zdarzenia w czasie <em>t</em>, gdzie czas <em>t</em> to
dowolny przedział [t1,t2]:</p>
<p><span class="math inline">\(P(t_1 &lt; T \leq t_2)=\int_{t1}^{t2}{f(t)}dt\)</span></p>
<p>Gdzie T to jest moment zdarzenia.</p>
<p><strong>Dystrybuanta funkcji gęstości prawdopodobieństwa F(t)</strong></p>
<p>Między nią a funkcją gęstości mamy zależność:</p>
<p>$$ f(t) = dF(t)/dt \</p>
<p>F(t) = _{0}^{t}{f(u)du} $$</p>
<p><strong>Funkcja przetrwania S(t) (survival function)</strong></p>
<p>Nazywa się też funkcją dożycia lub funkcją trwania. Pokazuje że dana
osoba przetrwa dłużej niż określony czas. Można ją wyliczyć jako
dopełnienie dystrybuanty funkcji gęstości:</p>
<p>S(t) = 1-F(t)</p>
<p>Z funkcją gęstości łączą ją następujące zależności:</p>
<p><span class="math display">\[
f(t)=-dS(t)/dt
S(t)=\int_{t}^{\infty}{f(u)du}
\]</span></p>
<p>Znajomość funkcji (1) gęstości , (2) dystrybuanty i (3) przetrwania
pozwala nam wyliczyć prawdopodobieństwo zdarzenia w określonym czasie:</p>
<p><span class="math display">\[
P(t_1 &lt; T \leq t_2)=\int_{t1}^{t2}{f(t)}dt \\
P(t_1 &lt; T \leq t_2)=F(t_2)-F(t_1) \\
P(t_1 &lt; T \leq t_2)=S(t_2)-S(t_1)
\]</span></p>
<p><strong>Funkcja hazardu</strong> <span class="math inline">\(\lambda(t)\)</span></p>
<p>Nazywana też funkcją intensywności procesu lub natężenia zdarzeń.
Określa ona prawdopodobieństwo zdarzenia w chwili t pod warunkiem że
klient dożył do tej chwili:</p>
<p><span class="math display">\[
\lambda(t)=\frac{f(t)}{S(t)} = \frac{d[ln(S(t))]}{dt}
\]</span></p>
<p><strong>Skumulowana funkcja hazardu:</strong></p>
<p>Jak sama definicja mówi.</p>
<p><strong>Struktura danych - uwagi</strong></p>
<p>Wydaje mi się że jest tak (np. w Pythonie) że tutaj nas nie interesują
dokładne momenty rozpoczęcia i zakończenia zbierania danych o
obserwacji. Potrzebujemy tylko czasu trwania obserwacji.</p>
<p><strong>Uwagi o podziale estymatorów.</strong></p>
<p>Są tutaj podzielone na standardowe (bardziej klasyczna statystyka) i
inne (bardziej machine learningu)</p>
<p>Podział metod standardowych można przestawić tak:</p>
<p><img src="03_TARGET/figures/survival_analysis_6.png" /></p>
<p>Powyżej w metodach parametrycznych (zielony kolor) powinny być jeszcze
dodane model proporcjonalnego hazardu ( w moim podziale dalej są
uwzględnione).</p>
</div>
<div id="estymatory-standardowe-nieparametryczne" class="section level3" number="5.10.2">
<h3><span class="header-section-number">5.10.2</span> <strong>Estymatory standardowe-nieparametryczne</strong></h3>
<div id="tablice-trwania-życia-life-table" class="section level4" number="5.10.2.1">
<h4><span class="header-section-number">5.10.2.1</span> Tablice trwania życia (life table)</h4>
<p>Tablica przeżycia to najprostsze opisowe podejście do tematu.</p>
<p>Przykładowe najprostsza analiza przeżycia:</p>
<table style="width:97%;">
<colgroup>
<col width="13%" />
<col width="13%" />
<col width="13%" />
<col width="13%" />
<col width="13%" />
<col width="13%" />
<col width="13%" />
</colgroup>
<thead>
<tr class="header">
<th><strong>Age</strong></th>
<th><ul>
<li><br />
<br />
<br />
<br />
<br />
<br />
<br />
<br />
<br />
<br />
<br />
<br />
<br />
<br />
<br />
<br />
<br />
<br />
<br />
<br />
<br />
<br />
<br />
<br />
<br />
<br />
<br />
<br />
<br />
*Number</li>
</ul>
<p>living
(At</p>
ri
sk)**</th>
<th><ul>
<li><br />
<br />
<br />
<br />
<br />
<br />
<br />
<br />
<br />
<br />
<br />
<br />
<br />
<br />
<br />
<br />
<br />
<br />
<br />
<br />
<br />
<br />
<br />
<br />
<br />
<br />
<br />
<br />
<br />
*Number</li>
</ul>
d
ead**</th>
<th><ul>
<li><br />
<br />
<br />
<br />
<br />
<br />
<br />
<br />
<br />
<br />
<br />
<br />
<br />
<br />
<br />
<br />
<br />
<br />
<br />
<br />
<br />
<br />
<br />
<br />
<br />
<br />
<br />
<br />
<br />
*Number
c</li>
</ul>
<p>ensored
(ci</p>
<p>którzy
o</p>
<p>puścili</p>
<p>badanie
ale nie</p>
<p>umarli
i r</p>
<p>edukują</p>
<p>ilość
obs</p>
<p>erwacji
w k</p>
<p>olejnym
wie</p>
rs
zu)**</th>
<th><strong>Prob
ability
of
death</strong></th>
<th>Survial
prob
ability</th>
<th><strong>Cum
ulative
S
urvival
Probab
ility</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>0</td>
<td>14,353</td>
<td>2</td>
<td>0</td>
<td>0.0001</td>
<td>1 -
0.0001
=
0.9999</td>
<td>0.9999</td>
</tr>
<tr class="even">
<td>1</td>
<td>14,353
- 0 - 2
= <strong>1
4,351</strong></td>
<td>248</td>
<td>1855</td>
<td>0.0173</td>
<td>1 -
0.0173
=
0.9827</td>
<td>0.9999
*
0.9827
= 0.
9826017</td>
</tr>
<tr class="odd">
<td>2</td>
<td>14,351
- 1855
- 240 =
<strong>1
2,248</strong></td>
<td>155</td>
<td>758</td>
<td>0.0127</td>
<td>1 -
0.0127
=
0.9873</td>
<td><ol start="0" style="list-style-type: decimal">
<li>982</li>
</ol>
<p>6017 *</p>
<p>0.9873
= 1.
9701227</p></td>
</tr>
</tbody>
</table>
</div>
<div id="kaplan-mayer" class="section level4" number="5.10.2.2">
<h4><span class="header-section-number">5.10.2.2</span> Kaplan Mayer</h4>
<p>Jest to nieparametryczny estymator funkcji przeżycia. Nie można go
niestety używać do predykcji czyli szacowania czasu przeżycia dla
elementów które żyły dłużej niż elementy w próbie (np. w probie
<span class="math inline">\(t_{max} = 10\)</span> , a ja chce wiedzieć jak funkcja przeżycia zachowa się
dla t = 20)</p>
<p>Estymator ma wzór:</p>
<p><span class="math display">\[
\hat{S}(t)= \prod_{i:\,t_i\leq t}{1-\frac{d_i}{n_i}}
\]</span></p>
<p>Czyli jest to iloczyn (czyli skumulowanie) prawdopodobieństw dożycia do
poprzednich okresów czasu.</p>
<p>Przykład obliczeń:</p>
<table style="width:97%;">
<colgroup>
<col width="19%" />
<col width="19%" />
<col width="19%" />
<col width="19%" />
<col width="19%" />
</colgroup>
<thead>
<tr class="header">
<th align="center"><strong>Time,
Years</strong></th>
<th align="center"><p><strong>Number at
Risk</strong></p>
<strong>Nt</strong></th>
<th align="center"><p><strong>Number of
Deaths</strong></p>
<strong>Dt</strong></th>
<th align="center"><p><strong>Number
Censored</strong></p>
<strong>Ct</strong></th>
<th align="center"><p><strong>Survival
Pr
obability</strong></p>
<strong>S<sub>t+1</sub> =
S<sub>t</sub>*((N~
t
+1<sub>-D</sub>t+1~
)/N<sub>t+1</sub>)</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">0</td>
<td align="center">20</td>
<td align="center"> </td>
<td align="center"> </td>
<td align="center">1</td>
</tr>
<tr class="even">
<td align="center">1</td>
<td align="center">20</td>
<td align="center">1</td>
<td align="center"> </td>
<td align="center">1*
((20-1)/20)
= 0.950</td>
</tr>
<tr class="odd">
<td align="center">2</td>
<td align="center">19</td>
<td align="center"> </td>
<td align="center">1</td>
<td align="center"><ol start="0" style="list-style-type: decimal">
<li>950*((19-0</li>
</ol>
)/19)=0.950</td>
</tr>
<tr class="even">
<td align="center">3</td>
<td align="center">18</td>
<td align="center">1</td>
<td align="center"> </td>
<td align="center">0.950*
((18-1)/18)
= 0.897</td>
</tr>
<tr class="odd">
<td align="center">5</td>
<td align="center">17</td>
<td align="center">1</td>
<td align="center"> </td>
<td align="center">0.897*
((17-1)/17)
= 0.844</td>
</tr>
<tr class="even">
<td align="center">6</td>
<td align="center">16</td>
<td align="center"> </td>
<td align="center">1</td>
<td align="center">0.844</td>
</tr>
<tr class="odd">
<td align="center">9</td>
<td align="center">15</td>
<td align="center"> </td>
<td align="center">1</td>
<td align="center">0.844</td>
</tr>
<tr class="even">
<td align="center">10</td>
<td align="center">14</td>
<td align="center"> </td>
<td align="center">1</td>
<td align="center">0.844</td>
</tr>
<tr class="odd">
<td align="center">11</td>
<td align="center">13</td>
<td align="center"> </td>
<td align="center">1</td>
<td align="center">0.844</td>
</tr>
<tr class="even">
<td align="center">12</td>
<td align="center">12</td>
<td align="center"> </td>
<td align="center">1</td>
<td align="center">0.844</td>
</tr>
<tr class="odd">
<td align="center">13</td>
<td align="center">11</td>
<td align="center"> </td>
<td align="center">1</td>
<td align="center">0.844</td>
</tr>
<tr class="even">
<td align="center">14</td>
<td align="center">10</td>
<td align="center">1</td>
<td align="center"> </td>
<td align="center">0.760</td>
</tr>
<tr class="odd">
<td align="center">17</td>
<td align="center">9</td>
<td align="center">1</td>
<td align="center">1</td>
<td align="center">0.676</td>
</tr>
<tr class="even">
<td align="center">18</td>
<td align="center">7</td>
<td align="center"> </td>
<td align="center">1</td>
<td align="center">0.676</td>
</tr>
<tr class="odd">
<td align="center">19</td>
<td align="center">6</td>
<td align="center"> </td>
<td align="center">1</td>
<td align="center">0.676</td>
</tr>
<tr class="even">
<td align="center">21</td>
<td align="center">5</td>
<td align="center"> </td>
<td align="center">1</td>
<td align="center">0.676</td>
</tr>
<tr class="odd">
<td align="center">23</td>
<td align="center">4</td>
<td align="center">1</td>
<td align="center"> </td>
<td align="center">0.507</td>
</tr>
<tr class="even">
<td align="center">24</td>
<td align="center">3</td>
<td align="center"> </td>
<td align="center">3</td>
<td align="center">0.507</td>
</tr>
</tbody>
</table>
<p>Wariancja estymatora jest dana wzorem (Greenwood formula):</p>
<p><span class="math display">\[
\hat \sigma^2[\hat S(t)] = \widehat var[\hat S(t)] = \hat S(t)^2 \sum_{i:t_i \le t} \frac{d_i}{n_i(n_i-d_i)}
\]</span></p>
<p>Jeżeli nie ma danych cenzorowanych wzór uprasza się do:</p>
<p><span class="math display">\[
\hat \sigma^2[\hat S(t)] = \frac{\hat S(t) [1- \hat S(t)]}{n}
\]</span></p>
<p>Założymy że estymator funkcji przeżycia Kaplana Mayera ma rozkład
asymptotycznie normalny:</p>
<p><span class="math display">\[
\hat S(t) \simeq N(\hat S(t), \sigma(t)/\sqrt(n))
\]</span>Wtedy możemy zbudować przedziały ufności :</p>
<p><span class="math display">\[
\bigg(\hat S(t) \pm z_{1-\alpha/2}  \cdot \hat \sigma/\sqrt(n) \bigg),
\]</span></p>
<p>Gdzie z to jest rozkład normalny standaryzowany.</p>
</div>
<div id="nelson-aalen" class="section level4" number="5.10.2.3">
<h4><span class="header-section-number">5.10.2.3</span> Nelson Aalen</h4>
<p>Jest to nieparametryczny estymator skumulowanej funkcji hazardu.
Podobnie jak przy estymatorze Kaplana Mayera nie może być używany do
predykcji. Jest dany formułą:</p>
<p>$$</p>
<p>(t)= _{i:,t_it}{} $$</p>
<p>Gdzie <span class="math inline">\(d_i\)</span> to zdarzenia w czasie <em>i</em>, a <span class="math inline">\(n_i\)</span> to ilość elementów w
okresie <em>i</em> .</p>
<p>Estymator wariancji wynosi:</p>
<p>$$</p>
<p>ar((t))= _{i:,t_it}{} $$</p>
<p><strong>Porównywanie funkcji estymowanych</strong></p>
<p>Przy metodach estymacji takich jak Kampal Mayer czy Nelson Aalen nie
możemy badać bezpośrednio wpływu jakichś dodatkowych zmiennych
objaśnianych na funkcję przeżycia. Żeby np. zbadać wpływ tego czy
palenie wpływa naszą funkcję przeżycia, jedyne co nam pozostaje to
zrobić dwie oddzielne funkcje dla palących i dla niepalących i potem je
porównać. Są liczne statystyki na stawienie testowanie hipotezy czy
krzywe są różne:</p>
<ul>
<li><p>współczynnik hazardu (hazard ratio)</p></li>
<li><p>test istotności z</p></li>
<li><p>test logarytmiczny rang (log-rank test) - dalej jest przykład
numeryczny</p></li>
<li><p>test WIlxona</p></li>
<li><p>test Tarone’a</p></li>
<li><p>test Peto</p></li>
<li><p>zmodyfikowany test Peto</p></li>
<li><p>test Fleminga</p></li>
</ul>
<p>Log rank test - przykład numeryczny:</p>
<p>Założmy że mamy 2 krzywe. Poniżej pokazuje tabele wyliczeń dla obu:</p>
<p>Pierwsza krzywa:</p>
<table style="width:97%;">
<colgroup>
<col width="19%" />
<col width="19%" />
<col width="19%" />
<col width="19%" />
<col width="19%" />
</colgroup>
<thead>
<tr class="header">
<th align="center"><strong>Time,
Months</strong></th>
<th align="center"><p><strong>Number at
Risk</strong></p>
<strong>N<sub>t</sub></strong></th>
<th align="center"><p><strong>Number of
Deaths</strong></p>
<strong>D<sub>t</sub></strong></th>
<th align="center"><p><strong>Number
Censored</strong></p>
<strong>C<sub>t</sub></strong></th>
<th align="center"><p><strong>Survival
Pr
obability</strong></p>
!</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">0</td>
<td align="center">10</td>
<td align="center"> </td>
<td align="center"> </td>
<td align="center">1</td>
</tr>
<tr class="even">
<td align="center">8</td>
<td align="center">10</td>
<td align="center">1</td>
<td align="center">1</td>
<td align="center">0.900</td>
</tr>
<tr class="odd">
<td align="center">12</td>
<td align="center">8</td>
<td align="center">1</td>
<td align="center"> </td>
<td align="center">0.788</td>
</tr>
<tr class="even">
<td align="center">14</td>
<td align="center">7</td>
<td align="center">1</td>
<td align="center">  </td>
<td align="center">0.675</td>
</tr>
<tr class="odd">
<td align="center">20</td>
<td align="center">6</td>
<td align="center"> </td>
<td align="center">1</td>
<td align="center">0.675</td>
</tr>
<tr class="even">
<td align="center">21</td>
<td align="center">5</td>
<td align="center">1</td>
<td align="center"> </td>
<td align="center">0.540</td>
</tr>
<tr class="odd">
<td align="center">26</td>
<td align="center">4</td>
<td align="center">1</td>
<td align="center">  </td>
<td align="center">0.405</td>
</tr>
<tr class="even">
<td align="center">27</td>
<td align="center">3</td>
<td align="center">1</td>
<td align="center">  </td>
<td align="center">0.270</td>
</tr>
<tr class="odd">
<td align="center">32</td>
<td align="center">2</td>
<td align="center">  </td>
<td align="center">1</td>
<td align="center">0.270</td>
</tr>
<tr class="even">
<td align="center">40</td>
<td align="center">1</td>
<td align="center">  </td>
<td align="center">1</td>
<td align="center">0.270</td>
</tr>
</tbody>
</table>
<p>Druga krzywa:</p>
<table style="width:97%;">
<colgroup>
<col width="19%" />
<col width="19%" />
<col width="19%" />
<col width="19%" />
<col width="19%" />
</colgroup>
<thead>
<tr class="header">
<th align="center"><strong>Time,
Months</strong></th>
<th align="center"><p><strong>Number at
Risk</strong></p>
<strong>N<sub>t</sub></strong></th>
<th align="center"><p><strong>Number of
Deaths</strong></p>
<strong>D<sub>t</sub></strong></th>
<th align="center"><p><strong>Number
Censored</strong></p>
<strong>C<sub>t</sub></strong></th>
<th align="center"><p><strong>Survival
Pr
obability</strong></p>
!</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">0</td>
<td align="center">10</td>
<td align="center"> </td>
<td align="center"> </td>
<td align="center">1</td>
</tr>
<tr class="even">
<td align="center">25</td>
<td align="center">10</td>
<td align="center"> </td>
<td align="center">2</td>
<td align="center">1.000</td>
</tr>
<tr class="odd">
<td align="center">28</td>
<td align="center">8</td>
<td align="center">1</td>
<td align="center"> </td>
<td align="center">0.875</td>
</tr>
<tr class="even">
<td align="center">33</td>
<td align="center">7</td>
<td align="center">1</td>
<td align="center">  </td>
<td align="center">0.750</td>
</tr>
<tr class="odd">
<td align="center">37</td>
<td align="center">6</td>
<td align="center">  </td>
<td align="center">1</td>
<td align="center">0.750</td>
</tr>
<tr class="even">
<td align="center">41</td>
<td align="center">5</td>
<td align="center">1</td>
<td align="center"> </td>
<td align="center">0.600</td>
</tr>
<tr class="odd">
<td align="center">43</td>
<td align="center">4</td>
<td align="center">  </td>
<td align="center">1</td>
<td align="center">0.600</td>
</tr>
<tr class="even">
<td align="center">48</td>
<td align="center">3</td>
<td align="center">  </td>
<td align="center">3</td>
<td align="center">0.600</td>
</tr>
</tbody>
</table>
<p>Z powyższych dwóch tabel zrobimy jedną uwzględniając ilość obserwacji
zgonów (deaths):</p>
<table style="width:97%;">
<colgroup>
<col width="19%" />
<col width="19%" />
<col width="19%" />
<col width="19%" />
<col width="19%" />
</colgroup>
<thead>
<tr class="header">
<th align="center"><strong>Time,
Months</strong></th>
<th align="center"><p><strong>Number at
Risk in
Group 1</strong></p>
<strong>N<sub>1t</sub></strong></th>
<th align="center"><p><strong>Number at
Risk in
Group 2</strong></p>
<strong>N<sub>2t</sub></strong></th>
<th align="center"><p><strong>Number of
Events
(Deaths) in
Group 1</strong></p>
<strong>O<sub>1t</sub></strong></th>
<th align="center"><p><strong>Number of
Events
(Deaths) in
Group 2</strong></p>
<strong>O<sub>2t</sub></strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">8</td>
<td align="center">10</td>
<td align="center">10</td>
<td align="center">1</td>
<td align="center">0</td>
</tr>
<tr class="even">
<td align="center">12</td>
<td align="center">8</td>
<td align="center">10</td>
<td align="center">1</td>
<td align="center">0</td>
</tr>
<tr class="odd">
<td align="center">14</td>
<td align="center">7</td>
<td align="center">10</td>
<td align="center">1</td>
<td align="center">0</td>
</tr>
<tr class="even">
<td align="center">21</td>
<td align="center">5</td>
<td align="center">10</td>
<td align="center">1</td>
<td align="center">0</td>
</tr>
<tr class="odd">
<td align="center">26</td>
<td align="center">4</td>
<td align="center">8</td>
<td align="center">1</td>
<td align="center">0</td>
</tr>
<tr class="even">
<td align="center">27</td>
<td align="center">3</td>
<td align="center">8</td>
<td align="center">1</td>
<td align="center">0</td>
</tr>
<tr class="odd">
<td align="center">28</td>
<td align="center">2</td>
<td align="center">8</td>
<td align="center">0</td>
<td align="center">1</td>
</tr>
<tr class="even">
<td align="center">33</td>
<td align="center">1</td>
<td align="center">7</td>
<td align="center">0</td>
<td align="center">1</td>
</tr>
<tr class="odd">
<td align="center">41</td>
<td align="center">0</td>
<td align="center">5</td>
<td align="center">0</td>
<td align="center">1</td>
</tr>
</tbody>
</table>
<p>Test opiera się na formule:</p>
<p><span class="math display">\[
\chi^2=\sum{\frac{(\sum{O_{jt}}-\sum{E_{jt}})^2}{\sum{E_{jt}}}}
\]</span></p>
<p>Gdzie <em>O</em> to jest obserwowana ilość zdarzeń a <em>E</em> oczekiwana ilość
zdarzeń. Oczekiwana ilość to ilość zdarzeń taka jaka powinna występować
jeżeli krzywe się nie różnią.</p>
<p>Obliczanie oczekiwanej ilości zdarzeń dla każdej krzywej:</p>
<table style="width:100%;">
<colgroup>
<col width="11%" />
<col width="11%" />
<col width="11%" />
<col width="11%" />
<col width="11%" />
<col width="11%" />
<col width="11%" />
<col width="11%" />
<col width="11%" />
</colgroup>
<thead>
<tr class="header">
<th align="center"><strong>T
ime,
Mon t
hs</strong></th>
<th align="center"><p><strong>N u
mber
at
Risk
in G
roup
1</strong></p>
<ul>
<li><br />
</li>
</ul>
<p>*N~</p>
<p>1t</p>
<br />
<br />
<br />
<br />
<br />
<br />
<br />
<br />
<br />
<br />
<br />
<br />
<br />
<br />
~
**</th>
<th align="center"><p><strong>N u
mber
at
Risk
in G
roup
2</strong></p>
<ul>
<li><br />
</li>
</ul>
<p>*N~</p>
<p>2t</p>
<br />
<br />
<br />
<br />
<br />
<br />
<br />
<br />
<br />
<br />
<br />
<br />
<br />
<br />
~
**</th>
<th align="center"><p><strong>T
otal
N u
mber
at R
i
sk</strong></p>
<strong>N
~ t
~</strong></th>
<th align="center"><p><strong>N u
mber
of E
v
ents
in G
roup
1</strong></p>
<ul>
<li><br />
</li>
</ul>
<p>*O~</p>
<p>1t</p>
<br />
<br />
<br />
<br />
<br />
<br />
<br />
<br />
<br />
<br />
<br />
<br />
<br />
<br />
~
**</th>
<th align="center"><p><strong>N u
mber
of E
v
ents
in G
roup
2</strong></p>
<ul>
<li><br />
</li>
</ul>
<p>*O~</p>
<p>2t</p>
<br />
<br />
<br />
<br />
<br />
<br />
<br />
<br />
<br />
<br />
<br />
<br />
<br />
<br />
~
**</th>
<th align="center"><p><strong>T
otal
N u
mber
of
Eve n
ts</strong></p>
<strong>O
~ t
~</strong></th>
<th align="center"><ul>
<li><br />
</li>
</ul>
<p>*Exp</p>
<p>e</p>
<p>cted
N u</p>
<p>mber</p>
<p>of E
v</p>
<p>ents
i n
**</p>
<p><strong>G
roup
1</strong></p>
<strong>E
<sub>1t</sub>
= N
<sub>1t</sub>
*
(O~
t
<sub>/N</sub>
t<br />
<br />
~)</strong></th>
<th align="center"><ul>
<li><br />
</li>
</ul>
<p>*Exp</p>
<p>e</p>
<p>cted
N u</p>
<p>mber</p>
<p>of E
v</p>
<p>ents
i n
**</p>
<p><strong>G
roup
2</strong></p>
<strong>E
<sub>2t</sub>
= N
<sub>2t</sub>
*
(O~
t
<sub>/N</sub>
t<br />
<br />
~)</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">8</td>
<td align="center">10</td>
<td align="center">10</td>
<td align="center">20</td>
<td align="center">1</td>
<td align="center">0</td>
<td align="center">1</td>
<td align="center">0
.500</td>
<td align="center">0
.500</td>
</tr>
<tr class="even">
<td align="center">12</td>
<td align="center">8</td>
<td align="center">10</td>
<td align="center">18</td>
<td align="center">1</td>
<td align="center">0</td>
<td align="center">1</td>
<td align="center">8
*(1
/
18)=
0
.444</td>
<td align="center">0
.556</td>
</tr>
<tr class="odd">
<td align="center">14</td>
<td align="center">7</td>
<td align="center">10</td>
<td align="center">17</td>
<td align="center">1</td>
<td align="center">0</td>
<td align="center">1</td>
<td align="center">0
.412</td>
<td align="center">0
.588</td>
</tr>
<tr class="even">
<td align="center">21</td>
<td align="center">5</td>
<td align="center">10</td>
<td align="center">15</td>
<td align="center">1</td>
<td align="center">0</td>
<td align="center">1</td>
<td align="center">0
.333</td>
<td align="center">0
.667</td>
</tr>
<tr class="odd">
<td align="center">26</td>
<td align="center">4</td>
<td align="center">8</td>
<td align="center">12</td>
<td align="center">1</td>
<td align="center">0</td>
<td align="center">1</td>
<td align="center">0
.333</td>
<td align="center">0
.667</td>
</tr>
<tr class="even">
<td align="center">27</td>
<td align="center">3</td>
<td align="center">8</td>
<td align="center">11</td>
<td align="center">1</td>
<td align="center">0</td>
<td align="center">1</td>
<td align="center">0
.273</td>
<td align="center">0
.727</td>
</tr>
<tr class="odd">
<td align="center">28</td>
<td align="center">2</td>
<td align="center">8</td>
<td align="center">10</td>
<td align="center">0</td>
<td align="center">1</td>
<td align="center">1</td>
<td align="center">0
.200</td>
<td align="center">0
.800</td>
</tr>
<tr class="even">
<td align="center">33</td>
<td align="center">1</td>
<td align="center">7</td>
<td align="center">8</td>
<td align="center">0</td>
<td align="center">1</td>
<td align="center">1</td>
<td align="center">0
.125</td>
<td align="center">0
.875</td>
</tr>
<tr class="odd">
<td align="center">41</td>
<td align="center">0</td>
<td align="center">5</td>
<td align="center">5</td>
<td align="center">0</td>
<td align="center">1</td>
<td align="center">1</td>
<td align="center">0
.000</td>
<td align="center">1
.000</td>
</tr>
<tr class="even">
<td align="center"> </td>
<td align="center"> </td>
<td align="center"> </td>
<td align="center"> </td>
<td align="center"><ul>
<li>*</li>
</ul>
6
**</td>
<td align="center"><ul>
<li>*</li>
</ul>
3
**</td>
<td align="center"></td>
<td align="center"><strong>2.
6
20</strong></td>
<td align="center"><strong>6.
3
80</strong></td>
</tr>
</tbody>
</table>
<p><img src="03_TARGET/figures/survival_analysis_3.png" /></p>
</div>
</div>
<div id="estymatora-standardowe-parametryczne" class="section level3" number="5.10.3">
<h3><span class="header-section-number">5.10.3</span> <strong>Estymatora standardowe parametryczne</strong></h3>
<p>Tutaj zakładamy że znamy funkcję gęstości rozkładu zdarzeń f(t).</p>
<p>Podstawowe estymatory możemy podzielić na 2 klasy :</p>
<ol style="list-style-type: decimal">
<li><p>przyśpieszonego życia (AFT - accelerated failure time)</p></li>
<li><p>proporcjonalnego hazardu</p></li>
</ol>
<p>W modelach AFT zakładamy, że predyktor ma multiplikatywny wpływ na
funkcję przeżycia (co się sprowadza do liniowego wpływu na logarytm
funkcji przeżycia). W modelu proporcjonalnego hazardu zakłada się z
kolei, że predyktor ma multiplikatywny wpływ na funkcję hazardu co się
sprowadza do zależności: <span class="math inline">\(\lambda(t,x)=\lambda_0(t)e^{x\beta}\)</span>.</p>
<p>Założenia parametrycznych modeli proporcjonalnego hazardu:</p>
<ul>
<li><p>The true form of the underlying functions (hazard, survival) are
specified correctly.</p></li>
<li><p>The relationship between the predictors and the log hazard is
linear.</p></li>
<li><p>In the absence of interactions, the predictors act additively on the
log hazard.</p></li>
<li><p>The effect of the predictors is the same for all values of t.</p></li>
</ul>
<p>Dla modeli AFT stosuje się rozkłady:</p>
<ul>
<li><p>Weibulla</p></li>
<li><p>wykładniczy</p></li>
<li><p>log-normalny</p></li>
<li><p>log-logistyczny</p></li>
<li><p>gamma</p></li>
</ul>
<p>Dla modeli proporcjonalnego hazardu stosuje się rozkłady:</p>
<ul>
<li><p>weibulla</p></li>
<li><p>wykładniczy</p></li>
<li><p>gompertza</p></li>
</ul>
<p>Rozkłady dopasowuje się najczęściej metodą największej wiarygodności lub
metodą najmniejszych kwadratów. .</p>
<p><strong>Regresja liniowa</strong></p>
<p>Można tutaj modelować czas zdarzenia t. Zatem t = a0 + a1x + a2x + … +
anx.</p>
<p>Zakłady że warunkowy rozkład t to rozkład normalny.</p>
</div>
<div id="estymatory-standardowe-semi-parametryczne" class="section level3" number="5.10.4">
<h3><span class="header-section-number">5.10.4</span> Estymatory standardowe semi-parametryczne</h3>
<div id="cox" class="section level4" number="5.10.4.1">
<h4><span class="header-section-number">5.10.4.1</span> <strong>Cox</strong></h4>
<p><a href="https://sphweb.bumc.bu.edu/otlt/mph-modules/bs/bs704_survival/BS704_Survival6.html">link</a>.</p>
<p>W modelu tym funkcja estymuje się nieparametrycznie. Dodatkowo opiera
się ona o pojęcia hazardu bazowego czyli wartości funkcji hazardu kiedy
wszystkie x = 0. Jest zaliczany do metod semiparametrycznych. Z jednej
strony nieparematrycznie estymuje funkcję hazardu jednak z drugiej
strony są założenia (i.e., independence, changes in predictors produce
proportional changes in the hazard regardless of time, and a linear
association between the natural logarithm of the relative hazard and the
predictors).</p>
<p>Warto zwrócić uwagę na założenia stałości wartości predyktorów w czasie.
Są uogólnienia gdzie predyktory mogą się zmieniać w czasie. W dla modelu
Coxa wtedy hazard nie jest już proporcjonalny.</p>
<p>Model coxa wystpiue</p>
</div>
</div>
<div id="estymatory-inne" class="section level3" number="5.10.5">
<h3><span class="header-section-number">5.10.5</span> Estymatory inne</h3>
<p><img src="03_TARGET/figures/survival_analysis_5.png" /></p>
<div id="random-survival-forest" class="section level4" number="5.10.5.1">
<h4><span class="header-section-number">5.10.5.1</span> Random Survival Forest</h4>
<p>Jest zaimplementowany w Pythonie</p>
<p>Another feasible machine learning approach which can be used to avoid
the proportional constraint of the Cox proportional hazards model is a
random survival forest (RSF). The random survival forest is defined as a
tree method that constructs an ensemble estimate for the cumulative
hazard function. Constructing the ensembles from base learners, such as
trees, can substantially improve the prediction performance. [13]</p>
<ul>
<li><p>Basically, RSF computes a random forest using the log-rank test as
the splitting criterion. It calculates the cumulative hazards of the
leaf nodes in each tree and averages them in following ensemble.</p></li>
<li><p>The tree is grown to full size under the condition that each
terminal node have no less than a prespecified number of deaths.
[18]</p></li>
<li><p>The out-of-bag samples are then used to compute the prediction error
of the ensemble cumulative hazard function.</p></li>
</ul>
</div>
<div id="deepsurv" class="section level4" number="5.10.5.2">
<h4><span class="header-section-number">5.10.5.2</span> <strong>DeepSurv</strong></h4>
<p>Jest to zastosowanie sieci neuronowych będących zamiennikiem dla modelu
Coxa. Więc podobnie jak tam, badamy zależność od wielu predyktorów
zachowania się funkcji hazardu
<a href="https://towardsdatascience.com/deep-learning-for-survival-analysis-fdd1505293c9">link</a>
.</p>
<p>Oto architektura sieci:</p>
<p><img src="03_TARGET/figures/survival_analysis_NN_1.png" /></p>
<p>Jej funkcja <em>loss</em>, która jest minimalizowana to:</p>
<p><img src="03_TARGET/figures/survival_analysis_NN_2.png" /></p>
<p>Funkcja straty jest oparta o funkcję straty optymalizowaną w modelu
Cox-a <a href="https://www.wikiwand.com/en/Proportional_hazards_model">link</a>.
Jest chyba optymalizowane niezależnie dla każdego punktu czasowego. Aby
minimalizować tą funkcję musimy maksymalizować wyrażenie w czerwonej
ramce. Lewa część wyrażenia musi być zatem maksymalizowana (hazard dla
elementów dla których wystąpiło zdarzenie w analizowanym momencie).
Prawa minimalizowana. W prawej części są elementy dla których nie zaszło
zdarzenie do analizowanego momentu czasowego.</p>
</div>
</div>
<div id="performence" class="section level3" number="5.10.6">
<h3><span class="header-section-number">5.10.6</span> <strong>Performence</strong></h3>
<p>Dopasowanie rozkładów do danych bada się w oparciu o reszty:</p>
<ul>
<li><p>reszty coxa snella</p></li>
<li><p>reszty martyngałowe</p></li>
<li><p>reszty schoenfelda</p></li>
</ul>
</div>
</div>
<div id="ensembled-models" class="section level2" number="5.11">
<h2><span class="header-section-number">5.11</span> Ensembled models</h2>
<div id="bagging-and-pasting-1" class="section level3" number="5.11.1">
<h3><span class="header-section-number">5.11.1</span> Bagging and Pasting</h3>
<div id="random-forest" class="section level4" number="5.11.1.1">
<h4><span class="header-section-number">5.11.1.1</span> Random Forest</h4>
<div id="out-of-bag-error" class="section level5" number="5.11.1.1.1">
<h5><span class="header-section-number">5.11.1.1.1</span> Out of Bag Error</h5>
<p>Pseudoalgorytm (mój intuicyjny) - Random Forest dla klasyfikacji.</p>
<ol style="list-style-type: decimal">
<li>Dla każdego drzewa losuję próbę z danych. Robię to albo boostrapowo
(z powtarzeniem z n elementowej populacji losuje n etlementów), albo
bez powtarzania.</li>
<li>Buduję niezależnie drzewa. Każde drzewo zakładam że na końcu zwraca
twarde labels a nie prawdopodobieństwa. W trakcie wyliczam
Out-Of-Bag Error. Dana obserwacje jest predykowana przez wszystkie
modele dla których nie została ona wylosowana do zbioru uczącego.
Out-Of-Bag error jest przydatny do ustalania optymalnej ilości
drzew.</li>
<li>Na koniec przeprowadzam ostateczną predykcję, poprzez głosowanie
drzew. Każde drzewo ma taką samą wagę.</li>
</ol>
<p>Pros:</p>
<ol style="list-style-type: decimal">
<li><p>Random forest can solve both type of problems that is classification
and regression and does a decent estimation at both fronts.</p></li>
<li><p>One of benefits of Random Forest which exists me most is, the power
of handle large data sets with higher dimensionality. It can handle
thousands of input variables and identity most significant variables
so it is considered as one of the dimensionality reduction method.
Further, the model outputs importance of variable, which can be a
very handy feature.</p></li>
<li><p>It has an effective method for estimating missing data and maintains
accuracy when large proportion of the data are missing.</p></li>
<li><p>It has methods for balancing errors in data sets where classes are
imbalanced.</p></li>
<li><p>The capability of the above can be extended to unlabeled data,
leading to unsupervised clustering,data views and outlier detection.</p></li>
<li><p>Random forest involves sampling of the input data with replacement
called as bootstrap sampling. Here one third of data is not used for
training and can be used to testing. These are called the OUT OF BAG
samples. Error estimated on these out put bag samples is know as out
of bag error. Study of error estimates by out of bag, gives avidenc
to show that the out of bag estimate is as accurate as using a test
set of the same size as the training set. Therefore, using the out
of bag error estimate removes the need for a set aside test set.</p></li>
</ol>
<p>Cons:</p>
<ol style="list-style-type: decimal">
<li><p>It surely does a good job at classification but not as for
regression problem as it does not gives precise continuous nature
prediction. In case of regression, it doesn’t predict beyond the
range in the training data, and that they may over fit data sets
that are particularly noisy.</p></li>
<li><p>Random forest can feel like a black box approach for a statistical
modelers we have very little control on what the model does. You can
at best try different parameters and random seeds.</p></li>
</ol>
</div>
</div>
</div>
<div id="boosting-1" class="section level3" number="5.11.2">
<h3><span class="header-section-number">5.11.2</span> Boosting</h3>
<p>Pierwsza z siedmiu części z artykułami o algorytmach typu boosting
<a href="https://deep-and-shallow.com/2020/02/02/the-gradient-boosters-i-the-math-heavy-primer-to-gradient-boosting-algorithm/">link:deep-and-shallow</a>
. Linki do kolejnych części są na końcu artykułu.</p>
<div id="ada-boost" class="section level4" number="5.11.2.1">
<h4><span class="header-section-number">5.11.2.1</span> Ada Boost</h4>
<p>Adaptive boosting (adaptacyjne wzmacnianie).</p>
<p>Mam tutaj 2 rodzaje wag:</p>
<ol style="list-style-type: decimal">
<li><p>Wagi modeli. Im lepszy model tym będzie miał w finalnej klasyfikacji
większą wagę.
<span class="math inline">\(\alpha_t = \frac{1}{2}\ln(\frac{1-total.error}{totl.error})\)</span> .
Ponieważ funkcja nie ma wartości dla total_error równe 0 i 1
zazwyczaj dodaje się tutaj jakąś korektę dla zabezpieczenia. Total
error to suma błędów ważonych wagami obserwacji.</p></li>
<li><p>Wagi obserwacji. Obserwacje źle zaklasyfikowane przez i-ty model
mają większą wagę przy następnym modelu. Wagi mogę być używane do
losowania ważonego dla następnego modelu, albo do ważonego Ginii
index używanego do obliczania “impurity.” Wagi dla obserwacji źle
zaklasyfikowanych liczy się ze wzoru :
<span class="math inline">\(nowa.waga = stara.waga \cdot e^{waga.poprzedniego.modelu}\)</span>. Wagi
dla klasyfikacji dobrze zaklasyfikowanych liczy się ze wzoru:
<span class="math inline">\(nowa.waga = stara.waga \cdot e^{- waga.poprzedniego.modelu}\)</span> .</p>
<p>W tym wzorach można dodać współczynnik uczenia w wykładniku
liczby e. Patrz: <span class="citation">(<a href="appendicies.html#ref-Bonaccorso2019" role="doc-biblioref">Bonaccorso 2019</a>)</span> s 263.</p></li>
</ol>
<p>Ada boost- uwagi:</p>
<ul>
<li><p>Zazwyczaj bazuje na drzewach. Jeżeli są to drzewa, to najczęściej
używa się <em>stumps,</em> czyli drzew binarnych z tylko jednym podziałem.</p></li>
<li><p>występuje w m.in następujących wersjach:</p>
<ul>
<li><p>Bazowy AdaBoost do zagadnień binarnych.</p></li>
<li><p>M1 - podstawowy algorytm dla zagadnienia klasyfikacyjnego.
<span class="citation">(<a href="appendicies.html#ref-Raschka2019" role="doc-biblioref">Mirjalili 2019</a>)</span> s 234.</p></li>
<li><p>M2 - (porównanie z M1
<a href="https://www.programmersought.com/article/89144744462/">link</a>)</p></li>
<li><p>SUMME - jest uogólnieniem na zagadnienie wieloklasowego bez
używania podejścia jeden-przeciwko-wszystkim (One-vs-Rest).
Jeżeli robimy model binarny to podeście to redukuje się do
standardowego AdaBoost M1.</p></li>
<li><p>SUMME.R - (litera R od <em>real</em> - AdaBoost rzeczywisty)
rozwinięcie, gdzie wagi są liczone w oparciu o
prawdopodobieństwa. Pełny algorytm w <span class="citation">(<a href="#ref-Bonaccarso2019" role="doc-biblioref"><strong>Bonaccarso2019?</strong></a>)</span> s 268.</p></li>
<li><p>R2 - AdaBoost dla zagadnienia regresyjnego. Pełny algorytm w
<span class="citation">(<a href="#ref-Bonaccarso2019" role="doc-biblioref"><strong>Bonaccarso2019?</strong></a>)</span> s 271.</p></li>
</ul></li>
</ul>
<p>Pseudoalgorym (mój intuicyjny) - dla wariantu M1 w ramach zagadnienia
binarnej klasyfikacji</p>
<ol style="list-style-type: decimal">
<li><p>Ustalam równe wagi dla obserwacji. Ustalam ilość iteracji <em>m</em>.
Ustalam <em>Learning Rate</em></p></li>
<li><p>Buduje pierwszy model</p></li>
<li><p>For t = 1 to n:</p>
<ol style="list-style-type: decimal">
<li><p>Buduje model na predykcjach z poprzedniego modelu.</p></li>
<li><p>Wyliczam wagę modelu proporcjonalną do jego dokładności:
<span class="math inline">\(\alpha_t = \frac{1}{2}\ln(\frac{1-total.error}{totl.error})\)</span></p></li>
<li><p>Wyliczam nowe wagi dla obserwacji. Wagi są większe dla elementów
źle zapredykowanych. Wagi zależą też od wagi modelu. Mało ważny
model ma mniejsze wagi dla elementów źle zapredykowanych. W tym
miejscu można dodać parametr uczący. Waga dla obserwacji źle
zaklasyfikowanych:
<span class="math inline">\(nowa.waga = stara.waga \cdot e^{waga.poprzedniego.modelu}\)</span>.
Waga dla obserwacji dobrze zaklasyfikowanych :
<span class="math inline">\(nowa.waga = stara.waga \cdot e^{- waga.poprzedniego.modelu}\)</span></p></li>
</ol></li>
<li><p>Na koniec jest robiona pełna predykcja gdzie modele z wszystkich
iteracji, głosują z siłą adekwatną do ich wagi.</p></li>
</ol>
<p><strong>SUMME</strong></p>
<p>W AdaBoost M1 dla przypadku binarnego, waga modelu w t-ej iteracji
zdefiniowana jako
<span class="math inline">\(\alpha_t = \frac{1}{2}\ln(\frac{1-total.error}{totl.error})\)</span> przyjmuje
wartość 0 jeżeli model jest losowy, czyli dostajemy 50% źle
zaklasyfikowanych elementów (jeżeli model zaklasyfikował poprawnie mniej
niż 50% to po prostu odwracamy jego predykcje i dostajemy model lepszy
od losowego). Jeżeli jednak mamy więcej klas to próg losowości musi być
inaczej zrobiony i zależny od ilości klas. Model gdzie jest 10
równolicznych klas i dobrze sklasyfikował 50% obserwacji jest dużo
lepszy od modelu losowego. Dlatego wzór na wagę modelu musi zostać
skorygowany.</p>
<p><strong>SUMMER.R</strong></p>
<p>Tutaj wagi modeli dla każdej iteracji są liczone w oparciu o
prawdopodobieństwa przynależności do klas. Każdy model ma inna wagą dla
każdej z klas. Nie jest tak jak w standardowym AdaBoost że jest jedna
waga dla modelu.</p>
<p>Wagi obserwacji też są liczone w oparciu o te prawdopodobieństwa. Przy
tych wagach uwzględniamy też faktyczne wartości empiryczne targetu.</p>
<p>Żeby policzyć wagę t-ego modelu dla k-tej klasy najpierw bierzemy
obserwacje w tej klasy (przynależność do klasy wynika z danych
empirycznych, a nie jest estymowana z modelu). Dla tych obserwacji
liczymy ŚREDNIE wyestymowane z modelu prawdopodobieństwo przynależenia
obserwacji do tej klasy. Przy uśrednianiu prawdopodobieństwa powinny
chyba powinny być używane wagi obserwacji.</p>
<p>Dla danej klasy jest tym większa waga modelu in wyższe jest
prawdopodobieństwo przynależenia tej klasy według modelu.</p>
<p>W modelu decyzja o klasyfikacji i-tej obserwacji jest podejmowana na
podstawie wyboru klasy dla której suma wago modelu po wszystkich
iteracjach jest największa (pamiętajmy że wagi modeli są per klasa).</p>
<p>Algorytm SUMME.R daje wyniki zbieżne do addytywnej regresji
logistycznej. Jest uważany za bardziej efektywny niż klasyczne wersja
AdaBoosta NIE oparta na prawdopodobieństwach.</p>
<p>AdaBoost w R od scratch-a:
<a href="https://rpubs.com/miguelpatricio/adaboost">link:rpubs</a></p>
<p><strong>Assumptions</strong></p>
<ul>
<li><p><strong>Quality Data</strong>: Because the ensemble method continues to attempt
to correct misclassifications in the training data, you need to be
careful that the training data is of a high-quality.</p></li>
<li><p><strong>Outliers</strong>: Outliers will force the ensemble down the rabbit hole
of working hard to correct for cases that are unrealistic. These
could be removed from the training dataset.</p></li>
<li><p><strong>Noisy Data</strong>: Noisy data, specifically noise in the output
variable can be problematic. If possible, attempt to isolate and
clean these from your training dataset.</p></li>
</ul>
<p><strong>Pros</strong></p>
<ul>
<li></li>
</ul>
<p><strong>Cons</strong></p>
<ul>
<li>Boosting technique learns progressively, it is important to ensure
that you have quality data. AdaBoost is also extremely sensitive to
Noisy data and outliers so if you do plan to use AdaBoost then it is
highly recommended to eliminate them.</li>
<li>AdaBoost has also been proven to be slower than XGBoost.</li>
</ul>
</div>
<div id="gradient-boost" class="section level4" number="5.11.2.2">
<h4><span class="header-section-number">5.11.2.2</span> Gradient Boost</h4>
<p>W przeciwieństwie do AdaBoosta używa się tutaj większych drzew
(najczęściej mających od 8 do 32 liści).</p>
<p>Dobre opracowanie:
<a href="https://www.frontiersin.org/articles/10.3389/fnbot.2013.00021/full">link</a>
.</p>
<p>Pseudoalgorytm (mój intuicyjny):</p>
<ol style="list-style-type: decimal">
<li><p>Wybieramy funkcję straty <em>L</em> będą cą naszą funkcją celu którą
będziemy minimalizować. Dla zagadnienia regresji najczęściej jest to
funkcja Mean Squared Error (MSE):</p>
<p><span class="math inline">\(\frac{1}{2}\sum{(y_i-\hat{y_i})^2}\)</span> oraz Mean Absolute Error (MAE):</p>
<p><span class="math inline">\(\sum{|y-\hat{y}|}\)</span></p>
<p>Natomiast dla zagadnienia klasyfikacji binarnej jest to funkcja
log(likelihood) oparta o rozkład Bernulliego:</p>
<p><span class="math inline">\(\sum_{i=1}^n y_i \log p(x_i) + (1 − y_i) \log (1 − p(x_i))\)</span></p>
<p>Inne ciekawe funkcje straty
<a href="https://towardsdatascience.com/the-most-awesome-loss-function-172ffc106c99">link:towardsdatascience</a></p>
<p>Następnie ustalamy inne hiperparametry, jak warunki stopu, parametry
dla <em>weak learnes</em> itp.</p></li>
<li><p>Dla pierwszej iteracji musimy zbudować wartości <span class="math inline">\(\hat{y}\)</span> które będę
punktem wyjścia. Ponieważ jest to punkt startowy nie mam tutaj
jeszcze oszacowanego modelu. Aby uzyskać wyjściowe wartości
<span class="math inline">\(\hat{y}\)</span> bez budowania modelu zakładamy, że będę one identyczne dla
wszystkich obserwacji stanowiąc naszą jedną niewiadomą. To
pojedynczą niewiadomą szukamy jej wstawienie do równania które
minimalizujemy:</p>
<p><span class="math inline">\(\underset{\gamma}{argmin}=\sum{L(y_i, \gamma)}\)</span>, gdzie L to funkcja
straty. Tak więc jeżeli funkcja jest różniczkowalna liczy jej
pochodną, przyrównujemy do zera i szukamy naszej pojedynczej
niewiadomej <span class="math inline">\(\gamma\)</span>, którą potem potraktujemy jako nasze <span class="math inline">\(\hat{y}\)</span>.</p></li>
<li><p>For i in t (t - kolejna iteracja):</p>
<ol style="list-style-type: decimal">
<li><p>Muszę teraz wyznaczyć wartości w oparciu o której buduje model.
Nie bierzemy tutaj czystych wartości <span class="math inline">\(y_i\)</span>. Istotą algorytmy
jest aby predykowane wartości które potem dodajemy do wartości
wyjściowych (dla pierwszej iteracji ta wartość wyjściowa to
wartość wyliczona w punkcie 2, a dla kolejnych to ta wartości
plus skumulowane predykcje z kolejnych modeli), dodawać takie
wartości które podążają za gradientem funkcji celu. Przykładowo
w przypadku funkcji celu MSE gradient sprowadza się do reszt
<span class="math inline">\(y_i-\hat{y_i}\)</span>. Dla funkcji log(likelihood) opartego o rozkład
Bernulliego to będą z kolei różnice wartości empirycznych {0,1}
i prawdopodobieństw wyliczonych przez przekształcenie log(odds).
Ponieważ jak widać, dla najpopularniejszych funkcji celu,
gradient redukuje się do jakiejś formy reszt, często nazywa się
do pseudo-resztami. Dodatkowo wartości oparte o pseudoreszy są
dodawana w skumulowany sposób tak aby zminimalizować różnice
wartości empirycznych i predykowanych, co każde je też traktować
jako składowe reszt naszego całego modelu (<em>strong learner-a</em>).</p></li>
<li><p>Buduję model <em>weak learner</em> w oparciu o wartości pseudo-reszt
wyznaczone w punkcie 1. Tutaj warto dodać, że powstałe drzewa
się zazwyczaj przycina.</p></li>
<li><p>Teraz wartości predykcyjne (pseudo-reszty) z uzyskane w <em>weak
lernar-a</em> dodatkowo przekształcam, głównie żeby ograniczyć
zjawisko overfittingu, ale również po to żeby wartości z
predykcji były przekształcić tak aby ich definicja była spójna z
wartościami z poprzednich iteracji, dzięki czemu możemy dokonać
agregacji nowych wartości z poprzednimi. Jeżeli nasze <em>weak
learner</em> jest drzewem to:</p>
<ol style="list-style-type: decimal">
<li><p>Stosujemy procedurę z punktu pierwszego, ale teraz
indywidualnie do każdego liścia. W ten sposób dla wielu
wartości w każdego liścia dostajemy jedną bardziej
syntetyczną “odszuminą” wartość predykcji. Dodatkowo w
przypadku log(likelihood) opartego o rozkład Bernulliego ,
dostajemy przekształcenie predykowanych przez model
prawdopodobieństwa na log(odds), którą możemy dodać do
wartości uzyskanych z sumowania wyników z poprzednich
iteracji. W przypadku regresji i funkcji straty MSE
obliczaliśmy reszty które bez problemu możemy dodać do
wartości z poprzednich iteracji.</p></li>
<li><p>Uzyskane wartości, zanim dodamy do zsumowanych wartości z
poprzednich iteracji, mnożymy przez *learning rate" aby
zapobiegać szybkiemu przetrenowaniu.</p></li>
</ol></li>
</ol></li>
</ol>
<p>Pseudoalgorytm:</p>
<p><img src="03_TARGET/figures/gradient_boost_algorytm.png" /></p>
<p>Miejsca gdzie GradienBoost może optymalizowany.</p>
<ul>
<li><p><em>weak learners</em>, zwłaszcza chodzi tutaj o szybsze trenowanie drzew.</p></li>
<li><p>problem wycieku informacji, polegający na tym że model w punkcie 3.2
algorytmu predykuje na wartościach na których był trenowany</p></li>
<li><p>Wybór innej funkcji celu</p></li>
<li><p>prepoces danych zwłaszcza danych jakościowych, głównie pod kątem
przyśpieszenia obliczeń.</p></li>
</ul>
<p>Jest wiele propozycji algorytmów które optymalizacji tych obszarów.
Najpopularniejsze to:</p>
<ul>
<li><p>xgboost</p></li>
<li><p>catboost</p></li>
<li><p>lgbm</p></li>
</ul>
</div>
<div id="xgboost" class="section level4" number="5.11.2.3">
<h4><span class="header-section-number">5.11.2.3</span> XGBoost</h4>
<p>Oryginalna praca na temat Xgboosting-u:
<a href="https://arxiv.org/pdf/1603.02754.pdf">link</a> (XGBoost: A Scalable Tree,
by Tianqi Chen and Carlos Guestrin)</p>
<p>Tutaj w przypadku funkcji celu w stosunku do GradienBoost-a stosujemy
dodatkowo regularyzację L1.</p>
<p>Ponadto metoda ma swój specyficzny sposób budowy drzew.</p>
<ul>
<li><p>Zamiast współczynnika Gini-ego do badania optymalności podziału
węzła używa się miary <em>similarity</em>.</p>
<p>Uwaga: miara <em>similarity</em> została wprowadzone w celu przyspieszenia
obliczeń. Dzieje się to w ten sposób że jest ona powiązana w
wartościami output z liści (wartości które finalnie są agregowane w
całym modelu). <em>similarity</em> to maksimum funkcji celu ze względu na
output z liści (zmienną są różne możliwe wartości output-u
podstawiane pod funkcję celu). To powiązanie powoduje że po
ostatecznym splicie mając policzone <em>similarity</em> może szybko
policzyć <em>output</em>. Wyprowadzenie <em>similarity</em> jest w fimiku ze
StatQuest na temat Xgboost (część 3, 20:00).</p></li>
<li><p>W takcie analizy podziału, dodatkowo jest wyliczany parametr
<em>cover</em>, który musi mieć odpowiednie wartości aby zaakceptować
istnienie danego podziału węzła. Jest on równy dla klasyfikacji
binarnej mianownikowi <em>similarity</em> bez parametru <span class="math inline">\(\lambda\)</span>. Więc mam
tutaj wbudowane coś w rodzaju hamowania rozrostu drzewa. Niezależnie
od tego robi cię tutaj przycinanie, ale oparte o poprawię wartości
<em>similarity</em> (przypomnijmy, że ta miara jest używana zamiast Gini).
W przypadku dużych zbiorów danych szukanie optymalnego punktu
odcięcia jest oparte o ważone kwantylowe histogramy. Najpierw waży
się obserwacje w oparciu o wspomniany wcześniej parametr <em>cover</em>
(tutaj mamy jego drugie zastosowanie). Tylko tutaj mamy wartość per
obserwacja, a wcześniej wartości per obserwacja agregowaliśmy dla
całego liścia. Następnie buduje się kwantyle tak, aby w każdym
kwantylu była równa ilość obserwacji, ale w uwzględnieniem wag. To
powoduje, że jest tendencja do grupowania w kwantylach oddzielnie
obserwacji które mają niskie i oddzielnie wysokie cover. Wysoki
<em>cover</em> jest przypisany obserwacją które mają niską ufność
predykcji, czyli w np. przypadku zagadnienia binarnego model
predykuje dla nich <em>p</em> równe ok 0.5. Obliczania ważonych
kwantylowych histogramów jest zaimplementowane tak aby było możliwe
obliczenia równoległe.</p></li>
<li><p>Algorytm ten dodatkowo ma zaimplementowany mechanizm raczenia sobie
z brakami danych. Standardowo w GradienBoosting-u braki po prostu są
nie brane pod uwagę przy trenowaniu drzewa. W Xgboost wygląda to
tak:</p>
<p><img src="03_TARGET/figures/xgboost_missing_values.PNG" /></p></li>
</ul>
<p>Podsumowanie parametrów <em>similarity</em> i <em>output</em> dla regresji i
klasyfikacji związanych z XGboost:</p>
<p><img src="03_TARGET/figures/xgboost_equations.PNG" /></p>
</div>
<div id="catboost" class="section level4" number="5.11.2.4">
<h4><span class="header-section-number">5.11.2.4</span> CatBoost</h4>
<p>Więcej o catboost:
<a href="https://towardsdatascience.com/catboost-demystified-8b0b538bfa31">link:towardsdatascience</a></p>
<p>W przeciwieństwie do Gradient Boosta tutaj:</p>
<ul>
<li><p>Domyślnie buduje się symetryczne drzewa. These are trees the same
features are responsible in splitting learning instances into the
left and the right partitions for each level of the tree.
Symetryczne drzewa dają następujące korzyści:</p>
<ul>
<li><p>Regularization: Since we are restricting the tree building
process to have only one feature split per level, we are
essentially reducing the complexity of the algorithm and thereby
regularization.</p></li>
<li><p>Computational Performance: One of the most time consuming part
of any tree-based algorithm is the search for the optimal split
at each nodes. But because we are restricting the features split
per level to one, we only have to search for a single feature
split instead of k splits, where k is the number of nodes in the
level. Even during inference these trees make it lightning fast.
It was shown to be 8X faster than XGBoost in inference.</p></li>
</ul></li>
<li><p>Aby zapobiec problemowy wyciekania informacji w trenowaniu drzew
zastosowano *Ordered boosting* . Najpierw permutujemy zbiór.
Permutacja wprowadza losowość dodatkowo zabezpieczając przed
overfittingiem. Następnie robimy log(m) (gdzie m to ilość
obserwacji) podziałów danych na zbiór trenujący i uczący tak aby
zbiory te były rozłączne. Na zbiorach trenujących trenujemy a na
testowych predykujemy.</p></li>
<li><p>Jest możliwość automatycznego enkodowania danych jakościowych. Wtedy
używamy algorytmu: We replace a categorical value by the mean of all
the targets for the training samples with the same categorical
value. For example, we have a Categorical value called weather,
which has four values – sunny, rainy, cloudy, and snow. The most
naive method is something called Greedy Target Statistics, where we
replace “sunny” with the average of the target value for all the
training samples where weather was “sunny.”</p>
<p>If M is the categorical feature we are encoding and <span class="math inline">\(m_i\)</span> is the
specific value in M, and n is the number of training samples with
<span class="math inline">\(M = m_i\)</span>.</p>
<p><span class="math inline">\(Geedy TS_{M=m_i} = \frac{\sum_{i}^{n}(y_i)}{n} \quad For \quad all \quad M=m_i\)</span></p>
<p>But this is unstable when the number of samples with <span class="math inline">\(m_i\)</span> is too
low or zero. Therefore we use the <a href="https://towardsdatascience.com/introduction-to-na%C3%AFve-bayes-classifier-fa59e3e24aaf">Laplace Smoothing used in Naive
Bayes
Classifier</a>
to make the statistics much more robust.</p>
<p><span class="math inline">\(Geedy TS_{M=m_i} = \frac{\sum_{i}^{n}(y_i)+ap}{n+a} \quad For \quad all \quad M=m_i\)</span></p>
<p>where <em>a</em> &gt; 0 is a parameter. A common setting for <em>p</em> (prior) is
the average target value in the dataset.</p></li>
<li><p>Jest zaimplementowany dektor overfittingu: Another interesting
feature in CatBoost is the inbuilt Overfitting Detector. CatBoost
can stop training earlier than the number of iterations we set, if
it detects overfitting. there are two overfitting detectors
implemented in CatBoost –</p>
<ol style="list-style-type: decimal">
<li><p>IncToDec</p></li>
<li><p>Iter</p></li>
</ol>
<p><a href="https://catboost.ai/docs/concepts/overfitting-detector.html#iter"><em>Iter</em></a>is
the equivalent of early stopping where the algorithm waits for <em>n</em>
iterations since an improvement in validation loss value before
stopping the iterations</p>
<p><a href="https://catboost.ai/docs/concepts/overfitting-detector.html#inctodec"><em>IncToDec</em></a>is
more slightly involved. It takes a slightly complicated route by
keeping track of the improvement of the metric iteration after
iteration and also smooths the progression using an approach similar
to exponential smoothing and sets a threshold to stop training
whenever that smoothed value falls below it.</p></li>
<li><p>Jest zimplementowane raczenie sobie z brakami w danych: If you
select “Min,” the missing values are processed as the minimum value
for the feature. And if you select “Max,” the missing values are
processed as the maximum value for the feature. In both cases, it is
guaranteed that the split between missing values and others are
considered in every tree split.</p></li>
</ul>
<p>Dokumentacja pod Python :
<a href="https://catboost.ai/docs/concepts/python-reference_parameters-list.html">link</a></p>
</div>
<div id="lightgbm" class="section level4" number="5.11.2.5">
<h4><span class="header-section-number">5.11.2.5</span> LightGBM</h4>
<p><a href="https://towardsdatascience.com/what-makes-lightgbm-lightning-fast-a27cf0d9785e">towardsdatascience</a></p>
<p>W stosunku do podstawowego GradienBoosta:</p>
<ul>
<li><p>Budujemy drzewa matodą <em>life-wise</em>, zamist <em>level-wise</em>. In
LightGBM, the leaf-wise tree growth finds the leaves which will
reduce the loss the maximum, and split only that leaf and not bother
with the rest of the leaves in the same level. This results in an
asymmetrical tree where subsequent splitting can very well happen
only on one side of the tree.</p>
<p>Leaf-wise tree growth strategy tend to achieve lower loss as
compared to the level-wise growth strategy, but it also tends to
overfit, especially small datasets. So small datasets, the
level-wise growth acts like a regularization to restrict the
complexity of the tree, where as the leaf-wise growth tends to be
greedy.</p></li>
<li><p>Zmienne przekształcamy metodą Exclusive Feature Bundling (EBF).
Przykład w pliku Excel w materials.</p></li>
<li><p>Aby zapobiec problemowy wyciekania informacji w trenowaniu drzew
zastosowano <strong>Gradient-based One-Side Sampling (GOSS).</strong> Tutaj
sortujemy pseudoreszty. Wypieramy top x % największych reszt. Potem
z pozostałych (niewybranych) dolosowujemy próbkę. Oba zbiory łączymy
i dostajemy zbiór do trenowania modelu. Predykcja jest potem robiona
na wszystkich obserwacjach. Ponieważ nie wszystkie predykowane
wartości są w zbiorze treningowym, to ograniczamy wyciek informacji.
Dodatkowo duże pseud-reszty są liczniej reprezentowane w zbiorze
uczącym co przyśpiesza uczenie (jest to rodzaj downsamplingu).</p></li>
</ul>
<p><strong>Pros</strong></p>
<ul>
<li></li>
</ul>
<p><strong>Cons</strong></p>
<ul>
<li>It is not advisable to use LGBM on small datasets. Light GBM is
<strong>sensitive to overfitting</strong> and can easily overfit small data.
Their is no threshold on the number of rows but my experience
suggests me to use it only for data with 10,000+ rows.</li>
</ul>
<p><strong>Split z użyciem histogramu</strong></p>
<p>Split finding algorithms are used to find candidate splits.</p>
<p>One of the most popular split finding algorithm is the Pre-sorted
algorithm which enumerates all possible split points on pre-sorted
values. This method is simple but highly inefficient in terms of
computation power and memory .</p>
<p><img src="03_TARGET/figures/histogram_spit_on_tree.png" /></p>
<p>The second method is the Histogram based algorithm which buckets
continuous features into discrete bins to construct feature histograms
during training. It costs O(#data * #feature) for histogram building
and O(#bin * #feature) for split point finding. As bin &lt;&lt; data
histogram building will dominate the computational complexity.</p>
<p><strong>GOSS (Gradient Based One Side Sampling)</strong></p>
<p>GOSS (Gradient Based One Side Sampling) is a novel sampling method which
down samples the instances on basis of gradients. As we know instances
with small gradients are well trained (small training error) and those
with large gradients are under trained. A naive approach to downsample
is to discard instances with small gradients by solely focussing on
instances with large gradients but this would alter the data
distribution. In a nutshell GOSS retains instances with large gradients
while performing random sampling on instances with small gradients.</p>
<p>Intuitive steps for GOSS calculation:</p>
<p>1. Sort the instances according to absolute gradients in a descending
order</p>
<p>2. Select the top a * 100% instances. [ Under trained / large
gradients ]</p>
<p>3. Randomly samples b * 100% instances from the rest of the data. This
will reduce the contribution of well trained examples by a factor of b (
b &lt; 1 )</p>
<p>4. Without point 3 count of samples having small gradients would be 1-a
( currently it is b ). In order to maintain the original distribution
LightGBM amplifies the contribution of samples having small gradients by
a constant (1-a)/b to put more focus on the under-trained instances.
This puts more focus on the under trained instances without changing the
data distribution by much.</p>
<p><strong>Dobieranie parametrów</strong>
<a href="https://www.analyticssteps.com/blogs/what-light-gbm-algorithm-how-use-it">link</a></p>
<p><em>If you need to speed up the things faster:</em></p>
<ul>
<li><p>Assign small values to max_bin.</p></li>
<li><p>Make use of bagging by bagging fraction and bagging frequency.</p></li>
<li><p>By setting feature_fraction use feature sub-sampling.</p></li>
<li><p>To speed up data loading in the future make use of save_binary.</p></li>
</ul>
<p><em>If you want to good accuracy:</em></p>
<ul>
<li><p>With a big value of num_iterations make use of small learning_rate.</p></li>
<li><p>Assign large values to max_bin. </p></li>
<li><p>Assign big value to num_leaves.</p></li>
<li><p>Your training data should be bigger in size.</p></li>
<li><p>Make use of categorical features directly. </p></li>
</ul>
<p><em>If you want to deal with overfitting of the model</em></p>
<ul>
<li><p>Assign small values to max_bin and num_leaves.</p></li>
<li><p>Make use of a large volume of training data.</p></li>
<li><p>Make use of max_depth so as to avoid deep trees.</p></li>
<li><p>Make use of bagging by setting bagging_fraction and bagging_freq.</p></li>
<li><p>By setting feature_fraction use feature sub-sampling.</p></li>
<li><p>Make use of l1 and l2 &amp; min_gain_to_split to regularization.</p></li>
</ul>
<p><a href="https://towardsdatascience.com/what-makes-lightgbm-lightning-fast-a27cf0d9785e">link:tword_data_sience</a></p>
</div>
</div>
<div id="stacking-1" class="section level3" number="5.11.3">
<h3><span class="header-section-number">5.11.3</span> Stacking</h3>
</div>
<div id="twicing" class="section level3" number="5.11.4">
<h3><span class="header-section-number">5.11.4</span> Twicing</h3>
</div>
<div id="bandling" class="section level3" number="5.11.5">
<h3><span class="header-section-number">5.11.5</span> Bandling</h3>
</div>
</div>
<div id="neural-networks-2" class="section level2" number="5.12">
<h2><span class="header-section-number">5.12</span> Neural Networks</h2>
<div id="introduction-6" class="section level3" number="5.12.1">
<h3><span class="header-section-number">5.12.1</span> Introduction</h3>
</div>
<div id="basics-2" class="section level3" number="5.12.2">
<h3><span class="header-section-number">5.12.2</span> Basics</h3>
</div>
<div id="reccurent" class="section level3" number="5.12.3">
<h3><span class="header-section-number">5.12.3</span> Reccurent</h3>
<div id="simple-reccurent" class="section level4" number="5.12.3.1">
<h4><span class="header-section-number">5.12.3.1</span> Simple reccurent</h4>
</div>
<div id="bidirectorial" class="section level4" number="5.12.3.2">
<h4><span class="header-section-number">5.12.3.2</span> Bidirectorial</h4>
</div>
<div id="lstm" class="section level4" number="5.12.3.3">
<h4><span class="header-section-number">5.12.3.3</span> LSTM</h4>
</div>
<div id="gru" class="section level4" number="5.12.3.4">
<h4><span class="header-section-number">5.12.3.4</span> GRU</h4>
</div>
<div id="attention" class="section level4" number="5.12.3.5">
<h4><span class="header-section-number">5.12.3.5</span> Attention</h4>
</div>
</div>
<div id="cnn" class="section level3" number="5.12.4">
<h3><span class="header-section-number">5.12.4</span> CNN</h3>
</div>
<div id="resnet" class="section level3" number="5.12.5">
<h3><span class="header-section-number">5.12.5</span> Resnet</h3>
</div>
</div>
<div id="stochastic-processes-1" class="section level2" number="5.13">
<h2><span class="header-section-number">5.13</span> Stochastic processes</h2>
<div id="basic-trend-models" class="section level3" number="5.13.1">
<h3><span class="header-section-number">5.13.1</span> Basic trend models</h3>
</div>
<div id="basic-adaptative-models" class="section level3" number="5.13.2">
<h3><span class="header-section-number">5.13.2</span> Basic adaptative models</h3>
</div>
<div id="econometric-time-series-models" class="section level3" number="5.13.3">
<h3><span class="header-section-number">5.13.3</span> Econometric time series models</h3>
<div id="dynamic-for-example-error-correction-models" class="section level4" number="5.13.3.1">
<h4><span class="header-section-number">5.13.3.1</span> dynamic (for example error correction models)</h4>
</div>
<div id="sarimax" class="section level4" number="5.13.3.2">
<h4><span class="header-section-number">5.13.3.2</span> SARIMAX</h4>
</div>
<div id="varimax" class="section level4" number="5.13.3.3">
<h4><span class="header-section-number">5.13.3.3</span> VARIMAX</h4>
</div>
<div id="arch-class-models" class="section level4" number="5.13.3.4">
<h4><span class="header-section-number">5.13.3.4</span> ARCH class models</h4>
</div>
<div id="cointegration-including-arld-approach" class="section level4" number="5.13.3.5">
<h4><span class="header-section-number">5.13.3.5</span> Cointegration (including ARLD approach)</h4>
</div>
</div>
<div id="time-series-decomposition-decomposition" class="section level3" number="5.13.4">
<h3><span class="header-section-number">5.13.4</span> Time series decomposition decomposition</h3>
</div>
<div id="kalman-filters" class="section level3" number="5.13.5">
<h3><span class="header-section-number">5.13.5</span> Kalman filters</h3>
</div>
<div id="neural-networks-3" class="section level3" number="5.13.6">
<h3><span class="header-section-number">5.13.6</span> Neural Networks</h3>
<div id="long-short-term-memory" class="section level4" number="5.13.6.1">
<h4><span class="header-section-number">5.13.6.1</span> Long short term memory</h4>
</div>
<div id="cnn-1" class="section level4" number="5.13.6.2">
<h4><span class="header-section-number">5.13.6.2</span> CNN</h4>
</div>
</div>
<div id="panel-regression" class="section level3" number="5.13.7">
<h3><span class="header-section-number">5.13.7</span> Panel Regression</h3>
</div>
<div id="gaussian-process" class="section level3" number="5.13.8">
<h3><span class="header-section-number">5.13.8</span> Gaussian Process</h3>
<p>Linki:</p>
<p><a href="https://royalsocietypublishing.org/doi/10.1098/rsta.2011.0550">Gaussian processes for time-series
modelling</a></p>
<p><a href="https://towardsdatascience.com/understanding-gaussian-process-the-socratic-way-ba02369d804">understanding-gaussian-process-the-socratic-way</a></p>
<p>Intuicja jest następująca.</p>
<p>Wielowymiarowy rozkład normalny jest określony przez macierz kowariancji
i wektor wartości oczekiwanych. Jednak co jeżeli wymiarów jest dużo albo
nieskończenie wiele. Wtedy używanie macierzy jest nieporęczna, albo
niemożliwe. Uogólnieniem rozkładu normalnego na nieskończenie-wymiarową
przestrzeń są procesy gaussowskie (gaussian process). Tutaj wartość
oczekiwana i korelacje są funkcjami. Funkcje korelacji są wyrażane przez
tzw. jądra (kernels). Po podstawieniu dwóch wartości (czyli wybieramy 2
wymiary) dostajemy korelacje dla dwóch rozkładów normalnych.</p>
<p>Nieskończenie wymiarowy rozkład użytecznie jest zrzutować na 2 wymiary.
W tym przypadku każdy punkt na osi x będzie odpowiadał jednemu
wymiarowy. Przykładowo poniżej punkt w rozkłady normalnego
dwuwymiarowego zrzutowano w taki sposób:</p>
<p><img src="03_TARGET/figures/gaussian_process_1.png" /></p>
<p>Poniżej mamy więcej wymiarów i rzutujemy całe rozkłady:</p>
<p><img src="03_TARGET/figures/gaussian_process_2.png" /></p>
<p>Wymiarów może być nieprzeliczalna ilość.</p>
<p><strong>Predykcja</strong></p>
<p>Wykonuje się ją warunkowo:</p>
<p><img src="03_TARGET/figures/gaussian_process_3.png" /></p>
<p>Powyżej mamy dany zestaw obserwacji y2. Chcemy na jego odstawie
zapredykować y1. Predykcja będzie zależeć od tego jaki kernele opisujące
korelacje przyjmiemy. Występują pewne podstawowe rodzaje kerneli (patrz
dalej) które możemy łączyć różnymi tranformacjami. Takie podstawowe
kernele mają pewne parametry który można dobrać tak aby z jak
największym prawdopodobieństwem przewidywał nasze punkty empiryczne
(y1). Wtedy możemy wykonań predykcje dla innych wartości.</p>
<p><strong>Kernele</strong></p>
<p><a href="https://peterroelants.github.io/posts/gaussian-process-kernels/">link</a></p>
<p><strong>White noise kernel</strong></p>
<p><span class="math display">\[
k(x, x) = \sigma^2 I_n
\]</span></p>
<p><strong>Exponentiated quadratic kernel</strong></p>
<p><span class="math display">\[
k(x_a, x_b) = \sigma^2 \exp \left(-\frac{ \left\Vert x_a - x_b \right\Vert^2}{2\ell^2}\right)
\]</span></p>
<ul>
<li><p>σ2 the overall variance (σ is also known as amplitude).</p></li>
<li><p>ℓ the lengthscale.</p></li>
</ul>
<p><img src="03_TARGET/figures/gaussian_process_kernel_1.png" /></p>
<p><strong>Rational quadratic kernel</strong></p>
<p><span class="math display">\[
k(x_a, x_b) = \sigma^2 \left( 1 + \frac{ \left\Vert x_a - x_b \right\Vert^2}{2 \alpha \ell^2} \right)^{-\alpha}
\]</span></p>
<ul>
<li><p>σ2 the overall variance (σ is also known as amplitude).</p></li>
<li><p>ℓ the lengthscale.</p></li>
<li><p>α the scale-mixture (α &gt; 0).</p></li>
</ul>
<p><img src="03_TARGET/figures/gaussian_process_kernel_2.png" /></p>
<p><strong>Periodic kernel</strong></p>
<p><span class="math display">\[
k(x_a, x_b) = \sigma^2 \exp \left(-\frac{2}{\ell^2}\sin^2 \left( \pi \frac{\lvert x_a - x_b \rvert}{p}\right) \right)
\]</span></p>
<ul>
<li><p>σ2 the overall variance (σ is also known as amplitude).</p></li>
<li><p>ℓ the lengthscale.</p></li>
<li><p>p the period, which is the distance between repetitions.</p></li>
</ul>
<p><img src="03_TARGET/figures/gaussian_process_kernel_3.png" /></p>
<p><strong>Local periodic kernel</strong></p>
<p>The local periodic kernel is a multiplication of the periodic kernel
with the exponentiated quadratic kernel to allow the periods to vary
over longer distances. Note that the variance parameters σ2 are combined
into one.</p>
<p><span class="math display">\[
k(x_a, x_b) = \sigma^2 \exp \left(-\frac{2}{\ell_p^2}\sin^2 \left( \pi \frac{\lvert x_a - x_b \rvert}{p}\right) \right)\exp \left(-\frac{ \left\Vert x_a - x_b \right\Vert^2}{2\ell_{eq}^2}\right)
\]</span></p>
<ul>
<li><p>σ2 the overall variance (σ is also known as amplitude).</p></li>
<li><p>ℓp lengthscale of the periodic function.</p></li>
<li><p>p the period.</p></li>
<li><p>ℓeq the lengthscale of the exponentiated quadratic.</p></li>
</ul>
<p><img src="03_TARGET/figures/gaussian_process_kernel_4.png" /></p>
<p><strong>Inne zagadnienia</strong></p>
<p>Porównanie Gaussian Process Regression i Kernel Ridge Regression
(<a href="https://gregorygundersen.com/blog/2020/01/06/kernel-gp-regression/">link</a>)</p>
</div>
<div id="ensembled-models-1" class="section level3" number="5.13.9">
<h3><span class="header-section-number">5.13.9</span> Ensembled models</h3>
</div>
<div id="martingales" class="section level3" number="5.13.10">
<h3><span class="header-section-number">5.13.10</span> Martingales</h3>
</div>
<div id="markov-process" class="section level3" number="5.13.11">
<h3><span class="header-section-number">5.13.11</span> Markov Process</h3>
</div>
<div id="winer-process" class="section level3" number="5.13.12">
<h3><span class="header-section-number">5.13.12</span> Winer Process</h3>
</div>
</div>
<div id="results-diagnostics-5" class="section level2" number="5.14">
<h2><span class="header-section-number">5.14</span> Results diagnostics</h2>
<div id="classification-4" class="section level3" number="5.14.1">
<h3><span class="header-section-number">5.14.1</span> Classification</h3>
<div id="measures" class="section level4" number="5.14.1.1">
<h4><span class="header-section-number">5.14.1.1</span> Measures</h4>
<div id="negative-log-likelihood" class="section level5" number="5.14.1.1.1">
<h5><span class="header-section-number">5.14.1.1.1</span> Negative log likelihood</h5>
<p>Well, to calculate the likelihood we have to use the probabilities. To
continue with the example above, imagine for some input we got the
following probabilities: [0.1, 0.3, 0.5, 0.1], 4 possible classes. If
the true answer would be the forth class, as a vector [0, 0, 0, 1], the
likelihood of the current state of the model producing the input is:</p>
<p>0*0.3 + 0*0.1 + 0*0.5 + 1*0.1 = 0.1.</p>
<p>NLL: -ln(0.1) = 2.3</p>
<p><strong>Can I use it for binary classification?</strong></p>
<p>Yes, of course, but usually frameworks have it’s own binary
classification loss functions.</p>
<p><strong>Can I use it for multi-label classification?</strong></p>
<p>Yes, you can. Take a look on <a href="https://gombru.github.io/2018/05/23/cross_entropy_loss/">this
article</a> about
the different ways to name cross entropy loss. Hold on! “cross entropy
loss.” What’s that? From wikipedia:</p>
</div>
<div id="cross-entrophy" class="section level5" number="5.14.1.1.2">
<h5><span class="header-section-number">5.14.1.1.2</span> Cross entrophy</h5>
<p>Dobre przykłady:
<a href="https://towardsdatascience.com/entropy-cross-entropy-and-kl-divergence-explained-b09cdae917a">link</a></p>
<p>true labels = [1,0], [0,1], [0,1], [0,1], [0,1] # do ktorej z dwoch
klas faktycznie nalezy obserwacja</p>
<p>predicted = [0.1, 0.9], [.5, .5], [.1, .9], [.1, .9], [.2, .8] #
prawdopodobienstwo z modelu</p>
<p>CE = -[ ln(.1) + ln(0.5) + ln(0.9) + ln(0.9) + ln(0.8)] = 3.4</p>
</div>
</div>
<div id="scores-calibration" class="section level4" number="5.14.1.2">
<h4><span class="header-section-number">5.14.1.2</span> Scores calibration</h4>
<div id="problem" class="section level5" number="5.14.1.2.1">
<h5><span class="header-section-number">5.14.1.2.1</span> Problem</h5>
<p>Kalibracja dotyczy</p>
<ul>
<li>prawdopodobieństwa które nie odpowiadaj poziomom ufnosci</li>
<li>miara (scores) z modeli które nia sa prawdopodobieństwami (SVM
zwraca score jako odleglosc obserwacji o hiperplaszczyzny
separujacej, a w K-NN mozemy budowac miary oparte o odleglosci
miedzy obserwacjami - wiecej w k-NN dla klasyfikacji) ale chcemy,
aby te scory byly przerobione na prawdopodobienstwa</li>
<li>nie wiem co z przypadkiem kiedy mamy same ‘labels’ z modelu i czy
można je przeksztaca na prawdopodobieństwo. Jednak takie modele sa
rzadkoscia: Nearly every classifier - ogistic regression, a neural
net, a decision tree, a k-NN classifier, a support vector machine,
etc. — can produce a score instead of (or in addition to) a class
label.1</li>
</ul>
</div>
<div id="kalibracja-a-problemy-konkretnych-modeli" class="section level5" number="5.14.1.2.2">
<h5><span class="header-section-number">5.14.1.2.2</span> Kalibracja a problemy konkretnych modeli</h5>
<p><strong>Random Forest</strong>: RandomForestClassifier shows the opposite behavior:
the histograms <strong>show peaks at approximately 0.2 and 0.9 probability,
while probabilities close to 0 or 1 are very rare</strong>. An explanation for
this is given by Niculescu-Mizil and Caruana 1: “Methods such as bagging
and random forests that average predictions from a base set of models
can have difficulty making predictions near 0 and 1 because variance in
the underlying base models will bias predictions that should be near
zero or one away from these values. Because predictions are restricted
to the interval [0,1], errors caused by variance tend to be one-sided
near zero and one. For example, if a model should predict p = 0 for a
case, the only way bagging can achieve this is if all bagged trees
predict zero. If we add noise to the trees that bagging is averaging
over, this noise will cause some trees to predict values larger than 0
for this case, thus moving the average prediction of the bagged ensemble
away from 0. We observe this effect most strongly with random forests
because the base-level trees trained with random forests have relatively
high variance due to feature subsetting.” As a result, the calibration
curve also referred to as the reliability diagram (Wilks 1995 2) shows a
characteristic sigmoid shape, indicating that the classifier could trust
its “intuition” more and return probabilities closer to 0 or 1
typically.</p>
<p><strong>LogisticRegression</strong>: Returns well calibrated predictions by default
as it directly optimizes Log loss. In contrast, the other methods return
biased probabilities; with different biases per method:</p>
<p><strong>GaussianNB</strong>: Tends to push probabilities to 0 or 1 (note the counts
in the histograms). This is mainly because it makes the assumption that
features are conditionally independent given the class, which is not the
case in this dataset which contains 2 redundant features.</p>
<p><strong>Linear Support Vector Classification (LinearSVC)</strong>: shows an even more
sigmoid curve than RandomForestClassifier, which is typical for
maximum-margin methods (compare Niculescu-Mizil and Caruana 1), which
focus on difficult to classify samples that are close to the decision
boundary (the support vectors).</p>
</div>
<div id="calibration-curve-reliability-diagram" class="section level5" number="5.14.1.2.3">
<h5><span class="header-section-number">5.14.1.2.3</span> Calibration curve (reliability diagram)</h5>
<p><a href="https://journals.ametsoc.org/view/journals/wefo/22/3/waf993_1.xml">how to make
it</a></p>
<p>First, the forecast values are partitioned into bins Bk, k = 1, . . . ,
K (which form a partition of the unit interval into nonoverlapping
exhaustive subintervals). The Bk are often taken to be of equal width,
but if the distribution of the forecast values is nonuniform, then
choosing the bins so that they are equally populated is an attractive
alternative.</p>
<p>Next, for each i, it is established which of the K bins the forecast
value Xi falls into. For each bin Bk, let Ik be the collection of all
indices i for which Xi falls into bin Bk; that is,</p>
<p><span class="math inline">\(I_k:=\{i;X_i \in B_k\}\)</span></p>
<p>The corresponding observed relative frequency fk is the number of times
the event happens, given that Xi ∈ Bk, divided by the total number of
forecast values Xi ∈ Bk. This can be expressed as:</p>
<p><span class="math inline">\(f_k=\frac{\sum_{i \in I_k}^{}{Y_i}}{\#I_k}\)</span></p>
<p>where #Ik denotes the number of elements in Ik. Each bin Bk is
represented by a single “typical” forecast probability rk. Although the
arithmetic center of the bin is often used to represent the forecast
values in that bin, this method has a clear disadvantage: If the
forecast is reliable, the observed relative frequency for a given bin Bk
is expected to coincide with the average of the forecast values over
that bin Bk, rather than with the arithmetic center of the bin. Plotting
the observed relative frequency over the arithmetic center can cause
even a perfect reliability diagram to be off the diagonal by up to half
the width of a bin. In this paper, observed relative frequencies for a
bin Bk are plotted versus the average of the forecast values over bin
Bk. This average, denoted by rk, is:</p>
<p><span class="math inline">\(r_k:=\frac{\sum_{i \in I_k}{X_i}}{\#I_k}\)</span></p>
<p>The reliability diagram comprises a plot of <span class="math inline">\(f_k\)</span> versus rk for all bins
<span class="math inline">\(B_k\)</span>.</p>
</div>
<div id="skalowanie-platta" class="section level5" number="5.14.1.2.4">
<h5><span class="header-section-number">5.14.1.2.4</span> Skalowanie Platta</h5>
<p><a href="https://medium.com/@nupur94/calibration-of-models-45721a221da6">link</a></p>
<p><strong>Steps</strong> for applying Platt scaling</p>
<ol style="list-style-type: decimal">
<li>Split the data set into train and test data set.</li>
<li>Train the model on the training data set.</li>
<li>Apply SGD (stochstic gradient descent) Classifier to minimize hinge
loss.</li>
<li>Apply Calibrated Classifier from sklearn and take SGD classifier as
a base estimator.</li>
<li>Sort the predicted probability scores in ascending order.</li>
<li>Divide the sorted probability and actual y into multiple bins. Here,
we are taking bin size as 50.</li>
<li>Take the average of actual ‘y’ and predicted probabilities for each
bins.</li>
<li>Plot average of actual y on y-axis and average of predicted
probability on x-axis.</li>
</ol>
<p>Pros: Works well with a small dataset</p>
<p>Cons: Could produce worse probabilities calibration wise if the
assumptions do not hold</p>
<p><strong>Skalowanie dla zagadnienia multiklasowego</strong></p>
<p><a href="https://datascience.stackexchange.com/questions/45924/platts-scaling-for-multi-label-classification">platts-scaling-for-multi-label-classification</a></p>
<p>There are a few multiclass variants of Platt scaling. The easiest
approach is as you have described; simply perform one Platt scaling on
each class.</p>
<p>However, there are more sophisticated options–a very simple one to
implement is training a standard logistic regression on the logits (the
values before the softmax activation is applied). This has called matrix
scaling and can overfit pretty easily, so only use this if you have a
large calibration set. Alternatively, a fewer-parameter version called
vector scaling is relatively simple to implement, where the weights
matrix inside the logistic regression is restricted to be a diagonal
matrix. Finally, a very simple option that has been shown to work well
for neural networks is temperature scaling, where all logits are simply
scaled by a single scalar parameter.</p>
<p>You can read more about these and their application to neural networks
in Section 4.2 of “On Calibration of Modern Neural Networks” (2017) -
available <a href="https://arxiv.org/pdf/1706.04599.pdf">here</a></p>
</div>
<div id="regresja-izotoniczna" class="section level5" number="5.14.1.2.5">
<h5><span class="header-section-number">5.14.1.2.5</span> Regresja izotoniczna</h5>
<p><a href="https://medium.com/@nupur94/calibration-of-models-45721a221da6">link</a></p>
<p>Pros:</p>
<p>Makes no assumption about the input probabilities. A benefit of isotonic
regression is that it is not constrained by any functional form, such as
the linearity imposed by linear regression, as long as the function is
monotonic increasing.</p>
<p>Cons: Requires more data points to work well</p>
</div>
<div id="calibration-in-sklearn" class="section level5" number="5.14.1.2.6">
<h5><span class="header-section-number">5.14.1.2.6</span> Calibration in <em>sklearn</em></h5>
<p>There are 2 ways of using the sklearn <code>CalibratedClassifierCV</code> class :</p>
<ul>
<li><p>Pass a fitted model and thereby setting cv to prefit. It is
important to note that the data used in fitting the base estimator
and the calibrator is disjoint.</p></li>
<li><p>Fit a base estimator using k-fold cross-validation and the
probabilities for each of the folds are then averaged for
prediction.</p></li>
</ul>
</div>
</div>
</div>
<div id="regression-4" class="section level3" number="5.14.2">
<h3><span class="header-section-number">5.14.2</span> Regression</h3>
</div>
</div>
<div id="elements-selection-5" class="section level2" number="5.15">
<h2><span class="header-section-number">5.15</span> Elements selection</h2>
<div id="feature-selection" class="section level3" number="5.15.1">
<h3><span class="header-section-number">5.15.1</span> Feature selection</h3>
<div id="feature-importance" class="section level5" number="5.15.1.0.1">
<h5><span class="header-section-number">5.15.1.0.1</span> Feature Importance</h5>
<p>Przyklady w Pythonie:
<a href="https://machinelearningmastery.com/calculate-feature-importance-with-python/">link</a></p>
<p><strong>MDI</strong></p>
<p><strong>MDA</strong></p>
<p>Mean Decrease Accuracy, MDA, also known as permutation importance.</p>
<p>The approach can be described in the following steps:</p>
<p>1. Train the baseline model and record the score (accuracy/R²/any
metric of importance) by passing the validation set (or OOB set in case
of Random Forest). This can also be done on the training set, at the
cost of sacrificing information about generalization.</p>
<p>2. Re-shuffle values from one feature in the selected dataset, pass the
dataset to the model again to obtain predictions and calculate the
metric for this modified dataset. The feature importance is the
difference between the benchmark score and the one from the modified
(permuted) dataset.</p>
</div>
<div id="boruta" class="section level5" number="5.15.1.0.2">
<h5><span class="header-section-number">5.15.1.0.2</span> Boruta</h5>
<p>nice explanation from tworddatascience
<a href="https://towardsdatascience.com/boruta-explained-the-way-i-wish-someone-explained-it-to-me-4489d70e154a">link</a></p>
</div>
</div>
<div id="variables-exogenity" class="section level3" number="5.15.2">
<h3><span class="header-section-number">5.15.2</span> Variables exogenity</h3>
<div id="granger-exogenity" class="section level4" number="5.15.2.1">
<h4><span class="header-section-number">5.15.2.1</span> Granger Exogenity</h4>
</div>
</div>
</div>
<div id="iml-5" class="section level2" number="5.16">
<h2><span class="header-section-number">5.16</span> IML</h2>
<div id="partial-dependence-plot" class="section level3" number="5.16.1">
<h3><span class="header-section-number">5.16.1</span> Partial Dependence Plot</h3>
<p><a href="https://towardsdatascience.com/introducing-pdpbox-2aa820afd312">link</a></p>
<p><a href="https://docs.seldon.io/projects/alibi/en/stable/methods/ALE.html">link</a></p>
<p>Pseudoalgorytm (mój intuicyjny - dla analizy jednej zmiennej)</p>
<ul>
<li><p>Wybieram zmienną która mnie interesuje do analizy.</p></li>
<li><p>Dla każdej wartości ustalonej tej zmiennej wyliczam predykcje modelu
(mojego wytrenowanego black boxa) podstawiając wszystkie możliwe
kombinacje wartości pozostałych zmiennych (tych których nie badam).
Następnie dla każdej wartości uśredniam wyniki. Teraz możemy zrobić
2 wykresy. W obu wykresach na osi x mamy wartości badanej zmiennej,
a na osi y wartości predykcji z modeli. W pierwszym wykresie
umieścimy wartości nie uśrednione. Tutaj wybierany określoną
kombinację zmiennych nie analizowanych i dla tej kombinacji
umieszczamy wszystkie występujące wartości zmiennej analizowanej.
Punkty łączymy linią. Następnie powtarzamy to dla wszystkich
możliwych kolejnych kombinacji. W ten sposób uzyskamy ICE plot. Dura
opcja to po prostu wrzucenie na wykres kolejnych wartości
uśrednionych i połączenie linią. Wtedy dostaniemy klasyczny PDP
plot.</p>
<ul>
<li><p>pierwotny zbiór danych:</p>
<p><img src="03_TARGET/figures/PDP_1.png" /></p></li>
<li><p>Zbiór danych po utworzeniu wszystkich możliwych kombinacji
wartości zmiennych niebadanych dla każdej wartości zmiennej
badane (zmienna badana to A1).</p>
<p><img src="03_TARGET/figures/PDP_2.png" /></p></li>
<li><p>Policzenie dla nowego zbioru predykcji i uśrednienie wyników dla
każdej wartości zmiennej badanej (A1):</p>
<p><img src="" /><img src="03_TARGET/figures/PDP_3.png" /></p></li>
<li><p>Utworzenie wykresów (ICE po lewej (na razie bez łączenie
punktów) i PDP po prawej):</p>
<p><img src="03_TARGET/figures/PDP_4.png" /></p></li>
<li><p>Pokazanie zależności między oboma wykresami:</p>
<p><img src="03_TARGET/figures/PDP_5.png" /></p></li>
</ul></li>
</ul>
<p><strong>Pros:</strong></p>
<p><strong>Cons:</strong></p>
<ul>
<li>Wadą rozwiązania jest to że w trakcie tworzenia zbioru różnych
kombinacji zmiennych nie analizowanych, mogą powstać sztuczne
obserwacje bardzo odległe od tego co jest w zbiorze danych. Dzieje
się to w sytuacji kiedy zmienna analizowana jest mocno skorelowana z
którąś z pozostałych zmiennych.</li>
</ul>
</div>
<div id="m-plot" class="section level3" number="5.16.2">
<h3><span class="header-section-number">5.16.2</span> M-plot</h3>
<p>M-plot jest teoretyczny próbą rozwiązania problemu PDP związanym z
powstawaniem sztucznych obserwacji odległych od pierwotnego zbioru.
Rozwiązanie mogłoby polegać na tym że kombinacje wartości zmiennych
dobieramy do wartości zmiennej analizowanej, warunkowo w oparciu o
prawdziwy rozkłady warunkowy zmiennych pozostałych względem zmiennej
analizowanej. Poniżej jest przykład rozkładu warunkowego zmiennej x2
względem analizowanej zmiennej x1.</p>
<p><img src="03_TARGET/figures/M-Plot.png" /></p>
<p>To rozwiązanie ma tą wadę. Załóżmy że analizowana zmienna x1 jest
skorelowana dodatnio (jak na rysunku powyżej) ze zmienną x2. Dodatkowo
załóżmy że zmienna x2 ma wpływ na predykcje z modelu a zmienna
analizowana x1 nie ma. W tym wypadku z analizy wyjdzie nam że poprzez
korelacje ze zmienną x2 zmienna wbrew stanowi faktycznego będzie miała
wpływ na wartości predykowane. Po prostu dla coraz wyższych wartości x1
będziemy losowali coraz wyższej wartości zmiennej x2, a zakładamy
przecież że zmiany x2 mają wpływ na predykcję.</p>
</div>
<div id="ale---accumulated-local-effects" class="section level3" number="5.16.3">
<h3><span class="header-section-number">5.16.3</span> ALE - Accumulated Local Effects</h3>
<p>W pythonie do ALE jest pakiet Alibi.</p>
<p>ALE próbuje rozwiązać problem jaki ma wykres M-Plot. Tutaj podobnie jak
w M-Plot losujemy wartości zmiennych uwzględniając rozkład warunkowy
względem A1. Tutaj jednak są pewne modyfikacje.</p>
<p>Wartości zmiennych losujemy z rozkładu warunkowego dla określonego
przedziału [a,b] wartości zmiennej analizowanej. Wartości zmiennych są
zastępowane ich średnią wartością w tym przedziale. Następnie dla tych
uśrednionych wartości liczymy predykcje modelu dla wartości zmiennej
analizowanej z początku przedział (a) i końca przedziału (b). Zatem
wartość zmiennej analizowanej się zmienia, a wartość pozostałych
zmiennych jest STAŁA dzięki czemu eliminujemy problem wpływu korelacji
miedzy zmienną analizowaną i pozostałymi zmiennymi.</p>
<p><img src="03_TARGET/figures/ALE_plot.png" /></p>
</div>
<div id="h-statistics" class="section level3" number="5.16.4">
<h3><span class="header-section-number">5.16.4</span> H-statistics</h3>
<p><a href="https://christophm.github.io/interpretable-ml-book/interaction.html#theory-friedmans-h-statistic">link</a></p>
<p>Jest to statystyka do badania interakcji między zmiennymi.</p>
<p>Jest to wartość wyliczana w oparciu o wartości jakie uzyskujemy przy
obliczeniach do PDP. Jeżeli między dwoma zmiennymi nie ma interakcji to
możemy założyć że:</p>
<p><span class="math inline">\(PD_{jk}(x_j,x_k)=PD_j(x_j)+PD_k(x_k)\)</span></p>
<p>Czyli suma wartości wyliczonych dla DPD dla każdej zmiennej z osobna
jest taka sama jak w sytuacji kiedy analizujemy dwie zmienne na raz.
Jeżeli ta addytywność nie jest spełnione to jest podejrzenie
interaktywności.</p>
<p>Pseudoalgorytm:</p>
<ul>
<li><p>obliczam wartości PD przy analizowaniu kilku zmiennych na raz
(wariant 1) i wartości przy analizie pojedynczych zmiennych (wariant
2).</p></li>
<li><p>Obliczam wariancje różnicy PD w obu wariantach.</p></li>
<li><p>Badam jaka część wariancji PD jest objaśniona poprzez różnice między
wariantami.</p></li>
</ul>
<p>Statystyka jest obliczana ze wzoru:</p>
<p><span class="math inline">\(H^2_{jk}=\sum_{i=1}^n\left[PD_{jk}(x_{j}^{(i)},x_k^{(i)})-PD_j(x_j^{(i)})-PD_k(x_{k}^{(i)})\right]^2/\sum_{i=1}^n{PD}^2_{jk}(x_j^{(i)},x_k^{(i)})\)</span></p>
<p>W liczniku mamy wariancje PD w różnych wariantach, a w mianowniku całą
wariancję w wariancie 1 który jest wariantem bazowym.</p>
</div>
<div id="lime-local-surrogate" class="section level3" number="5.16.5">
<h3><span class="header-section-number">5.16.5</span> LIME (Local surrogate)</h3>
<p><a href="https://towardsdatascience.com/decrypting-your-machine-learning-model-using-lime-5adc035109b5">link</a></p>
<p><a href="https://ema.drwhy.ai/LIME.html#LIMEIntuition">link</a></p>
<p>Jest to modelowanie lokalne per obserwacja.</p>
<p>Pseudoalgorytm (mój intuicyjny dla danych <strong>tabular data</strong>):</p>
<ul>
<li><p>Wybieram interesującą mnie obserwację.</p></li>
<li><p>Z rozkładu (najczęściej normalnego, z wartością oczekiwaną pokrywają
się z wartością zmiennych dla interesującego nas punktu) , dla
zmiennych objaśniających (features) losuje obserwacje.</p></li>
<li><p>Po wylosowaniu obserwacji ustalam metryke aby zważyć wylosowane
obserwacje. Te które są bliżej intersujęcego nas punktu ważą więcej.</p></li>
<li><p>Dla ważonych obserwacji buduje model który jest nie jest black-boxem
(model łatwy w interpretacji). Może to być np. model regresji
liniowej.</p></li>
<li><p>Parametry mojego modelu traktuje jako przybliżoną wskazówkę jaki
wpływ na wartość predykcji dla mojej obserwacji mają konkretne
zmienne objaśniające</p></li>
</ul>
<p>Pseudoalgorytm (mój intuicyjny dla danych <strong>tekstowych</strong>):</p>
<ul>
<li><p>zakładam że mam klasyfikator określający czy dany komentarz jest
spamem czy nie. Chcemy odczarować nasz black box i zobaczyć w tych
komentarzach jaki wpływ na predykcje mają poszczególne wyrazy.</p></li>
<li><p>Wybieram konkretną obserwację (komentarze)</p></li>
<li><p>Dla tego komentarze tworzę różne jego warianty wyłączając różne
kombinacje wyrazów. Poniżej jest przykład komentarza “For Christmas
Song visit my channel”: Wartości 0 dla kolejnych wyrazów oznaczają
ich wyłączanie w różnych wariantach:</p>
<p><img src="03_TARGET/figures/Lime_tekst_1.png" /></p></li>
<li><p>Dla różnych kombinacji wyliczam predykcje ( w tym przypadku
prawdopodobieństwo w przedostatniej kolumnie powyższej tabeli)
modelu. Dodatkowo wyliczane są wagi dla poszczególnych kombinacji
definiowane jako: The “weight” column shows the proximity of the
variation to the original sentence, calculated as 1 minus the
proportion of words that were removed, for example if 1 out of 7
words was removed, the proximity is 1 - 1/7 = 0.86. Czyli im mniej
wyrazów zostały wyrzuconych tym kombinacja jest bardziej podobna do
oryginału i ma większą wagę.</p></li>
<li><p>Następnie wyliczam lokalne wagi poszczególnych słów dzięki czemu
uzyskuje interpretowalność. Biorę kolejne obserwacje i analizuje
kolejne wyrazy w tych obserwacjach (w poniższej w tabeli mam 2
komentarze i dla każdego z nich po 3 wyrazy. Pierwszy komentarz nie
jest spamem (case1), a drugi jest (case2) ).</p>
<p><img src="03_TARGET/figures/Lime_tekst_2.png" /></p>
<p>Słowo “channel” w case 2 zwiększa prawdopodobieństwo że mamy spam o
6.18% (nie wiem jak to zostało wyliczone, ale wydaje mi się że
bierzemy średnią predykcji prawdopodobieństwa ze wszystkich
kombinacje bez słowa “channel” i drugą średnią z kombinacjami ze
słowem “channel” i liczę różnice) . For the non-spam comment (case</p>
<ol style="list-style-type: decimal">
<li>no non-zero weight was estimated, because no matter which word
is removed, the predicted class remains the same.</li>
</ol>
<p>Presudoalgorytm (mój intuicyjny dla <strong>zdjęć)</strong>:</p></li>
<li><p>Wybieram konkretne zdjęcia</p></li>
<li><p>Tworzę tzw. Megapixele. Mogą to być przylegające obszary o podobnym
kolorze.</p></li>
<li><p>Następnie tworzę różne kombinacje obrazka wyłączając różne
megapixele i sprawdzam jak wygląda klasyfikacja.</p></li>
<li><p>Potem liczę lokalne wagi chyba w sposób podobny do tego jak to jest
robione przy danych tekstowych.</p></li>
</ul>
<p><strong>Pros:</strong></p>
<ul>
<li><p>Even if you replace the underlying machine learning model, you can
still use the same local, interpretable model for explanation.
Suppose the people looking at the explanations understand decision
trees best. Because you use local surrogate models, you use decision
trees as explanations without actually having to use a decision tree
to make the predictions. For example, you can use a SVM. And if it
turns out that an xgboost model works better, you can replace the
SVM and still use as decision tree to explain the predictions.</p></li>
<li><p>Local surrogate models benefit from the literature and experience of
training and interpreting interpretable models.</p></li>
<li><p>When using Lasso or short trees, the resulting explanations are
short (= selective) and possibly contrastive. Therefore, they make
<a href="https://christophm.github.io/interpretable-ml-book/explanation.html#explanation">human-friendly
explanations</a>.
This is why I see LIME more in applications where the recipient of
the explanation is a lay person or someone with very little time. It
is not sufficient for complete attributions, so I do not see LIME in
compliance scenarios where you might be legally required to fully
explain a prediction. Also for debugging machine learning models, it
is useful to have all the reasons instead of a few.</p></li>
<li><p>LIME is one of the few methods that works for tabular data, text and
images.</p></li>
<li><p>The fidelity measure (how well the interpretable model approximates
the black box predictions) gives us a good idea of how reliable the
interpretable model is in explaining the black box predictions in
the neighborhood of the data instance of interest.</p></li>
<li><p>LIME is implemented in Python
(<a href="https://github.com/marcotcr/lime">lime</a> library) and R (<a href="https://cran.r-project.org/web/packages/lime/index.html">lime
package</a>
and <a href="https://cran.r-project.org/web/packages/iml/index.html">iml
package</a>)
and is very easy to use.</p></li>
<li><p>The explanations created with local surrogate models can use other
(interpretable) features than the original model was trained on.. Of
course, these interpretable features must be derived from the data
instances. A text classifier can rely on abstract word embeddings as
features, but the explanation can be based on the presence or
absence of words in a sentence. A regression model can rely on a
non-interpretable transformation of some attributes, but the
explanations can be created with the original attributes. For
example, the regression model could be trained on components of a
principal component analysis (PCA) of answers to a survey, but LIME
might be trained on the original survey questions. Using
interpretable features for LIME can be a big advantage over other
methods, especially when the model was trained with
non-interpretable features.</p></li>
</ul>
<p><strong>Cons:</strong></p>
<ul>
<li><p>The correct definition of the neighborhood is a very big, unsolved
problem when using LIME with tabular data. In my opinion it is the
biggest problem with LIME and the reason why I would recommend to
use LIME only with great care. For each application you have to try
different kernel settings and see for yourself if the explanations
make sense. Unfortunately, this is the best advice I can give to
find good kernel widths.</p></li>
<li><p>Sampling could be improved in the current implementation of LIME.
Data points are sampled from a Gaussian distribution, ignoring the
correlation between features. This can lead to unlikely data points
which can then be used to learn local explanation models.</p></li>
<li><p>The complexity of the explanation model has to be defined in
advance. This is just a small complaint, because in the end the user
always has to define the compromise between fidelity and sparsity.</p></li>
<li><p>Another really big problem is the instability of the explanations.
In an article
<sup><a href="https://christophm.github.io/interpretable-ml-book/lime.html#fn38">38</a></sup>
the authors showed that the explanations of two very close points
varied greatly in a simulated setting. Also, in my experience, if
you repeat the sampling process, then the explantions that come out
can be different. Instability means that it is difficult to trust
the explanations, and you should be very critical.</p></li>
<li><p>LIME explanations can be manipulated by the data scientist to hide
biases
<sup><a href="https://christophm.github.io/interpretable-ml-book/lime.html#fn39">39</a></sup>.
The possibility of manipulation makes it more difficult to trust
explanations generated with LIME.</p></li>
<li><p>Conclusion: Local surrogate models, with LIME as a concrete
implementation, are very promising. But the method is still in
development phase and many problems need to be solved before it can
be safely applied.5.7.4 Advantages</p></li>
<li><p>Even if you replace the underlying machine learning model, you can
still use the same local, interpretable model for explanation.
Suppose the people looking at the explanations understand decision
trees best. Because you use local surrogate models, you use decision
trees as explanations without actually having to use a decision tree
to make the predictions. For example, you can use a SVM. And if it
turns out that an xgboost model works better, you can replace the
SVM and still use as decision tree to explain the predictions.</p></li>
<li><p>Local surrogate models benefit from the literature and experience of
training and interpreting interpretable models.</p></li>
<li><p>When using Lasso or short trees, the resulting explanations are
short (= selective) and possibly contrastive. Therefore, they make
<a href="https://christophm.github.io/interpretable-ml-book/explanation.html#explanation">human-friendly
explanations</a>.
This is why I see LIME more in applications where the recipient of
the explanation is a lay person or someone with very little time. It
is not sufficient for complete attributions, so I do not see LIME in
compliance scenarios where you might be legally required to fully
explain a prediction. Also for debugging machine learning models, it
is useful to have all the reasons instead of a few.</p></li>
<li><p>LIME is one of the few methods that works for tabular data, text and
images.</p></li>
<li><p>The fidelity measure (how well the interpretable model approximates
the black box predictions) gives us a good idea of how reliable the
interpretable model is in explaining the black box predictions in
the neighborhood of the data instance of interest.</p></li>
<li><p>LIME is implemented in Python
(<a href="https://github.com/marcotcr/lime">lime</a> library) and R (<a href="https://cran.r-project.org/web/packages/lime/index.html">lime
package</a>
and <a href="https://cran.r-project.org/web/packages/iml/index.html">iml
package</a>)
and is very easy to use.</p></li>
<li><p>The explanations created with local surrogate models can use other
(interpretable) features than the original model was trained on.. Of
course, these interpretable features must be derived from the data
instances. A text classifier can rely on abstract word embeddings as
features, but the explanation can be based on the presence or
absence of words in a sentence. A regression model can rely on a
non-interpretable transformation of some attributes, but the
explanations can be created with the original attributes. For
example, the regression model could be trained on components of a
principal component analysis (PCA) of answers to a survey, but LIME
might be trained on the original survey questions. Using
interpretable features for LIME can be a big advantage over other
methods, especially when the model was trained with
non-interpretable features.</p></li>
</ul>
</div>
<div id="shapley-value" class="section level3" number="5.16.6">
<h3><span class="header-section-number">5.16.6</span> Shapley value</h3>
<p>Tak jak Lime jest wyliczany per obserwacja.</p>
<p>Pseudoalgorytm (mój intuicyjny):</p>
<ul>
<li><p>Wyliczam średnią predykcję dla całego zbioru. Nie to będzie np. 100</p></li>
<li><p>Biorę konkretną obserwacją i jej wartość predykcji (np. 110). Chce
zobaczyć jaki wpływ mają poszczególne zmienne objaśniające na
odchylenie predykcji dla obserwacji o średniej dla całego zbioru
(110-100=10)</p></li>
<li><p>Wybieram zmienną do analizy.</p></li>
<li><p>Z pozostałych zmiennych tworzę wszystkie możliwe koalicje. Zmienne w
kolacji mają ustalone wartości równe wartością dla badanej
obserwacji. Dla zmiennych spoza koalicji będziemy robili losowania.</p></li>
<li><p>Dla każdej kolacji robię 2 warianty. (1) Zmienna analizowana jest w
koalicji, (2) zmienna analizowana nie jest w kolacji.</p></li>
<li><p>Dla każdej koalicji robię losowania pozostałych zmiennych. Wyliczam
średnią z predykcji dla sytuacji kiedy zmienna analizowana jest w
koalicji i jej nie ma. Następnie liczę średnią ze średnich po
wszystkich koalicjach (oddzielnie dla sytuacji kiedy zmienna
analizowana jest w koalicji i kiedy jej nie ma).</p></li>
<li><p>Liczę różnice między średnimi w dwóch wariantach. Ta różnica to kład
w odchylenie wartości predykcji od obserwacji od średniej z
predykcji po wszystkich obserwacjach.</p></li>
</ul>
<p>Przykład interpretacji wyników</p>
<p>Mamy średnią predykcję dla wszystkich obserwacji 0.03. Dla konkretnej
analizowanej obserwacji wartość predykcji wynosi 0.57. Różnica między
tymi wartościami to 0.54. Przykładowo zmienna “wiek” dla tej obserwacji
ma wartość 20 i jej wkład w różnicę to ok 0.03.</p>
<p><img src="03_TARGET/figures/shapley_1.png" /></p>
<p>To co jest powyżej można ładniej zaprezentować jako <em>force plot</em>
(poniżej 2 przykłady):</p>
<p><img src="03_TARGET/figures/shapley_2.png" /></p>
<p>Poniżej wykres zbiorczy:</p>
<p><img src="03_TARGET/figures/shapley_3.png" /></p>
<p>Każde obserwacja ma tyle SHAP Values ile jest zmiennych. Można to
wrzucić na powyższy wykres. Oś Y to zmienne. Dla każdej zmiennej mamy
SHAP po wszystkich obserwacjach. SHAP odczytujemy z osi X. Wartość danej
zmiennej na danej obserwacji odczytujemy po kolorach (od czerwonego do
niebieskiego).</p>
<p>Dodatkowo możemy zrobić coś w rodzaju klastrowania obserwacji. Bierzemy
wszystkie force ploty odwracamy o 90 stopni i wrzucamy na wykres.
Następnie je sortujemy używając metryki podobieństwa pomiędzy tymi
plotami. W ten sposób można próbować wyodrębnić klastry obserwacji które
są podobne do siebie (Oś y to wartość predykcji a oś x podobieństwo).</p>
<p><img src="03_TARGET/figures/shapley_4.png" /></p>
</div>
</div>
<div id="by-problems-6" class="section level2" number="5.17">
<h2><span class="header-section-number">5.17</span> By problems</h2>
<div id="numerical" class="section level3" number="5.17.1">
<h3><span class="header-section-number">5.17.1</span> Numerical</h3>
</div>
<div id="categorical" class="section level3" number="5.17.2">
<h3><span class="header-section-number">5.17.2</span> Categorical</h3>
</div>
<div id="text" class="section level3" number="5.17.3">
<h3><span class="header-section-number">5.17.3</span> Text</h3>
</div>
<div id="sound-1" class="section level3" number="5.17.4">
<h3><span class="header-section-number">5.17.4</span> Sound</h3>
</div>
<div id="vision-1" class="section level3" number="5.17.5">
<h3><span class="header-section-number">5.17.5</span> Vision</h3>

</div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="learning-patterns-discovering.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="learning-hybrid.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/rstudio/bookdown-demo/edit/master/03_TARGET.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["bookdown-demo.pdf", "bookdown-demo.epub"],
"toc": {
"collapse": "section"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
