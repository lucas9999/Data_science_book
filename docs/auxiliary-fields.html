<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 3 AUXILIARY FIELDS | Data Science Book</title>
  <meta name="description" content="Chapter 3 AUXILIARY FIELDS | Data Science Book" />
  <meta name="generator" content="bookdown 0.21 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 3 AUXILIARY FIELDS | Data Science Book" />
  <meta property="og:type" content="book" />
  
  
  
  <meta name="github-repo" content="rstudio/bookdown-demo" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 3 AUXILIARY FIELDS | Data Science Book" />
  
  
  

<meta name="author" content="Łukasz Muszyński" />


<meta name="date" content="2023-04-03" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="introduction.html"/>
<link rel="next" href="learning-patterns-discovering.html"/>
<script src="libs/header-attrs-2.5/header-attrs.js"></script>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<link href="libs/anchor-sections-1.0/anchor-sections.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.0/anchor-sections.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">A Minimal Book Example</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> INTRO</a></li>
<li class="chapter" data-level="2" data-path="introduction.html"><a href="introduction.html"><i class="fa fa-check"></i><b>2</b> INTRODUCTION</a>
<ul>
<li class="chapter" data-level="2.1" data-path="introduction.html"><a href="introduction.html#to-do"><i class="fa fa-check"></i><b>2.1</b> TO DO</a></li>
<li class="chapter" data-level="2.2" data-path="introduction.html"><a href="introduction.html#draft"><i class="fa fa-check"></i><b>2.2</b> draft</a></li>
<li class="chapter" data-level="2.3" data-path="introduction.html"><a href="introduction.html#introduction-1"><i class="fa fa-check"></i><b>2.3</b> Introduction</a></li>
<li class="chapter" data-level="2.4" data-path="introduction.html"><a href="introduction.html#ai-problems-and-algorithms-classification"><i class="fa fa-check"></i><b>2.4</b> AI problems and algorithms classification</a></li>
<li class="chapter" data-level="2.5" data-path="introduction.html"><a href="introduction.html#meta-issues"><i class="fa fa-check"></i><b>2.5</b> Meta issues</a>
<ul>
<li class="chapter" data-level="2.5.1" data-path="introduction.html"><a href="introduction.html#knowledge-representation"><i class="fa fa-check"></i><b>2.5.1</b> Knowledge representation</a></li>
<li class="chapter" data-level="2.5.2" data-path="introduction.html"><a href="introduction.html#types-of-learning"><i class="fa fa-check"></i><b>2.5.2</b> Types of learning</a>
<ul>
<li class="chapter" data-level="2.5.2.1" data-path="introduction.html"><a href="introduction.html#ensemble-zespołowe"><i class="fa fa-check"></i><b>2.5.2.1</b> Ensemble (zespołowe)</a>
<ul>
<li class="chapter" data-level="2.5.2.1.1" data-path="introduction.html"><a href="introduction.html#bagging-and-pasting"><i class="fa fa-check"></i><b>2.5.2.1.1</b> Bagging and Pasting</a></li>
<li class="chapter" data-level="2.5.2.1.2" data-path="introduction.html"><a href="introduction.html#boosting"><i class="fa fa-check"></i><b>2.5.2.1.2</b> Boosting</a></li>
<li class="chapter" data-level="2.5.2.1.3" data-path="introduction.html"><a href="introduction.html#stacking"><i class="fa fa-check"></i><b>2.5.2.1.3</b> Stacking</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="2.5.3" data-path="introduction.html"><a href="introduction.html#model-complexity"><i class="fa fa-check"></i><b>2.5.3</b> Model complexity</a></li>
<li class="chapter" data-level="2.5.4" data-path="introduction.html"><a href="introduction.html#overfittng-underfitting"><i class="fa fa-check"></i><b>2.5.4</b> Overfittng / underfitting</a></li>
<li class="chapter" data-level="2.5.5" data-path="introduction.html"><a href="introduction.html#bias-variance-trade-off"><i class="fa fa-check"></i><b>2.5.5</b> Bias / Variance trade off</a></li>
<li class="chapter" data-level="2.5.6" data-path="introduction.html"><a href="introduction.html#curse-of-dimentionality"><i class="fa fa-check"></i><b>2.5.6</b> Curse of dimentionality</a></li>
<li class="chapter" data-level="2.5.7" data-path="introduction.html"><a href="introduction.html#sparious-phenomenon"><i class="fa fa-check"></i><b>2.5.7</b> Sparious phenomenon</a></li>
</ul></li>
<li class="chapter" data-level="2.6" data-path="introduction.html"><a href="introduction.html#rozne-podzialy-algorytmow"><i class="fa fa-check"></i><b>2.6</b> Rozne podzialy algorytmow</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="auxiliary-fields.html"><a href="auxiliary-fields.html"><i class="fa fa-check"></i><b>3</b> AUXILIARY FIELDS</a>
<ul>
<li class="chapter" data-level="3.1" data-path="auxiliary-fields.html"><a href="auxiliary-fields.html#introduction-2"><i class="fa fa-check"></i><b>3.1</b> Introduction</a></li>
<li class="chapter" data-level="3.2" data-path="auxiliary-fields.html"><a href="auxiliary-fields.html#philosophy"><i class="fa fa-check"></i><b>3.2</b> Philosophy</a></li>
<li class="chapter" data-level="3.3" data-path="auxiliary-fields.html"><a href="auxiliary-fields.html#logic"><i class="fa fa-check"></i><b>3.3</b> Logic</a></li>
<li class="chapter" data-level="3.4" data-path="auxiliary-fields.html"><a href="auxiliary-fields.html#psychology"><i class="fa fa-check"></i><b>3.4</b> Psychology</a></li>
<li class="chapter" data-level="3.5" data-path="auxiliary-fields.html"><a href="auxiliary-fields.html#linguistics"><i class="fa fa-check"></i><b>3.5</b> Linguistics</a></li>
<li class="chapter" data-level="3.6" data-path="auxiliary-fields.html"><a href="auxiliary-fields.html#cybernetics-control-theory"><i class="fa fa-check"></i><b>3.6</b> Cybernetics (control theory)</a></li>
<li class="chapter" data-level="3.7" data-path="auxiliary-fields.html"><a href="auxiliary-fields.html#math_1-probability"><i class="fa fa-check"></i><b>3.7</b> Math_1 – Probability</a>
<ul>
<li class="chapter" data-level="3.7.1" data-path="auxiliary-fields.html"><a href="auxiliary-fields.html#basics"><i class="fa fa-check"></i><b>3.7.1</b> Basics</a></li>
<li class="chapter" data-level="3.7.2" data-path="auxiliary-fields.html"><a href="auxiliary-fields.html#univariate-distributions"><i class="fa fa-check"></i><b>3.7.2</b> Univariate distributions</a></li>
<li class="chapter" data-level="3.7.3" data-path="auxiliary-fields.html"><a href="auxiliary-fields.html#multivariate-distributions"><i class="fa fa-check"></i><b>3.7.3</b> Multivariate distributions</a></li>
<li class="chapter" data-level="3.7.4" data-path="auxiliary-fields.html"><a href="auxiliary-fields.html#stochastic-processes"><i class="fa fa-check"></i><b>3.7.4</b> Stochastic processes</a></li>
</ul></li>
<li class="chapter" data-level="3.8" data-path="auxiliary-fields.html"><a href="auxiliary-fields.html#math_2-statistics"><i class="fa fa-check"></i><b>3.8</b> Math_2 – Statistics</a>
<ul>
<li class="chapter" data-level="3.8.1" data-path="auxiliary-fields.html"><a href="auxiliary-fields.html#descriptive-statistics"><i class="fa fa-check"></i><b>3.8.1</b> Descriptive statistics</a>
<ul>
<li class="chapter" data-level="3.8.1.1" data-path="auxiliary-fields.html"><a href="auxiliary-fields.html#univariate"><i class="fa fa-check"></i><b>3.8.1.1</b> Univariate</a></li>
<li class="chapter" data-level="3.8.1.2" data-path="auxiliary-fields.html"><a href="auxiliary-fields.html#multivariate"><i class="fa fa-check"></i><b>3.8.1.2</b> Multivariate</a>
<ul>
<li class="chapter" data-level="3.8.1.2.1" data-path="auxiliary-fields.html"><a href="auxiliary-fields.html#correlation"><i class="fa fa-check"></i><b>3.8.1.2.1</b> Correlation</a></li>
<li class="chapter" data-level="3.8.1.2.2" data-path="auxiliary-fields.html"><a href="auxiliary-fields.html#autocerrelation"><i class="fa fa-check"></i><b>3.8.1.2.2</b> Autocerrelation</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3.8.2" data-path="auxiliary-fields.html"><a href="auxiliary-fields.html#statistical-and-ecometrical-inference"><i class="fa fa-check"></i><b>3.8.2</b> Statistical and ecometrical inference</a>
<ul>
<li class="chapter" data-level="3.8.2.1" data-path="auxiliary-fields.html"><a href="auxiliary-fields.html#basics-1"><i class="fa fa-check"></i><b>3.8.2.1</b> Basics</a></li>
<li class="chapter" data-level="3.8.2.2" data-path="auxiliary-fields.html"><a href="auxiliary-fields.html#pameters-estimation-algorithms"><i class="fa fa-check"></i><b>3.8.2.2</b> Pameters estimation algorithms</a>
<ul>
<li class="chapter" data-level="3.8.2.2.1" data-path="auxiliary-fields.html"><a href="auxiliary-fields.html#general-moments-methods"><i class="fa fa-check"></i><b>3.8.2.2.1</b> General moments methods</a></li>
<li class="chapter" data-level="3.8.2.2.2" data-path="auxiliary-fields.html"><a href="auxiliary-fields.html#maxium-likehood"><i class="fa fa-check"></i><b>3.8.2.2.2</b> Maxium likehood</a></li>
<li class="chapter" data-level="3.8.2.2.3" data-path="auxiliary-fields.html"><a href="auxiliary-fields.html#nonparametric-techniques"><i class="fa fa-check"></i><b>3.8.2.2.3</b> Nonparametric techniques</a></li>
</ul></li>
<li class="chapter" data-level="3.8.2.3" data-path="auxiliary-fields.html"><a href="auxiliary-fields.html#sampling-techniques"><i class="fa fa-check"></i><b>3.8.2.3</b> Sampling techniques</a>
<ul>
<li class="chapter" data-level="3.8.2.3.1" data-path="auxiliary-fields.html"><a href="auxiliary-fields.html#holdout"><i class="fa fa-check"></i><b>3.8.2.3.1</b> Holdout</a></li>
<li class="chapter" data-level="3.8.2.3.2" data-path="auxiliary-fields.html"><a href="auxiliary-fields.html#boostrap"><i class="fa fa-check"></i><b>3.8.2.3.2</b> Boostrap</a></li>
<li class="chapter" data-level="3.8.2.3.3" data-path="auxiliary-fields.html"><a href="auxiliary-fields.html#jacknife"><i class="fa fa-check"></i><b>3.8.2.3.3</b> Jacknife</a></li>
<li class="chapter" data-level="3.8.2.3.4" data-path="auxiliary-fields.html"><a href="auxiliary-fields.html#permutation"><i class="fa fa-check"></i><b>3.8.2.3.4</b> Permutation</a></li>
<li class="chapter" data-level="3.8.2.3.5" data-path="auxiliary-fields.html"><a href="auxiliary-fields.html#cross-validation"><i class="fa fa-check"></i><b>3.8.2.3.5</b> Cross validation</a></li>
<li class="chapter" data-level="3.8.2.3.6" data-path="auxiliary-fields.html"><a href="auxiliary-fields.html#monte-carlo"><i class="fa fa-check"></i><b>3.8.2.3.6</b> Monte Carlo</a></li>
<li class="chapter" data-level="3.8.2.3.7" data-path="auxiliary-fields.html"><a href="auxiliary-fields.html#stratified-sampling"><i class="fa fa-check"></i><b>3.8.2.3.7</b> Stratified sampling</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3.8.3" data-path="auxiliary-fields.html"><a href="auxiliary-fields.html#other-issues"><i class="fa fa-check"></i><b>3.8.3</b> Other issues</a>
<ul>
<li class="chapter" data-level="3.8.3.1" data-path="auxiliary-fields.html"><a href="auxiliary-fields.html#similarity-and-dissimilarity-meassures-for-observations"><i class="fa fa-check"></i><b>3.8.3.1</b> Similarity and dissimilarity meassures for observations</a></li>
<li class="chapter" data-level="3.8.3.2" data-path="auxiliary-fields.html"><a href="auxiliary-fields.html#similarity-and-dissimilarity-meassures-for-distributions"><i class="fa fa-check"></i><b>3.8.3.2</b> Similarity and dissimilarity meassures for distributions</a></li>
<li class="chapter" data-level="3.8.3.3" data-path="auxiliary-fields.html"><a href="auxiliary-fields.html#measures-of-disorderrandomness"><i class="fa fa-check"></i><b>3.8.3.3</b> Measures of disorder/randomness</a></li>
<li class="chapter" data-level="3.8.3.4" data-path="auxiliary-fields.html"><a href="auxiliary-fields.html#conformal-prediction"><i class="fa fa-check"></i><b>3.8.3.4</b> Conformal prediction</a>
<ul>
<li class="chapter" data-level="3.8.3.4.1" data-path="auxiliary-fields.html"><a href="auxiliary-fields.html#przykład-knn-dla-random-forest-klasyfikacja-i-regresja"><i class="fa fa-check"></i><b>3.8.3.4.1</b> Przykład knn dla random forest (klasyfikacja i regresja)</a></li>
<li class="chapter" data-level="3.8.3.4.2" data-path="auxiliary-fields.html"><a href="auxiliary-fields.html#przykład-dla-knn-dla-klasyfikacji-link"><i class="fa fa-check"></i><b>3.8.3.4.2</b> Przykład dla knn dla klasyfikacji (<span>link</span>)</a></li>
</ul></li>
<li class="chapter" data-level="3.8.3.5" data-path="auxiliary-fields.html"><a href="auxiliary-fields.html#paradoxes"><i class="fa fa-check"></i><b>3.8.3.5</b> Paradoxes</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3.9" data-path="auxiliary-fields.html"><a href="auxiliary-fields.html#math_3---deep-learning"><i class="fa fa-check"></i><b>3.9</b> Math_3 - Deep Learning</a>
<ul>
<li class="chapter" data-level="3.9.1" data-path="auxiliary-fields.html"><a href="auxiliary-fields.html#różne-uwagi"><i class="fa fa-check"></i><b>3.9.1</b> Różne uwagi</a>
<ul>
<li class="chapter" data-level="3.9.1.1" data-path="auxiliary-fields.html"><a href="auxiliary-fields.html#ogólnie-o-sieciach"><i class="fa fa-check"></i><b>3.9.1.1</b> Ogólnie o sieciach</a></li>
<li class="chapter" data-level="3.9.1.2" data-path="auxiliary-fields.html"><a href="auxiliary-fields.html#funkcje-aktywacyjne"><i class="fa fa-check"></i><b>3.9.1.2</b> Funkcje aktywacyjne</a></li>
<li class="chapter" data-level="3.9.1.3" data-path="auxiliary-fields.html"><a href="auxiliary-fields.html#rnn"><i class="fa fa-check"></i><b>3.9.1.3</b> RNN</a></li>
<li class="chapter" data-level="3.9.1.4" data-path="auxiliary-fields.html"><a href="auxiliary-fields.html#cnn-dwuwymiarowe"><i class="fa fa-check"></i><b>3.9.1.4</b> CNN dwuwymiarowe:</a>
<ul>
<li class="chapter" data-level="3.9.1.4.1" data-path="auxiliary-fields.html"><a href="auxiliary-fields.html#r-cnn-region-cnn"><i class="fa fa-check"></i><b>3.9.1.4.1</b> R-CNN (Region-CNN)</a></li>
<li class="chapter" data-level="3.9.1.4.2" data-path="auxiliary-fields.html"><a href="auxiliary-fields.html#fast-r-cnn"><i class="fa fa-check"></i><b>3.9.1.4.2</b> Fast R-CNN</a></li>
<li class="chapter" data-level="3.9.1.4.3" data-path="auxiliary-fields.html"><a href="auxiliary-fields.html#fast-er-r-cnn"><i class="fa fa-check"></i><b>3.9.1.4.3</b> Fast-er R-CNN</a></li>
<li class="chapter" data-level="3.9.1.4.4" data-path="auxiliary-fields.html"><a href="auxiliary-fields.html#yolo"><i class="fa fa-check"></i><b>3.9.1.4.4</b> Yolo</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3.9.2" data-path="auxiliary-fields.html"><a href="auxiliary-fields.html#embedding"><i class="fa fa-check"></i><b>3.9.2</b> Embedding</a></li>
</ul></li>
<li class="chapter" data-level="3.10" data-path="auxiliary-fields.html"><a href="auxiliary-fields.html#math_4-game-theory"><i class="fa fa-check"></i><b>3.10</b> Math_4 – Game theory</a></li>
<li class="chapter" data-level="3.11" data-path="auxiliary-fields.html"><a href="auxiliary-fields.html#math_5-optimisation"><i class="fa fa-check"></i><b>3.11</b> Math_5 – Optimisation</a>
<ul>
<li class="chapter" data-level="3.11.1" data-path="auxiliary-fields.html"><a href="auxiliary-fields.html#functions-optimum"><i class="fa fa-check"></i><b>3.11.1</b> Functions optimum</a></li>
<li class="chapter" data-level="3.11.2" data-path="auxiliary-fields.html"><a href="auxiliary-fields.html#functions-optimum-constrained"><i class="fa fa-check"></i><b>3.11.2</b> Functions optimum – constrained</a>
<ul>
<li class="chapter" data-level="3.11.2.1" data-path="auxiliary-fields.html"><a href="auxiliary-fields.html#lagrange-multipliers"><i class="fa fa-check"></i><b>3.11.2.1</b> Lagrange Multipliers</a></li>
<li class="chapter" data-level="3.11.2.2" data-path="auxiliary-fields.html"><a href="auxiliary-fields.html#linear-programming"><i class="fa fa-check"></i><b>3.11.2.2</b> Linear programming</a></li>
<li class="chapter" data-level="3.11.2.3" data-path="auxiliary-fields.html"><a href="auxiliary-fields.html#nonlinear-programming"><i class="fa fa-check"></i><b>3.11.2.3</b> Nonlinear programming</a></li>
<li class="chapter" data-level="3.11.2.4" data-path="auxiliary-fields.html"><a href="auxiliary-fields.html#regularization"><i class="fa fa-check"></i><b>3.11.2.4</b> Regularization</a></li>
</ul></li>
<li class="chapter" data-level="3.11.3" data-path="auxiliary-fields.html"><a href="auxiliary-fields.html#functional-optimum"><i class="fa fa-check"></i><b>3.11.3</b> Functional optimum</a>
<ul>
<li class="chapter" data-level="3.11.3.1" data-path="auxiliary-fields.html"><a href="auxiliary-fields.html#dynamic-programming"><i class="fa fa-check"></i><b>3.11.3.1</b> Dynamic programming</a></li>
<li class="chapter" data-level="3.11.3.2" data-path="auxiliary-fields.html"><a href="auxiliary-fields.html#calculus-of-variations"><i class="fa fa-check"></i><b>3.11.3.2</b> Calculus of variations</a></li>
</ul></li>
<li class="chapter" data-level="3.11.4" data-path="auxiliary-fields.html"><a href="auxiliary-fields.html#cost-functions"><i class="fa fa-check"></i><b>3.11.4</b> Cost functions</a></li>
<li class="chapter" data-level="3.11.5" data-path="auxiliary-fields.html"><a href="auxiliary-fields.html#back-propagation"><i class="fa fa-check"></i><b>3.11.5</b> Back propagation</a></li>
<li class="chapter" data-level="3.11.6" data-path="auxiliary-fields.html"><a href="auxiliary-fields.html#heuristic-algorithms"><i class="fa fa-check"></i><b>3.11.6</b> Heuristic algorithms</a>
<ul>
<li class="chapter" data-level="3.11.6.1" data-path="auxiliary-fields.html"><a href="auxiliary-fields.html#swarm-algorithm"><i class="fa fa-check"></i><b>3.11.6.1</b> Swarm algorithm</a></li>
<li class="chapter" data-level="3.11.6.2" data-path="auxiliary-fields.html"><a href="auxiliary-fields.html#ants-algorithm"><i class="fa fa-check"></i><b>3.11.6.2</b> Ants algorithm</a></li>
<li class="chapter" data-level="3.11.6.3" data-path="auxiliary-fields.html"><a href="auxiliary-fields.html#genetics-algorithms"><i class="fa fa-check"></i><b>3.11.6.3</b> Genetics algorithms</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3.12" data-path="auxiliary-fields.html"><a href="auxiliary-fields.html#math_5-other-issues"><i class="fa fa-check"></i><b>3.12</b> Math_5 – Other issues</a>
<ul>
<li class="chapter" data-level="3.12.1" data-path="auxiliary-fields.html"><a href="auxiliary-fields.html#functions-usefull-in-data-science"><i class="fa fa-check"></i><b>3.12.1</b> Functions usefull in Data Science</a></li>
<li class="chapter" data-level="3.12.2" data-path="auxiliary-fields.html"><a href="auxiliary-fields.html#useful-tricks"><i class="fa fa-check"></i><b>3.12.2</b> Useful tricks</a></li>
<li class="chapter" data-level="3.12.3" data-path="auxiliary-fields.html"><a href="auxiliary-fields.html#linear-algebra"><i class="fa fa-check"></i><b>3.12.3</b> Linear algebra</a></li>
<li class="chapter" data-level="3.12.4" data-path="auxiliary-fields.html"><a href="auxiliary-fields.html#combinatorics"><i class="fa fa-check"></i><b>3.12.4</b> Combinatorics</a></li>
<li class="chapter" data-level="3.12.5" data-path="auxiliary-fields.html"><a href="auxiliary-fields.html#numerical-methods"><i class="fa fa-check"></i><b>3.12.5</b> Numerical methods</a></li>
<li class="chapter" data-level="3.12.6" data-path="auxiliary-fields.html"><a href="auxiliary-fields.html#equations"><i class="fa fa-check"></i><b>3.12.6</b> Equations</a>
<ul>
<li class="chapter" data-level="3.12.6.1" data-path="auxiliary-fields.html"><a href="auxiliary-fields.html#x-as-number"><i class="fa fa-check"></i><b>3.12.6.1</b> x as number</a></li>
<li class="chapter" data-level="3.12.6.2" data-path="auxiliary-fields.html"><a href="auxiliary-fields.html#x-as-derivative-differential-and-difference-equations"><i class="fa fa-check"></i><b>3.12.6.2</b> X as derivative: differential and difference equations</a></li>
<li class="chapter" data-level="3.12.6.3" data-path="auxiliary-fields.html"><a href="auxiliary-fields.html#choas"><i class="fa fa-check"></i><b>3.12.6.3</b> Choas</a>
<ul>
<li class="chapter" data-level="3.12.6.3.1" data-path="auxiliary-fields.html"><a href="auxiliary-fields.html#logistic-map"><i class="fa fa-check"></i><b>3.12.6.3.1</b> logistic map</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3.12.7" data-path="auxiliary-fields.html"><a href="auxiliary-fields.html#fuzzy-logic"><i class="fa fa-check"></i><b>3.12.7</b> Fuzzy logic</a></li>
<li class="chapter" data-level="3.12.8" data-path="auxiliary-fields.html"><a href="auxiliary-fields.html#graphs"><i class="fa fa-check"></i><b>3.12.8</b> Graphs</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html"><i class="fa fa-check"></i><b>4</b> LEARNING: PATTERNS DISCOVERING</a>
<ul>
<li class="chapter" data-level="4.1" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#introduction-3"><i class="fa fa-check"></i><b>4.1</b> Introduction</a></li>
<li class="chapter" data-level="4.2" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#clustering"><i class="fa fa-check"></i><b>4.2</b> Clustering</a>
<ul>
<li class="chapter" data-level="4.2.1" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#section"><i class="fa fa-check"></i><b>4.2.1</b> <img src="02_PATTERNS/figures/miary_odleglosci_klastrow.PNG" /></a></li>
<li class="chapter" data-level="4.2.2" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#introduction-4"><i class="fa fa-check"></i><b>4.2.2</b> Introduction</a></li>
<li class="chapter" data-level="4.2.3" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#hierarchical-connectivity-based"><i class="fa fa-check"></i><b>4.2.3</b> Hierarchical (Connectivity-based)</a>
<ul>
<li class="chapter" data-level="4.2.3.1" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#agglomerativedivisive"><i class="fa fa-check"></i><b>4.2.3.1</b> Agglomerative/Divisive</a></li>
<li class="chapter" data-level="4.2.3.2" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#chameleon"><i class="fa fa-check"></i><b>4.2.3.2</b> CHAMELEON</a></li>
<li class="chapter" data-level="4.2.3.3" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#birch"><i class="fa fa-check"></i><b>4.2.3.3</b> BIRCH</a></li>
<li class="chapter" data-level="4.2.3.4" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#hdbscan"><i class="fa fa-check"></i><b>4.2.3.4</b> HDBSCAN</a></li>
<li class="chapter" data-level="4.2.3.5" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#rock"><i class="fa fa-check"></i><b>4.2.3.5</b> ROCK</a></li>
<li class="chapter" data-level="4.2.3.6" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#echidna"><i class="fa fa-check"></i><b>4.2.3.6</b> Echidna</a></li>
<li class="chapter" data-level="4.2.3.7" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#diana"><i class="fa fa-check"></i><b>4.2.3.7</b> Diana</a></li>
<li class="chapter" data-level="4.2.3.8" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#agnes"><i class="fa fa-check"></i><b>4.2.3.8</b> Agnes</a></li>
</ul></li>
<li class="chapter" data-level="4.2.4" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#partititonal"><i class="fa fa-check"></i><b>4.2.4</b> Partititonal</a>
<ul>
<li class="chapter" data-level="4.2.4.1" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#k-methods"><i class="fa fa-check"></i><b>4.2.4.1</b> k-methods</a>
<ul>
<li class="chapter" data-level="4.2.4.1.1" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#k-means"><i class="fa fa-check"></i><b>4.2.4.1.1</b> k-means</a></li>
<li class="chapter" data-level="4.2.4.1.2" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#k-means-1"><i class="fa fa-check"></i><b>4.2.4.1.2</b> k-means ++</a></li>
<li class="chapter" data-level="4.2.4.1.3" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#k-means-scalable"><i class="fa fa-check"></i><b>4.2.4.1.3</b> k-means ++ scalable</a></li>
<li class="chapter" data-level="4.2.4.1.4" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#c-fuzzy-means"><i class="fa fa-check"></i><b>4.2.4.1.4</b> c-fuzzy means</a></li>
<li class="chapter" data-level="4.2.4.1.5" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#k-medoids"><i class="fa fa-check"></i><b>4.2.4.1.5</b> k-medoids</a></li>
<li class="chapter" data-level="4.2.4.1.6" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#k-medians"><i class="fa fa-check"></i><b>4.2.4.1.6</b> k-medians</a></li>
<li class="chapter" data-level="4.2.4.1.7" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#k-modes"><i class="fa fa-check"></i><b>4.2.4.1.7</b> k-modes</a></li>
<li class="chapter" data-level="4.2.4.1.8" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#k-prototypes"><i class="fa fa-check"></i><b>4.2.4.1.8</b> k-prototypes</a></li>
<li class="chapter" data-level="4.2.4.1.9" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#k-means-sgd-stochastic-gradient-descent"><i class="fa fa-check"></i><b>4.2.4.1.9</b> k-means SGD (stochastic gradient descent)</a></li>
<li class="chapter" data-level="4.2.4.1.10" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#k-mini-batches"><i class="fa fa-check"></i><b>4.2.4.1.10</b> k-mini-batches</a></li>
</ul></li>
<li class="chapter" data-level="4.2.4.2" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#claranas"><i class="fa fa-check"></i><b>4.2.4.2</b> CLARANAS</a></li>
<li class="chapter" data-level="4.2.4.3" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#clara"><i class="fa fa-check"></i><b>4.2.4.3</b> CLARA</a></li>
<li class="chapter" data-level="4.2.4.4" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#fcm"><i class="fa fa-check"></i><b>4.2.4.4</b> FCM</a></li>
<li class="chapter" data-level="4.2.4.5" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#fcmdc"><i class="fa fa-check"></i><b>4.2.4.5</b> FCMdC</a></li>
<li class="chapter" data-level="4.2.4.6" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#fanny"><i class="fa fa-check"></i><b>4.2.4.6</b> Fanny</a></li>
</ul></li>
<li class="chapter" data-level="4.2.5" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#density-latent-distibutions"><i class="fa fa-check"></i><b>4.2.5</b> Density /Latent distibutions</a>
<ul>
<li class="chapter" data-level="4.2.5.1" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#dbscan"><i class="fa fa-check"></i><b>4.2.5.1</b> DBSCAN</a></li>
<li class="chapter" data-level="4.2.5.2" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#optics"><i class="fa fa-check"></i><b>4.2.5.2</b> OPTICS</a></li>
<li class="chapter" data-level="4.2.5.3" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#predecon"><i class="fa fa-check"></i><b>4.2.5.3</b> PreDeCon</a></li>
<li class="chapter" data-level="4.2.5.4" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#subclu"><i class="fa fa-check"></i><b>4.2.5.4</b> SUBCLU</a></li>
<li class="chapter" data-level="4.2.5.5" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#denclue"><i class="fa fa-check"></i><b>4.2.5.5</b> DENCLUE</a></li>
<li class="chapter" data-level="4.2.5.6" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#dbclasd"><i class="fa fa-check"></i><b>4.2.5.6</b> DBCLASD</a></li>
<li class="chapter" data-level="4.2.5.7" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#graph-based-clustering"><i class="fa fa-check"></i><b>4.2.5.7</b> Graph based clustering</a>
<ul>
<li class="chapter" data-level="4.2.5.7.1" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#spectral-clustering"><i class="fa fa-check"></i><b>4.2.5.7.1</b> Spectral clustering</a></li>
</ul></li>
<li class="chapter" data-level="4.2.5.8" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#mean-shift"><i class="fa fa-check"></i><b>4.2.5.8</b> Mean Shift</a></li>
<li class="chapter" data-level="4.2.5.9" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#substractive-methods"><i class="fa fa-check"></i><b>4.2.5.9</b> Substractive Methods</a></li>
</ul></li>
<li class="chapter" data-level="4.2.6" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#grids"><i class="fa fa-check"></i><b>4.2.6</b> Grids</a>
<ul>
<li class="chapter" data-level="4.2.6.1" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#sting"><i class="fa fa-check"></i><b>4.2.6.1</b> STING</a></li>
<li class="chapter" data-level="4.2.6.2" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#clique"><i class="fa fa-check"></i><b>4.2.6.2</b> CLIQUE</a></li>
<li class="chapter" data-level="4.2.6.3" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#wavecluster"><i class="fa fa-check"></i><b>4.2.6.3</b> WaveCluster</a></li>
<li class="chapter" data-level="4.2.6.4" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#optigrid"><i class="fa fa-check"></i><b>4.2.6.4</b> OptiGrid</a></li>
</ul></li>
<li class="chapter" data-level="4.2.7" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#model-based"><i class="fa fa-check"></i><b>4.2.7</b> Model Based</a>
<ul>
<li class="chapter" data-level="4.2.7.1" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#classit"><i class="fa fa-check"></i><b>4.2.7.1</b> CLASSIT</a></li>
<li class="chapter" data-level="4.2.7.2" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#soms"><i class="fa fa-check"></i><b>4.2.7.2</b> SOMs</a></li>
<li class="chapter" data-level="4.2.7.3" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#cobweb"><i class="fa fa-check"></i><b>4.2.7.3</b> COBWEB</a></li>
<li class="chapter" data-level="4.2.7.4" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#neural-networks"><i class="fa fa-check"></i><b>4.2.7.4</b> Neural Networks</a></li>
</ul></li>
<li class="chapter" data-level="4.2.8" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#other"><i class="fa fa-check"></i><b>4.2.8</b> Other</a>
<ul>
<li class="chapter" data-level="4.2.8.1" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#affinity-propagation"><i class="fa fa-check"></i><b>4.2.8.1</b> Affinity propagation</a></li>
<li class="chapter" data-level="4.2.8.2" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#random-foreset"><i class="fa fa-check"></i><b>4.2.8.2</b> Random Foreset</a></li>
</ul></li>
<li class="chapter" data-level="4.2.9" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#consensus"><i class="fa fa-check"></i><b>4.2.9</b> Consensus</a>
<ul>
<li class="chapter" data-level="4.2.9.1" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#monti-consensus"><i class="fa fa-check"></i><b>4.2.9.1</b> Monti Consensus</a></li>
<li class="chapter" data-level="4.2.9.2" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#rand-index"><i class="fa fa-check"></i><b>4.2.9.2</b> Rand Index</a></li>
</ul></li>
<li class="chapter" data-level="4.2.10" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#by-problems"><i class="fa fa-check"></i><b>4.2.10</b> By problems</a>
<ul>
<li class="chapter" data-level="4.2.10.1" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#numerical-and-categorical"><i class="fa fa-check"></i><b>4.2.10.1</b> Numerical and categorical</a></li>
<li class="chapter" data-level="4.2.10.2" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#text-data"><i class="fa fa-check"></i><b>4.2.10.2</b> Text data</a>
<ul>
<li class="chapter" data-level="4.2.10.2.1" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#latent-dirichlet-allocation"><i class="fa fa-check"></i><b>4.2.10.2.1</b> Latent Dirichlet allocation</a></li>
</ul></li>
<li class="chapter" data-level="4.2.10.3" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#sound"><i class="fa fa-check"></i><b>4.2.10.3</b> Sound</a></li>
<li class="chapter" data-level="4.2.10.4" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#vision"><i class="fa fa-check"></i><b>4.2.10.4</b> Vision</a></li>
</ul></li>
<li class="chapter" data-level="4.2.11" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#results-diagnostics"><i class="fa fa-check"></i><b>4.2.11</b> Results diagnostics</a>
<ul>
<li class="chapter" data-level="4.2.11.1" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#bicaic"><i class="fa fa-check"></i><b>4.2.11.1</b> BIC/AIC</a></li>
<li class="chapter" data-level="4.2.11.2" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#metoda-łokcia-elbow."><i class="fa fa-check"></i><b>4.2.11.2</b> Metoda łokcia (elbow).</a></li>
<li class="chapter" data-level="4.2.11.3" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#silhouette-link"><i class="fa fa-check"></i><b>4.2.11.3</b> silhouette: <span>link</span></a></li>
<li class="chapter" data-level="4.2.11.4" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#celinski-harabasz-indeks"><i class="fa fa-check"></i><b>4.2.11.4</b> Celinski Harabasz indeks</a></li>
<li class="chapter" data-level="4.2.11.5" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#davies-bouldin-index"><i class="fa fa-check"></i><b>4.2.11.5</b> <strong>Davies-Bouldin Index</strong></a></li>
</ul></li>
<li class="chapter" data-level="4.2.12" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#elements-selection"><i class="fa fa-check"></i><b>4.2.12</b> Elements selection</a></li>
<li class="chapter" data-level="4.2.13" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#iml"><i class="fa fa-check"></i><b>4.2.13</b> IML</a></li>
<li class="chapter" data-level="4.2.14" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#by-problems-1"><i class="fa fa-check"></i><b>4.2.14</b> By problems</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#association"><i class="fa fa-check"></i><b>4.3</b> Association</a>
<ul>
<li class="chapter" data-level="4.3.1" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#apriori"><i class="fa fa-check"></i><b>4.3.1</b> Apriori</a></li>
<li class="chapter" data-level="4.3.2" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#euclat"><i class="fa fa-check"></i><b>4.3.2</b> Euclat</a></li>
<li class="chapter" data-level="4.3.3" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#fp-growth"><i class="fa fa-check"></i><b>4.3.3</b> FP-growth</a></li>
<li class="chapter" data-level="4.3.4" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#assoc"><i class="fa fa-check"></i><b>4.3.4</b> ASSOC</a></li>
<li class="chapter" data-level="4.3.5" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#opus"><i class="fa fa-check"></i><b>4.3.5</b> OPUS</a></li>
<li class="chapter" data-level="4.3.6" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#neural-networks-1"><i class="fa fa-check"></i><b>4.3.6</b> Neural Networks</a></li>
<li class="chapter" data-level="4.3.7" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#results-diagnostics-1"><i class="fa fa-check"></i><b>4.3.7</b> Results diagnostics</a></li>
<li class="chapter" data-level="4.3.8" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#elements-selection-1"><i class="fa fa-check"></i><b>4.3.8</b> Elements selection</a></li>
<li class="chapter" data-level="4.3.9" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#iml-1"><i class="fa fa-check"></i><b>4.3.9</b> IML</a></li>
<li class="chapter" data-level="4.3.10" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#by-problems-2"><i class="fa fa-check"></i><b>4.3.10</b> By problems</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#dimentionality-reduction"><i class="fa fa-check"></i><b>4.4</b> Dimentionality reduction</a>
<ul>
<li class="chapter" data-level="4.4.1" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#unsupervised"><i class="fa fa-check"></i><b>4.4.1</b> Unsupervised</a>
<ul>
<li class="chapter" data-level="4.4.1.1" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#pca"><i class="fa fa-check"></i><b>4.4.1.1</b> PCA</a>
<ul>
<li class="chapter" data-level="4.4.1.1.1" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#basic-pca"><i class="fa fa-check"></i><b>4.4.1.1.1</b> Basic PCA</a></li>
<li class="chapter" data-level="4.4.1.1.2" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#incremental-pca"><i class="fa fa-check"></i><b>4.4.1.1.2</b> Incremental PCA</a></li>
<li class="chapter" data-level="4.4.1.1.3" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#randomized-pca"><i class="fa fa-check"></i><b>4.4.1.1.3</b> Randomized PCA</a></li>
<li class="chapter" data-level="4.4.1.1.4" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#kernel-pca"><i class="fa fa-check"></i><b>4.4.1.1.4</b> kernel PCA</a></li>
</ul></li>
<li class="chapter" data-level="4.4.1.2" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#t-sne"><i class="fa fa-check"></i><b>4.4.1.2</b> t-SNE</a></li>
<li class="chapter" data-level="4.4.1.3" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#local-linear-embedding-lle"><i class="fa fa-check"></i><b>4.4.1.3</b> Local Linear Embedding (LLE)</a></li>
<li class="chapter" data-level="4.4.1.4" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#isomap"><i class="fa fa-check"></i><b>4.4.1.4</b> Isomap</a></li>
<li class="chapter" data-level="4.4.1.5" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#lda-as-dimentional-reduction"><i class="fa fa-check"></i><b>4.4.1.5</b> LDA as dimentional reduction</a></li>
<li class="chapter" data-level="4.4.1.6" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#partial-least-squares"><i class="fa fa-check"></i><b>4.4.1.6</b> Partial Least Squares</a></li>
<li class="chapter" data-level="4.4.1.7" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#multidimentional-scaling"><i class="fa fa-check"></i><b>4.4.1.7</b> Multidimentional Scaling</a></li>
<li class="chapter" data-level="4.4.1.8" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#correspondence-analysis"><i class="fa fa-check"></i><b>4.4.1.8</b> Correspondence Analysis</a></li>
<li class="chapter" data-level="4.4.1.9" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#kohonen-networks"><i class="fa fa-check"></i><b>4.4.1.9</b> Kohonen Networks</a></li>
<li class="chapter" data-level="4.4.1.10" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#neural-networks-other-than-kohonen"><i class="fa fa-check"></i><b>4.4.1.10</b> Neural Networks (other than Kohonen)</a></li>
<li class="chapter" data-level="4.4.1.11" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#factor-analysis"><i class="fa fa-check"></i><b>4.4.1.11</b> Factor Analysis</a></li>
<li class="chapter" data-level="4.4.1.12" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#latent-semantic-analysis"><i class="fa fa-check"></i><b>4.4.1.12</b> Latent semantic analysis</a></li>
<li class="chapter" data-level="4.4.1.13" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#autoencoders"><i class="fa fa-check"></i><b>4.4.1.13</b> Autoencoders</a></li>
<li class="chapter" data-level="4.4.1.14" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#analiza-glownych-skladowych-pca-principal-component-analysis"><i class="fa fa-check"></i><b>4.4.1.14</b> Analiza glownych skladowych (PCA) [Principal Component Analysis]</a></li>
<li class="chapter" data-level="4.4.1.15" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#analiza-glownych-wspolrzednych-pcoa-principal-coordinates-analysis"><i class="fa fa-check"></i><b>4.4.1.15</b> Analiza glownych wspolrzednych (PCoA) [Principal Coordinates Analysis]</a></li>
<li class="chapter" data-level="4.4.1.16" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#analiza-korespondencji-ca-correspondenca-analysis"><i class="fa fa-check"></i><b>4.4.1.16</b> Analiza korespondencji (CA) [Correspondenca Analysis]</a></li>
<li class="chapter" data-level="4.4.1.17" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#asymetryczna-analiza-korespondencji-aca-non-symmetric-correspondence-analysis"><i class="fa fa-check"></i><b>4.4.1.17</b> Asymetryczna analiza korespondencji (ACA) [Non-symmetric correspondence analysis]</a></li>
<li class="chapter" data-level="4.4.1.18" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#kanoniczna-analiza-korespondencji-cca-canonical-correspondence-analysis"><i class="fa fa-check"></i><b>4.4.1.18</b> Kanoniczna analiza korespondencji (CCA) [Canonical correspondence analysis]</a></li>
<li class="chapter" data-level="4.4.1.19" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#laczna-analiza-korespondencji-jca-joint-correspondence-analysis"><i class="fa fa-check"></i><b>4.4.1.19</b> Laczna analiza korespondencji (JCA) [Joint Correspondence Analysis]</a></li>
<li class="chapter" data-level="4.4.1.20" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#odwrocona-analiza-korespondencji-invca-inverse-correspondence-analysis"><i class="fa fa-check"></i><b>4.4.1.20</b> Odwrocona analiza korespondencji (InvCA) [Inverse correspondence analysis]</a></li>
<li class="chapter" data-level="4.4.1.21" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#taksowkowa-analiza-korespondencji-tca-taxicab-correspondence-analysis"><i class="fa fa-check"></i><b>4.4.1.21</b> Taksowkowa analiza korespondencji (TCA) [Taxicab Correspondence Analysis]</a></li>
<li class="chapter" data-level="4.4.1.22" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#rozmyta-analiza-korespondencji-fca-fuzzy-correspondence-analysis"><i class="fa fa-check"></i><b>4.4.1.22</b> Rozmyta analiza korespondencji (FCA) [Fuzzy correspondence analysis]</a></li>
<li class="chapter" data-level="4.4.1.23" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#wieloraka-analiza-korespondencji-mca-multiple-correspondence-analysis"><i class="fa fa-check"></i><b>4.4.1.23</b> Wieloraka analiza korespondencji (MCA) [Multiple correspondence analysis]</a></li>
<li class="chapter" data-level="4.4.1.24" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#regularyzowana-wieloraka-analiza-korespondencji-rmca-regularized-multiple-correspondence-analysis"><i class="fa fa-check"></i><b>4.4.1.24</b> Regularyzowana wieloraka analiza korespondencji (RMCA) [Regularized Multiple Correspondence Analysis]</a></li>
<li class="chapter" data-level="4.4.1.25" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#analiza-czynnikowa-fa-factor-analysis"><i class="fa fa-check"></i><b>4.4.1.25</b> Analiza czynnikowa (FA) <span>Factor analysis</span></a></li>
<li class="chapter" data-level="4.4.1.26" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#wieloraka-analiza-czynnikowa-mfa-multiple-factor-analysis"><i class="fa fa-check"></i><b>4.4.1.26</b> Wieloraka analiza czynnikowa (MFA) [Multiple Factor Analysis]</a></li>
<li class="chapter" data-level="4.4.1.27" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#analiza-skladowych-niezaleznych-ica-independent-component-analysis"><i class="fa fa-check"></i><b>4.4.1.27</b> Analiza skladowych niezaleznych (ICA) [Independent component analysis ]</a></li>
<li class="chapter" data-level="4.4.1.28" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#dca-detreded-correspondence-analysis"><i class="fa fa-check"></i><b>4.4.1.28</b> (DCA) [Detreded Correspondence Analysis]</a></li>
<li class="chapter" data-level="4.4.1.29" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#nieliniowa-analiza-korespondencji-npca-nonlinear-principal-components-analysis"><i class="fa fa-check"></i><b>4.4.1.29</b> Nieliniowa Analiza Korespondencji (NPCA) [Nonlinear Principal Components Analysis]</a></li>
<li class="chapter" data-level="4.4.1.30" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#mds-non-metric-multidimensional-scaling"><i class="fa fa-check"></i><b>4.4.1.30</b> (MDS) [Non-Metric Multidimensional Scaling]</a></li>
<li class="chapter" data-level="4.4.1.31" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#umap"><i class="fa fa-check"></i><b>4.4.1.31</b> UMAP</a></li>
<li class="chapter" data-level="4.4.1.32" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#trimap"><i class="fa fa-check"></i><b>4.4.1.32</b> <strong>TriMAP</strong></a></li>
<li class="chapter" data-level="4.4.1.33" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#pacmap"><i class="fa fa-check"></i><b>4.4.1.33</b> PaCMAP</a></li>
</ul></li>
<li class="chapter" data-level="4.4.2" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#supervised"><i class="fa fa-check"></i><b>4.4.2</b> Supervised</a>
<ul>
<li class="chapter" data-level="4.4.2.1" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#lda"><i class="fa fa-check"></i><b>4.4.2.1</b> LDA</a></li>
<li class="chapter" data-level="4.4.2.2" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#partial-least-squares-1"><i class="fa fa-check"></i><b>4.4.2.2</b> Partial Least Squares</a></li>
</ul></li>
<li class="chapter" data-level="4.4.3" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#results-diagnostics-2"><i class="fa fa-check"></i><b>4.4.3</b> Results diagnostics</a></li>
<li class="chapter" data-level="4.4.4" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#elements-selection-2"><i class="fa fa-check"></i><b>4.4.4</b> Elements selection</a></li>
<li class="chapter" data-level="4.4.5" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#iml-2"><i class="fa fa-check"></i><b>4.4.5</b> IML</a></li>
<li class="chapter" data-level="4.4.6" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#by-problems-3"><i class="fa fa-check"></i><b>4.4.6</b> By problems</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#casuality-analysis"><i class="fa fa-check"></i><b>4.5</b> Casuality analysis</a>
<ul>
<li class="chapter" data-level="4.5.1" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#sem"><i class="fa fa-check"></i><b>4.5.1</b> SEM</a>
<ul>
<li class="chapter" data-level="4.5.1.1" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#confirmatory-factor-analysis"><i class="fa fa-check"></i><b>4.5.1.1</b> Confirmatory factor analysis</a></li>
<li class="chapter" data-level="4.5.1.2" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#confirmatory-composite-analysis"><i class="fa fa-check"></i><b>4.5.1.2</b> Confirmatory composite analysis</a></li>
<li class="chapter" data-level="4.5.1.3" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#path-analysis"><i class="fa fa-check"></i><b>4.5.1.3</b> Path analysis</a></li>
<li class="chapter" data-level="4.5.1.4" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#partial-least-squares-path-modeling"><i class="fa fa-check"></i><b>4.5.1.4</b> Partial least squares path modeling</a></li>
<li class="chapter" data-level="4.5.1.5" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#latent-growth-modeling"><i class="fa fa-check"></i><b>4.5.1.5</b> Latent growth modeling</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4.6" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#dimentions-decomoposition"><i class="fa fa-check"></i><b>4.6</b> Dimentions decomoposition</a>
<ul>
<li class="chapter" data-level="4.6.1" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#results-diagnostics-3"><i class="fa fa-check"></i><b>4.6.1</b> Results diagnostics</a></li>
<li class="chapter" data-level="4.6.2" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#elements-selection-3"><i class="fa fa-check"></i><b>4.6.2</b> Elements selection</a></li>
<li class="chapter" data-level="4.6.3" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#iml-3"><i class="fa fa-check"></i><b>4.6.3</b> IML</a></li>
<li class="chapter" data-level="4.6.4" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#by-problems-4"><i class="fa fa-check"></i><b>4.6.4</b> By problems</a></li>
</ul></li>
<li class="chapter" data-level="4.7" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#generative-models"><i class="fa fa-check"></i><b>4.7</b> Generative models</a>
<ul>
<li class="chapter" data-level="4.7.1" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#results-diagnostics-4"><i class="fa fa-check"></i><b>4.7.1</b> Results diagnostics</a></li>
<li class="chapter" data-level="4.7.2" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#elements-selection-4"><i class="fa fa-check"></i><b>4.7.2</b> Elements selection</a></li>
<li class="chapter" data-level="4.7.3" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#iml-4"><i class="fa fa-check"></i><b>4.7.3</b> IML</a></li>
<li class="chapter" data-level="4.7.4" data-path="learning-patterns-discovering.html"><a href="learning-patterns-discovering.html#by-problems-5"><i class="fa fa-check"></i><b>4.7.4</b> By problems</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="learning-with-target.html"><a href="learning-with-target.html"><i class="fa fa-check"></i><b>5</b> LEARNING: WITH TARGET</a>
<ul>
<li class="chapter" data-level="5.1" data-path="learning-with-target.html"><a href="learning-with-target.html#introduction-5"><i class="fa fa-check"></i><b>5.1</b> Introduction</a>
<ul>
<li class="chapter" data-level="5.1.1" data-path="learning-with-target.html"><a href="learning-with-target.html#classification"><i class="fa fa-check"></i><b>5.1.1</b> Classification</a></li>
<li class="chapter" data-level="5.1.2" data-path="learning-with-target.html"><a href="learning-with-target.html#regression"><i class="fa fa-check"></i><b>5.1.2</b> Regression</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="learning-with-target.html"><a href="learning-with-target.html#econometrical-regression"><i class="fa fa-check"></i><b>5.2</b> Econometrical regression</a>
<ul>
<li class="chapter" data-level="5.2.1" data-path="learning-with-target.html"><a href="learning-with-target.html#basic-regression"><i class="fa fa-check"></i><b>5.2.1</b> Basic regression</a></li>
<li class="chapter" data-level="5.2.2" data-path="learning-with-target.html"><a href="learning-with-target.html#basic-dynamic-model"><i class="fa fa-check"></i><b>5.2.2</b> Basic dynamic model</a></li>
<li class="chapter" data-level="5.2.3" data-path="learning-with-target.html"><a href="learning-with-target.html#generalisations-and-constrains"><i class="fa fa-check"></i><b>5.2.3</b> Generalisations and constrains</a>
<ul>
<li class="chapter" data-level="5.2.3.1" data-path="learning-with-target.html"><a href="learning-with-target.html#glm"><i class="fa fa-check"></i><b>5.2.3.1</b> GLM</a>
<ul>
<li class="chapter" data-level="5.2.3.1.1" data-path="learning-with-target.html"><a href="learning-with-target.html#logisti-regression"><i class="fa fa-check"></i><b>5.2.3.1.1</b> logisti regression</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5.2.4" data-path="learning-with-target.html"><a href="learning-with-target.html#bayesian-inference"><i class="fa fa-check"></i><b>5.2.4</b> Bayesian inference</a></li>
<li class="chapter" data-level="5.2.5" data-path="learning-with-target.html"><a href="learning-with-target.html#multivariate-models"><i class="fa fa-check"></i><b>5.2.5</b> Multivariate models</a></li>
<li class="chapter" data-level="5.2.6" data-path="learning-with-target.html"><a href="learning-with-target.html#models-with-effects"><i class="fa fa-check"></i><b>5.2.6</b> Models with effects</a></li>
<li class="chapter" data-level="5.2.7" data-path="learning-with-target.html"><a href="learning-with-target.html#nonparametric-regression"><i class="fa fa-check"></i><b>5.2.7</b> Nonparametric regression</a>
<ul>
<li class="chapter" data-level="5.2.7.1" data-path="learning-with-target.html"><a href="learning-with-target.html#mars-splines"><i class="fa fa-check"></i><b>5.2.7.1</b> MARS Splines</a></li>
</ul></li>
<li class="chapter" data-level="5.2.8" data-path="learning-with-target.html"><a href="learning-with-target.html#pros"><i class="fa fa-check"></i><b>5.2.8</b> Pros</a></li>
<li class="chapter" data-level="5.2.9" data-path="learning-with-target.html"><a href="learning-with-target.html#cons"><i class="fa fa-check"></i><b>5.2.9</b> Cons</a>
<ul>
<li class="chapter" data-level="5.2.9.1" data-path="learning-with-target.html"><a href="learning-with-target.html#isotonic"><i class="fa fa-check"></i><b>5.2.9.1</b> Isotonic</a></li>
</ul></li>
<li class="chapter" data-level="5.2.10" data-path="learning-with-target.html"><a href="learning-with-target.html#other-regression-models"><i class="fa fa-check"></i><b>5.2.10</b> Other regression models</a>
<ul>
<li class="chapter" data-level="5.2.10.1" data-path="learning-with-target.html"><a href="learning-with-target.html#canonical-analysis"><i class="fa fa-check"></i><b>5.2.10.1</b> Canonical analysis</a></li>
<li class="chapter" data-level="5.2.10.2" data-path="learning-with-target.html"><a href="learning-with-target.html#anova-manova-ancova"><i class="fa fa-check"></i><b>5.2.10.2</b> ANOVA MANOVA ANCOVA</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="learning-with-target.html"><a href="learning-with-target.html#lda-qda"><i class="fa fa-check"></i><b>5.3</b> LDA &amp; QDA</a></li>
<li class="chapter" data-level="5.4" data-path="learning-with-target.html"><a href="learning-with-target.html#bayesian-models"><i class="fa fa-check"></i><b>5.4</b> Bayesian models</a></li>
<li class="chapter" data-level="5.5" data-path="learning-with-target.html"><a href="learning-with-target.html#trees"><i class="fa fa-check"></i><b>5.5</b> Trees</a>
<ul>
<li class="chapter" data-level="5.5.1" data-path="learning-with-target.html"><a href="learning-with-target.html#pros-1"><i class="fa fa-check"></i><b>5.5.1</b> pros</a></li>
<li class="chapter" data-level="5.5.2" data-path="learning-with-target.html"><a href="learning-with-target.html#cons-1"><i class="fa fa-check"></i><b>5.5.2</b> cons</a></li>
<li class="chapter" data-level="5.5.3" data-path="learning-with-target.html"><a href="learning-with-target.html#classification-1"><i class="fa fa-check"></i><b>5.5.3</b> Classification</a></li>
<li class="chapter" data-level="5.5.4" data-path="learning-with-target.html"><a href="learning-with-target.html#regression-1"><i class="fa fa-check"></i><b>5.5.4</b> Regression</a></li>
</ul></li>
<li class="chapter" data-level="5.6" data-path="learning-with-target.html"><a href="learning-with-target.html#svm"><i class="fa fa-check"></i><b>5.6</b> SVM</a>
<ul>
<li class="chapter" data-level="5.6.1" data-path="learning-with-target.html"><a href="learning-with-target.html#classification-2"><i class="fa fa-check"></i><b>5.6.1</b> Classification</a></li>
<li class="chapter" data-level="5.6.2" data-path="learning-with-target.html"><a href="learning-with-target.html#regression-2"><i class="fa fa-check"></i><b>5.6.2</b> Regression</a></li>
</ul></li>
<li class="chapter" data-level="5.7" data-path="learning-with-target.html"><a href="learning-with-target.html#k-nn"><i class="fa fa-check"></i><b>5.7</b> K-NN</a>
<ul>
<li class="chapter" data-level="5.7.1" data-path="learning-with-target.html"><a href="learning-with-target.html#classification-3"><i class="fa fa-check"></i><b>5.7.1</b> Classification</a>
<ul>
<li class="chapter" data-level="5.7.1.1" data-path="learning-with-target.html"><a href="learning-with-target.html#kd---tree"><i class="fa fa-check"></i><b>5.7.1.1</b> KD - tree</a></li>
<li class="chapter" data-level="5.7.1.2" data-path="learning-with-target.html"><a href="learning-with-target.html#ball-tree"><i class="fa fa-check"></i><b>5.7.1.2</b> Ball tree</a></li>
<li class="chapter" data-level="5.7.1.3" data-path="learning-with-target.html"><a href="learning-with-target.html#condensing-hart-algorithm"><i class="fa fa-check"></i><b>5.7.1.3</b> Condensing (Hart algorithm)</a></li>
<li class="chapter" data-level="5.7.1.4" data-path="learning-with-target.html"><a href="learning-with-target.html#editing"><i class="fa fa-check"></i><b>5.7.1.4</b> <strong>Editing</strong></a></li>
<li class="chapter" data-level="5.7.1.5" data-path="learning-with-target.html"><a href="learning-with-target.html#reducing"><i class="fa fa-check"></i><b>5.7.1.5</b> Reducing</a></li>
</ul></li>
<li class="chapter" data-level="5.7.2" data-path="learning-with-target.html"><a href="learning-with-target.html#regression-3"><i class="fa fa-check"></i><b>5.7.2</b> Regression</a></li>
</ul></li>
<li class="chapter" data-level="5.8" data-path="learning-with-target.html"><a href="learning-with-target.html#log-linear-model"><i class="fa fa-check"></i><b>5.8</b> Log-linear model</a></li>
<li class="chapter" data-level="5.9" data-path="learning-with-target.html"><a href="learning-with-target.html#similarity-learning"><i class="fa fa-check"></i><b>5.9</b> Similarity learning</a></li>
<li class="chapter" data-level="5.10" data-path="learning-with-target.html"><a href="learning-with-target.html#survival-models"><i class="fa fa-check"></i><b>5.10</b> Survival models</a>
<ul>
<li class="chapter" data-level="5.10.1" data-path="learning-with-target.html"><a href="learning-with-target.html#podstawowe-pojęcia"><i class="fa fa-check"></i><b>5.10.1</b> <strong>Podstawowe pojęcia</strong></a></li>
<li class="chapter" data-level="5.10.2" data-path="learning-with-target.html"><a href="learning-with-target.html#estymatory-standardowe-nieparametryczne"><i class="fa fa-check"></i><b>5.10.2</b> <strong>Estymatory standardowe-nieparametryczne</strong></a>
<ul>
<li class="chapter" data-level="5.10.2.1" data-path="learning-with-target.html"><a href="learning-with-target.html#tablice-trwania-życia-life-table"><i class="fa fa-check"></i><b>5.10.2.1</b> Tablice trwania życia (life table)</a></li>
<li class="chapter" data-level="5.10.2.2" data-path="learning-with-target.html"><a href="learning-with-target.html#kaplan-mayer"><i class="fa fa-check"></i><b>5.10.2.2</b> Kaplan Mayer</a></li>
<li class="chapter" data-level="5.10.2.3" data-path="learning-with-target.html"><a href="learning-with-target.html#nelson-aalen"><i class="fa fa-check"></i><b>5.10.2.3</b> Nelson Aalen</a></li>
</ul></li>
<li class="chapter" data-level="5.10.3" data-path="learning-with-target.html"><a href="learning-with-target.html#estymatora-standardowe-parametryczne"><i class="fa fa-check"></i><b>5.10.3</b> <strong>Estymatora standardowe parametryczne</strong></a></li>
<li class="chapter" data-level="5.10.4" data-path="learning-with-target.html"><a href="learning-with-target.html#estymatory-standardowe-semi-parametryczne"><i class="fa fa-check"></i><b>5.10.4</b> Estymatory standardowe semi-parametryczne</a>
<ul>
<li class="chapter" data-level="5.10.4.1" data-path="learning-with-target.html"><a href="learning-with-target.html#cox"><i class="fa fa-check"></i><b>5.10.4.1</b> <strong>Cox</strong></a></li>
</ul></li>
<li class="chapter" data-level="5.10.5" data-path="learning-with-target.html"><a href="learning-with-target.html#estymatory-inne"><i class="fa fa-check"></i><b>5.10.5</b> Estymatory inne</a>
<ul>
<li class="chapter" data-level="5.10.5.1" data-path="learning-with-target.html"><a href="learning-with-target.html#random-survival-forest"><i class="fa fa-check"></i><b>5.10.5.1</b> Random Survival Forest</a></li>
<li class="chapter" data-level="5.10.5.2" data-path="learning-with-target.html"><a href="learning-with-target.html#deepsurv"><i class="fa fa-check"></i><b>5.10.5.2</b> <strong>DeepSurv</strong></a></li>
</ul></li>
<li class="chapter" data-level="5.10.6" data-path="learning-with-target.html"><a href="learning-with-target.html#performence"><i class="fa fa-check"></i><b>5.10.6</b> <strong>Performence</strong></a></li>
</ul></li>
<li class="chapter" data-level="5.11" data-path="learning-with-target.html"><a href="learning-with-target.html#ensembled-models"><i class="fa fa-check"></i><b>5.11</b> Ensembled models</a>
<ul>
<li class="chapter" data-level="5.11.1" data-path="learning-with-target.html"><a href="learning-with-target.html#bagging-and-pasting-1"><i class="fa fa-check"></i><b>5.11.1</b> Bagging and Pasting</a>
<ul>
<li class="chapter" data-level="5.11.1.1" data-path="learning-with-target.html"><a href="learning-with-target.html#random-forest"><i class="fa fa-check"></i><b>5.11.1.1</b> Random Forest</a>
<ul>
<li class="chapter" data-level="5.11.1.1.1" data-path="learning-with-target.html"><a href="learning-with-target.html#out-of-bag-error"><i class="fa fa-check"></i><b>5.11.1.1.1</b> Out of Bag Error</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5.11.2" data-path="learning-with-target.html"><a href="learning-with-target.html#boosting-1"><i class="fa fa-check"></i><b>5.11.2</b> Boosting</a>
<ul>
<li class="chapter" data-level="5.11.2.1" data-path="learning-with-target.html"><a href="learning-with-target.html#ada-boost"><i class="fa fa-check"></i><b>5.11.2.1</b> Ada Boost</a></li>
<li class="chapter" data-level="5.11.2.2" data-path="learning-with-target.html"><a href="learning-with-target.html#gradient-boost"><i class="fa fa-check"></i><b>5.11.2.2</b> Gradient Boost</a></li>
<li class="chapter" data-level="5.11.2.3" data-path="learning-with-target.html"><a href="learning-with-target.html#xgboost"><i class="fa fa-check"></i><b>5.11.2.3</b> XGBoost</a></li>
<li class="chapter" data-level="5.11.2.4" data-path="learning-with-target.html"><a href="learning-with-target.html#catboost"><i class="fa fa-check"></i><b>5.11.2.4</b> CatBoost</a></li>
<li class="chapter" data-level="5.11.2.5" data-path="learning-with-target.html"><a href="learning-with-target.html#lightgbm"><i class="fa fa-check"></i><b>5.11.2.5</b> LightGBM</a></li>
</ul></li>
<li class="chapter" data-level="5.11.3" data-path="learning-with-target.html"><a href="learning-with-target.html#stacking-1"><i class="fa fa-check"></i><b>5.11.3</b> Stacking</a></li>
<li class="chapter" data-level="5.11.4" data-path="learning-with-target.html"><a href="learning-with-target.html#twicing"><i class="fa fa-check"></i><b>5.11.4</b> Twicing</a></li>
<li class="chapter" data-level="5.11.5" data-path="learning-with-target.html"><a href="learning-with-target.html#bandling"><i class="fa fa-check"></i><b>5.11.5</b> Bandling</a></li>
</ul></li>
<li class="chapter" data-level="5.12" data-path="learning-with-target.html"><a href="learning-with-target.html#neural-networks-2"><i class="fa fa-check"></i><b>5.12</b> Neural Networks</a>
<ul>
<li class="chapter" data-level="5.12.1" data-path="learning-with-target.html"><a href="learning-with-target.html#introduction-6"><i class="fa fa-check"></i><b>5.12.1</b> Introduction</a></li>
<li class="chapter" data-level="5.12.2" data-path="learning-with-target.html"><a href="learning-with-target.html#basics-2"><i class="fa fa-check"></i><b>5.12.2</b> Basics</a></li>
<li class="chapter" data-level="5.12.3" data-path="learning-with-target.html"><a href="learning-with-target.html#reccurent"><i class="fa fa-check"></i><b>5.12.3</b> Reccurent</a>
<ul>
<li class="chapter" data-level="5.12.3.1" data-path="learning-with-target.html"><a href="learning-with-target.html#simple-reccurent"><i class="fa fa-check"></i><b>5.12.3.1</b> Simple reccurent</a></li>
<li class="chapter" data-level="5.12.3.2" data-path="learning-with-target.html"><a href="learning-with-target.html#bidirectorial"><i class="fa fa-check"></i><b>5.12.3.2</b> Bidirectorial</a></li>
<li class="chapter" data-level="5.12.3.3" data-path="learning-with-target.html"><a href="learning-with-target.html#lstm"><i class="fa fa-check"></i><b>5.12.3.3</b> LSTM</a></li>
<li class="chapter" data-level="5.12.3.4" data-path="learning-with-target.html"><a href="learning-with-target.html#gru"><i class="fa fa-check"></i><b>5.12.3.4</b> GRU</a></li>
<li class="chapter" data-level="5.12.3.5" data-path="learning-with-target.html"><a href="learning-with-target.html#attention"><i class="fa fa-check"></i><b>5.12.3.5</b> Attention</a></li>
</ul></li>
<li class="chapter" data-level="5.12.4" data-path="learning-with-target.html"><a href="learning-with-target.html#cnn"><i class="fa fa-check"></i><b>5.12.4</b> CNN</a></li>
<li class="chapter" data-level="5.12.5" data-path="learning-with-target.html"><a href="learning-with-target.html#resnet"><i class="fa fa-check"></i><b>5.12.5</b> Resnet</a></li>
</ul></li>
<li class="chapter" data-level="5.13" data-path="learning-with-target.html"><a href="learning-with-target.html#stochastic-processes-1"><i class="fa fa-check"></i><b>5.13</b> Stochastic processes</a>
<ul>
<li class="chapter" data-level="5.13.1" data-path="learning-with-target.html"><a href="learning-with-target.html#basic-trend-models"><i class="fa fa-check"></i><b>5.13.1</b> Basic trend models</a></li>
<li class="chapter" data-level="5.13.2" data-path="learning-with-target.html"><a href="learning-with-target.html#basic-adaptative-models"><i class="fa fa-check"></i><b>5.13.2</b> Basic adaptative models</a></li>
<li class="chapter" data-level="5.13.3" data-path="learning-with-target.html"><a href="learning-with-target.html#econometric-time-series-models"><i class="fa fa-check"></i><b>5.13.3</b> Econometric time series models</a>
<ul>
<li class="chapter" data-level="5.13.3.1" data-path="learning-with-target.html"><a href="learning-with-target.html#dynamic-for-example-error-correction-models"><i class="fa fa-check"></i><b>5.13.3.1</b> dynamic (for example error correction models)</a></li>
<li class="chapter" data-level="5.13.3.2" data-path="learning-with-target.html"><a href="learning-with-target.html#sarimax"><i class="fa fa-check"></i><b>5.13.3.2</b> SARIMAX</a></li>
<li class="chapter" data-level="5.13.3.3" data-path="learning-with-target.html"><a href="learning-with-target.html#varimax"><i class="fa fa-check"></i><b>5.13.3.3</b> VARIMAX</a></li>
<li class="chapter" data-level="5.13.3.4" data-path="learning-with-target.html"><a href="learning-with-target.html#arch-class-models"><i class="fa fa-check"></i><b>5.13.3.4</b> ARCH class models</a></li>
<li class="chapter" data-level="5.13.3.5" data-path="learning-with-target.html"><a href="learning-with-target.html#cointegration-including-arld-approach"><i class="fa fa-check"></i><b>5.13.3.5</b> Cointegration (including ARLD approach)</a></li>
</ul></li>
<li class="chapter" data-level="5.13.4" data-path="learning-with-target.html"><a href="learning-with-target.html#time-series-decomposition-decomposition"><i class="fa fa-check"></i><b>5.13.4</b> Time series decomposition decomposition</a></li>
<li class="chapter" data-level="5.13.5" data-path="learning-with-target.html"><a href="learning-with-target.html#kalman-filters"><i class="fa fa-check"></i><b>5.13.5</b> Kalman filters</a></li>
<li class="chapter" data-level="5.13.6" data-path="learning-with-target.html"><a href="learning-with-target.html#neural-networks-3"><i class="fa fa-check"></i><b>5.13.6</b> Neural Networks</a>
<ul>
<li class="chapter" data-level="5.13.6.1" data-path="learning-with-target.html"><a href="learning-with-target.html#long-short-term-memory"><i class="fa fa-check"></i><b>5.13.6.1</b> Long short term memory</a></li>
<li class="chapter" data-level="5.13.6.2" data-path="learning-with-target.html"><a href="learning-with-target.html#cnn-1"><i class="fa fa-check"></i><b>5.13.6.2</b> CNN</a></li>
</ul></li>
<li class="chapter" data-level="5.13.7" data-path="learning-with-target.html"><a href="learning-with-target.html#panel-regression"><i class="fa fa-check"></i><b>5.13.7</b> Panel Regression</a></li>
<li class="chapter" data-level="5.13.8" data-path="learning-with-target.html"><a href="learning-with-target.html#gaussian-process"><i class="fa fa-check"></i><b>5.13.8</b> Gaussian Process</a></li>
<li class="chapter" data-level="5.13.9" data-path="learning-with-target.html"><a href="learning-with-target.html#ensembled-models-1"><i class="fa fa-check"></i><b>5.13.9</b> Ensembled models</a></li>
<li class="chapter" data-level="5.13.10" data-path="learning-with-target.html"><a href="learning-with-target.html#martingales"><i class="fa fa-check"></i><b>5.13.10</b> Martingales</a></li>
<li class="chapter" data-level="5.13.11" data-path="learning-with-target.html"><a href="learning-with-target.html#markov-process"><i class="fa fa-check"></i><b>5.13.11</b> Markov Process</a></li>
<li class="chapter" data-level="5.13.12" data-path="learning-with-target.html"><a href="learning-with-target.html#winer-process"><i class="fa fa-check"></i><b>5.13.12</b> Winer Process</a></li>
</ul></li>
<li class="chapter" data-level="5.14" data-path="learning-with-target.html"><a href="learning-with-target.html#results-diagnostics-5"><i class="fa fa-check"></i><b>5.14</b> Results diagnostics</a>
<ul>
<li class="chapter" data-level="5.14.1" data-path="learning-with-target.html"><a href="learning-with-target.html#classification-4"><i class="fa fa-check"></i><b>5.14.1</b> Classification</a>
<ul>
<li class="chapter" data-level="5.14.1.1" data-path="learning-with-target.html"><a href="learning-with-target.html#measures"><i class="fa fa-check"></i><b>5.14.1.1</b> Measures</a>
<ul>
<li class="chapter" data-level="5.14.1.1.1" data-path="learning-with-target.html"><a href="learning-with-target.html#negative-log-likelihood"><i class="fa fa-check"></i><b>5.14.1.1.1</b> Negative log likelihood</a></li>
<li class="chapter" data-level="5.14.1.1.2" data-path="learning-with-target.html"><a href="learning-with-target.html#cross-entrophy"><i class="fa fa-check"></i><b>5.14.1.1.2</b> Cross entrophy</a></li>
</ul></li>
<li class="chapter" data-level="5.14.1.2" data-path="learning-with-target.html"><a href="learning-with-target.html#scores-calibration"><i class="fa fa-check"></i><b>5.14.1.2</b> Scores calibration</a>
<ul>
<li class="chapter" data-level="5.14.1.2.1" data-path="learning-with-target.html"><a href="learning-with-target.html#problem"><i class="fa fa-check"></i><b>5.14.1.2.1</b> Problem</a></li>
<li class="chapter" data-level="5.14.1.2.2" data-path="learning-with-target.html"><a href="learning-with-target.html#kalibracja-a-problemy-konkretnych-modeli"><i class="fa fa-check"></i><b>5.14.1.2.2</b> Kalibracja a problemy konkretnych modeli</a></li>
<li class="chapter" data-level="5.14.1.2.3" data-path="learning-with-target.html"><a href="learning-with-target.html#calibration-curve-reliability-diagram"><i class="fa fa-check"></i><b>5.14.1.2.3</b> Calibration curve (reliability diagram)</a></li>
<li class="chapter" data-level="5.14.1.2.4" data-path="learning-with-target.html"><a href="learning-with-target.html#skalowanie-platta"><i class="fa fa-check"></i><b>5.14.1.2.4</b> Skalowanie Platta</a></li>
<li class="chapter" data-level="5.14.1.2.5" data-path="learning-with-target.html"><a href="learning-with-target.html#regresja-izotoniczna"><i class="fa fa-check"></i><b>5.14.1.2.5</b> Regresja izotoniczna</a></li>
<li class="chapter" data-level="5.14.1.2.6" data-path="learning-with-target.html"><a href="learning-with-target.html#calibration-in-sklearn"><i class="fa fa-check"></i><b>5.14.1.2.6</b> Calibration in <em>sklearn</em></a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5.14.2" data-path="learning-with-target.html"><a href="learning-with-target.html#regression-4"><i class="fa fa-check"></i><b>5.14.2</b> Regression</a></li>
</ul></li>
<li class="chapter" data-level="5.15" data-path="learning-with-target.html"><a href="learning-with-target.html#elements-selection-5"><i class="fa fa-check"></i><b>5.15</b> Elements selection</a>
<ul>
<li class="chapter" data-level="5.15.1" data-path="learning-with-target.html"><a href="learning-with-target.html#feature-selection"><i class="fa fa-check"></i><b>5.15.1</b> Feature selection</a>
<ul>
<li class="chapter" data-level="5.15.1.0.1" data-path="learning-with-target.html"><a href="learning-with-target.html#feature-importance"><i class="fa fa-check"></i><b>5.15.1.0.1</b> Feature Importance</a></li>
<li class="chapter" data-level="5.15.1.0.2" data-path="learning-with-target.html"><a href="learning-with-target.html#boruta"><i class="fa fa-check"></i><b>5.15.1.0.2</b> Boruta</a></li>
</ul></li>
<li class="chapter" data-level="5.15.2" data-path="learning-with-target.html"><a href="learning-with-target.html#variables-exogenity"><i class="fa fa-check"></i><b>5.15.2</b> Variables exogenity</a>
<ul>
<li class="chapter" data-level="5.15.2.1" data-path="learning-with-target.html"><a href="learning-with-target.html#granger-exogenity"><i class="fa fa-check"></i><b>5.15.2.1</b> Granger Exogenity</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5.16" data-path="learning-with-target.html"><a href="learning-with-target.html#iml-5"><i class="fa fa-check"></i><b>5.16</b> IML</a>
<ul>
<li class="chapter" data-level="5.16.1" data-path="learning-with-target.html"><a href="learning-with-target.html#partial-dependence-plot"><i class="fa fa-check"></i><b>5.16.1</b> Partial Dependence Plot</a></li>
<li class="chapter" data-level="5.16.2" data-path="learning-with-target.html"><a href="learning-with-target.html#m-plot"><i class="fa fa-check"></i><b>5.16.2</b> M-plot</a></li>
<li class="chapter" data-level="5.16.3" data-path="learning-with-target.html"><a href="learning-with-target.html#ale---accumulated-local-effects"><i class="fa fa-check"></i><b>5.16.3</b> ALE - Accumulated Local Effects</a></li>
<li class="chapter" data-level="5.16.4" data-path="learning-with-target.html"><a href="learning-with-target.html#h-statistics"><i class="fa fa-check"></i><b>5.16.4</b> H-statistics</a></li>
<li class="chapter" data-level="5.16.5" data-path="learning-with-target.html"><a href="learning-with-target.html#lime-local-surrogate"><i class="fa fa-check"></i><b>5.16.5</b> LIME (Local surrogate)</a></li>
<li class="chapter" data-level="5.16.6" data-path="learning-with-target.html"><a href="learning-with-target.html#shapley-value"><i class="fa fa-check"></i><b>5.16.6</b> Shapley value</a></li>
</ul></li>
<li class="chapter" data-level="5.17" data-path="learning-with-target.html"><a href="learning-with-target.html#by-problems-6"><i class="fa fa-check"></i><b>5.17</b> By problems</a>
<ul>
<li class="chapter" data-level="5.17.1" data-path="learning-with-target.html"><a href="learning-with-target.html#numerical"><i class="fa fa-check"></i><b>5.17.1</b> Numerical</a></li>
<li class="chapter" data-level="5.17.2" data-path="learning-with-target.html"><a href="learning-with-target.html#categorical"><i class="fa fa-check"></i><b>5.17.2</b> Categorical</a></li>
<li class="chapter" data-level="5.17.3" data-path="learning-with-target.html"><a href="learning-with-target.html#text"><i class="fa fa-check"></i><b>5.17.3</b> Text</a></li>
<li class="chapter" data-level="5.17.4" data-path="learning-with-target.html"><a href="learning-with-target.html#sound-1"><i class="fa fa-check"></i><b>5.17.4</b> Sound</a></li>
<li class="chapter" data-level="5.17.5" data-path="learning-with-target.html"><a href="learning-with-target.html#vision-1"><i class="fa fa-check"></i><b>5.17.5</b> Vision</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="learning-hybrid.html"><a href="learning-hybrid.html"><i class="fa fa-check"></i><b>6</b> LEARNING: HYBRID</a>
<ul>
<li class="chapter" data-level="6.1" data-path="learning-hybrid.html"><a href="learning-hybrid.html#introduction-7"><i class="fa fa-check"></i><b>6.1</b> Introduction</a></li>
<li class="chapter" data-level="6.2" data-path="learning-hybrid.html"><a href="learning-hybrid.html#semi-supervised-learning"><i class="fa fa-check"></i><b>6.2</b> Semi-supervised learning</a>
<ul>
<li class="chapter" data-level="6.2.1" data-path="learning-hybrid.html"><a href="learning-hybrid.html#em"><i class="fa fa-check"></i><b>6.2.1</b> EM</a></li>
<li class="chapter" data-level="6.2.2" data-path="learning-hybrid.html"><a href="learning-hybrid.html#cple"><i class="fa fa-check"></i><b>6.2.2</b> CPLE</a></li>
<li class="chapter" data-level="6.2.3" data-path="learning-hybrid.html"><a href="learning-hybrid.html#svm-and-tsvm"><i class="fa fa-check"></i><b>6.2.3</b> SVM and TSVM</a></li>
<li class="chapter" data-level="6.2.4" data-path="learning-hybrid.html"><a href="learning-hybrid.html#graphs-1"><i class="fa fa-check"></i><b>6.2.4</b> Graphs</a></li>
<li class="chapter" data-level="6.2.5" data-path="learning-hybrid.html"><a href="learning-hybrid.html#neural-networks-4"><i class="fa fa-check"></i><b>6.2.5</b> Neural Networks</a></li>
<li class="chapter" data-level="6.2.6" data-path="learning-hybrid.html"><a href="learning-hybrid.html#by-problems-7"><i class="fa fa-check"></i><b>6.2.6</b> By problems</a>
<ul>
<li class="chapter" data-level="6.2.6.1" data-path="learning-hybrid.html"><a href="learning-hybrid.html#numerical-and-categorical-1"><i class="fa fa-check"></i><b>6.2.6.1</b> Numerical and categorical</a></li>
<li class="chapter" data-level="6.2.6.2" data-path="learning-hybrid.html"><a href="learning-hybrid.html#text-data-1"><i class="fa fa-check"></i><b>6.2.6.2</b> Text data</a></li>
<li class="chapter" data-level="6.2.6.3" data-path="learning-hybrid.html"><a href="learning-hybrid.html#sound-2"><i class="fa fa-check"></i><b>6.2.6.3</b> Sound</a></li>
<li class="chapter" data-level="6.2.6.4" data-path="learning-hybrid.html"><a href="learning-hybrid.html#vision-2"><i class="fa fa-check"></i><b>6.2.6.4</b> Vision</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="learning-hybrid.html"><a href="learning-hybrid.html#self-supervised-learning"><i class="fa fa-check"></i><b>6.3</b> Self-supervised learning</a></li>
<li class="chapter" data-level="6.4" data-path="learning-hybrid.html"><a href="learning-hybrid.html#mult-instance-learning"><i class="fa fa-check"></i><b>6.4</b> Mult-instance learning</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="learning-reinforcement.html"><a href="learning-reinforcement.html"><i class="fa fa-check"></i><b>7</b> LEARNING: REINFORCEMENT</a>
<ul>
<li class="chapter" data-level="7.1" data-path="learning-reinforcement.html"><a href="learning-reinforcement.html#introduction-8"><i class="fa fa-check"></i><b>7.1</b> Introduction</a></li>
<li class="chapter" data-level="7.2" data-path="learning-reinforcement.html"><a href="learning-reinforcement.html#td"><i class="fa fa-check"></i><b>7.2</b> TD</a></li>
<li class="chapter" data-level="7.3" data-path="learning-reinforcement.html"><a href="learning-reinforcement.html#sarsa"><i class="fa fa-check"></i><b>7.3</b> SARSA</a></li>
<li class="chapter" data-level="7.4" data-path="learning-reinforcement.html"><a href="learning-reinforcement.html#q-learning"><i class="fa fa-check"></i><b>7.4</b> Q-learning</a></li>
<li class="chapter" data-level="7.5" data-path="learning-reinforcement.html"><a href="learning-reinforcement.html#by-problems-8"><i class="fa fa-check"></i><b>7.5</b> By problems</a>
<ul>
<li class="chapter" data-level="7.5.1" data-path="learning-reinforcement.html"><a href="learning-reinforcement.html#numerical-and-categorical-2"><i class="fa fa-check"></i><b>7.5.1</b> Numerical and categorical</a></li>
<li class="chapter" data-level="7.5.2" data-path="learning-reinforcement.html"><a href="learning-reinforcement.html#text-data-2"><i class="fa fa-check"></i><b>7.5.2</b> Text data</a></li>
<li class="chapter" data-level="7.5.3" data-path="learning-reinforcement.html"><a href="learning-reinforcement.html#sound-3"><i class="fa fa-check"></i><b>7.5.3</b> Sound</a></li>
<li class="chapter" data-level="7.5.4" data-path="learning-reinforcement.html"><a href="learning-reinforcement.html#vision-3"><i class="fa fa-check"></i><b>7.5.4</b> Vision</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="8" data-path="data-preprocessing.html"><a href="data-preprocessing.html"><i class="fa fa-check"></i><b>8</b> DATA PREPROCESSING</a>
<ul>
<li class="chapter" data-level="8.1" data-path="data-preprocessing.html"><a href="data-preprocessing.html#introduction-9"><i class="fa fa-check"></i><b>8.1</b> Introduction</a></li>
<li class="chapter" data-level="8.2" data-path="data-preprocessing.html"><a href="data-preprocessing.html#variables-tranformations"><i class="fa fa-check"></i><b>8.2</b> Variables tranformations</a>
<ul>
<li class="chapter" data-level="8.2.1" data-path="data-preprocessing.html"><a href="data-preprocessing.html#discretization"><i class="fa fa-check"></i><b>8.2.1</b> discretization</a></li>
<li class="chapter" data-level="8.2.2" data-path="data-preprocessing.html"><a href="data-preprocessing.html#numeric-variable-continuous-tranformations"><i class="fa fa-check"></i><b>8.2.2</b> numeric variable continuous tranformations</a></li>
<li class="chapter" data-level="8.2.3" data-path="data-preprocessing.html"><a href="data-preprocessing.html#nominal-variables-tranformations"><i class="fa fa-check"></i><b>8.2.3</b> nominal variables tranformations</a>
<ul>
<li class="chapter" data-level="8.2.3.1" data-path="data-preprocessing.html"><a href="data-preprocessing.html#encoding"><i class="fa fa-check"></i><b>8.2.3.1</b> encoding</a>
<ul>
<li class="chapter" data-level="8.2.3.1.1" data-path="data-preprocessing.html"><a href="data-preprocessing.html#one-hot"><i class="fa fa-check"></i><b>8.2.3.1.1</b> one-hot</a></li>
<li class="chapter" data-level="8.2.3.1.2" data-path="data-preprocessing.html"><a href="data-preprocessing.html#embedding-1"><i class="fa fa-check"></i><b>8.2.3.1.2</b> embedding</a></li>
</ul></li>
<li class="chapter" data-level="8.2.3.2" data-path="data-preprocessing.html"><a href="data-preprocessing.html#other-1"><i class="fa fa-check"></i><b>8.2.3.2</b> other</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="8.3" data-path="data-preprocessing.html"><a href="data-preprocessing.html#data-problems"><i class="fa fa-check"></i><b>8.3</b> Data Problems</a>
<ul>
<li class="chapter" data-level="8.3.1" data-path="data-preprocessing.html"><a href="data-preprocessing.html#numeric-and-categorical"><i class="fa fa-check"></i><b>8.3.1</b> Numeric and categorical</a>
<ul>
<li class="chapter" data-level="8.3.1.1" data-path="data-preprocessing.html"><a href="data-preprocessing.html#extreme-values"><i class="fa fa-check"></i><b>8.3.1.1</b> Extreme values</a>
<ul>
<li class="chapter" data-level="8.3.1.1.1" data-path="data-preprocessing.html"><a href="data-preprocessing.html#lof-local-outlier-factor"><i class="fa fa-check"></i><b>8.3.1.1.1</b> LOF (local outlier factor)</a></li>
<li class="chapter" data-level="8.3.1.1.2" data-path="data-preprocessing.html"><a href="data-preprocessing.html#angle"><i class="fa fa-check"></i><b>8.3.1.1.2</b> Angle</a></li>
<li class="chapter" data-level="8.3.1.1.3" data-path="data-preprocessing.html"><a href="data-preprocessing.html#knn"><i class="fa fa-check"></i><b>8.3.1.1.3</b> knn</a></li>
<li class="chapter" data-level="8.3.1.1.4" data-path="data-preprocessing.html"><a href="data-preprocessing.html#one-class-svm"><i class="fa fa-check"></i><b>8.3.1.1.4</b> One class SVM</a></li>
<li class="chapter" data-level="8.3.1.1.5" data-path="data-preprocessing.html"><a href="data-preprocessing.html#z-score"><i class="fa fa-check"></i><b>8.3.1.1.5</b> z-score</a></li>
<li class="chapter" data-level="8.3.1.1.6" data-path="data-preprocessing.html"><a href="data-preprocessing.html#pca-1"><i class="fa fa-check"></i><b>8.3.1.1.6</b> PCA</a></li>
<li class="chapter" data-level="8.3.1.1.7" data-path="data-preprocessing.html"><a href="data-preprocessing.html#autoencoders-1"><i class="fa fa-check"></i><b>8.3.1.1.7</b> Autoencoders</a></li>
<li class="chapter" data-level="8.3.1.1.8" data-path="data-preprocessing.html"><a href="data-preprocessing.html#elliptic-envelope"><i class="fa fa-check"></i><b>8.3.1.1.8</b> <strong>Elliptic Envelope</strong></a></li>
<li class="chapter" data-level="8.3.1.1.9" data-path="data-preprocessing.html"><a href="data-preprocessing.html#copod"><i class="fa fa-check"></i><b>8.3.1.1.9</b> COPOD</a></li>
<li class="chapter" data-level="8.3.1.1.10" data-path="data-preprocessing.html"><a href="data-preprocessing.html#isolation-forest"><i class="fa fa-check"></i><b>8.3.1.1.10</b> Isolation Forest</a></li>
</ul></li>
<li class="chapter" data-level="8.3.1.2" data-path="data-preprocessing.html"><a href="data-preprocessing.html#missing-values"><i class="fa fa-check"></i><b>8.3.1.2</b> Missing values</a></li>
<li class="chapter" data-level="8.3.1.3" data-path="data-preprocessing.html"><a href="data-preprocessing.html#untipical-distributions-for-example-copula-models-kernel-estimators-logaritmic-transofmations-ect.-mixed-distributions"><i class="fa fa-check"></i><b>8.3.1.3</b> Untipical distributions (for example copula models, kernel estimators, logaritmic transofmations ect., mixed distributions)</a></li>
<li class="chapter" data-level="8.3.1.4" data-path="data-preprocessing.html"><a href="data-preprocessing.html#censoredtruncated-data"><i class="fa fa-check"></i><b>8.3.1.4</b> Censored/truncated data</a></li>
<li class="chapter" data-level="8.3.1.5" data-path="data-preprocessing.html"><a href="data-preprocessing.html#aggregated-date-decomposition"><i class="fa fa-check"></i><b>8.3.1.5</b> Aggregated date (decomposition)</a></li>
<li class="chapter" data-level="8.3.1.6" data-path="data-preprocessing.html"><a href="data-preprocessing.html#meassurement-error-for-example-kalman-filter-model"><i class="fa fa-check"></i><b>8.3.1.6</b> Meassurement error (for example Kalman filter model)</a></li>
<li class="chapter" data-level="8.3.1.7" data-path="data-preprocessing.html"><a href="data-preprocessing.html#granularity-of-data"><i class="fa fa-check"></i><b>8.3.1.7</b> Granularity of data</a></li>
<li class="chapter" data-level="8.3.1.8" data-path="data-preprocessing.html"><a href="data-preprocessing.html#imbalanced-categories"><i class="fa fa-check"></i><b>8.3.1.8</b> Imbalanced categories</a>
<ul>
<li class="chapter" data-level="8.3.1.8.1" data-path="data-preprocessing.html"><a href="data-preprocessing.html#non-synthetic-methods"><i class="fa fa-check"></i><b>8.3.1.8.1</b> Non synthetic methods</a></li>
<li class="chapter" data-level="8.3.1.8.2" data-path="data-preprocessing.html"><a href="data-preprocessing.html#synthetic-methods"><i class="fa fa-check"></i><b>8.3.1.8.2</b> Synthetic methods</a></li>
</ul></li>
<li class="chapter" data-level="8.3.1.9" data-path="data-preprocessing.html"><a href="data-preprocessing.html#imbalanced-values"><i class="fa fa-check"></i><b>8.3.1.9</b> Imbalanced values</a></li>
<li class="chapter" data-level="8.3.1.10" data-path="data-preprocessing.html"><a href="data-preprocessing.html#small-samples-problem"><i class="fa fa-check"></i><b>8.3.1.10</b> Small samples problem</a></li>
</ul></li>
<li class="chapter" data-level="8.3.2" data-path="data-preprocessing.html"><a href="data-preprocessing.html#text-1"><i class="fa fa-check"></i><b>8.3.2</b> Text</a>
<ul>
<li class="chapter" data-level="8.3.2.1" data-path="data-preprocessing.html"><a href="data-preprocessing.html#tf-idf"><i class="fa fa-check"></i><b>8.3.2.1</b> TF-IDF</a></li>
</ul></li>
<li class="chapter" data-level="8.3.3" data-path="data-preprocessing.html"><a href="data-preprocessing.html#visual"><i class="fa fa-check"></i><b>8.3.3</b> Visual</a>
<ul>
<li class="chapter" data-level="8.3.3.1" data-path="data-preprocessing.html"><a href="data-preprocessing.html#wykrywanie-krewedzi"><i class="fa fa-check"></i><b>8.3.3.1</b> Wykrywanie krewedzi</a>
<ul>
<li class="chapter" data-level="8.3.3.1.1" data-path="data-preprocessing.html"><a href="data-preprocessing.html#hough"><i class="fa fa-check"></i><b>8.3.3.1.1</b> Hough</a></li>
</ul></li>
<li class="chapter" data-level="8.3.3.2" data-path="data-preprocessing.html"><a href="data-preprocessing.html#wykrywanie-elementów"><i class="fa fa-check"></i><b>8.3.3.2</b> Wykrywanie elementów</a>
<ul>
<li class="chapter" data-level="8.3.3.2.1" data-path="data-preprocessing.html"><a href="data-preprocessing.html#haar-cascade"><i class="fa fa-check"></i><b>8.3.3.2.1</b> Haar Cascade</a></li>
<li class="chapter" data-level="8.3.3.2.2" data-path="data-preprocessing.html"><a href="data-preprocessing.html#orb"><i class="fa fa-check"></i><b>8.3.3.2.2</b> ORB</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="8.3.4" data-path="data-preprocessing.html"><a href="data-preprocessing.html#sound-4"><i class="fa fa-check"></i><b>8.3.4</b> Sound</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="9" data-path="other-models-and-problems.html"><a href="other-models-and-problems.html"><i class="fa fa-check"></i><b>9</b> OTHER MODELS AND PROBLEMS</a>
<ul>
<li class="chapter" data-level="9.1" data-path="other-models-and-problems.html"><a href="other-models-and-problems.html#hyperparameters-tunning"><i class="fa fa-check"></i><b>9.1</b> Hyperparameters tunning</a>
<ul>
<li class="chapter" data-level="9.1.1" data-path="other-models-and-problems.html"><a href="other-models-and-problems.html#bayesian-methods"><i class="fa fa-check"></i><b>9.1.1</b> Bayesian methods</a>
<ul>
<li class="chapter" data-level="9.1.1.1" data-path="other-models-and-problems.html"><a href="other-models-and-problems.html#tree-structured-parzen-estimator-tpe"><i class="fa fa-check"></i><b>9.1.1.1</b> <strong>Tree-structured Parzen Estimator (TPE)</strong></a></li>
</ul></li>
<li class="chapter" data-level="9.1.2" data-path="other-models-and-problems.html"><a href="other-models-and-problems.html#successive-halving"><i class="fa fa-check"></i><b>9.1.2</b> <strong>Successive Halving</strong></a></li>
<li class="chapter" data-level="9.1.3" data-path="other-models-and-problems.html"><a href="other-models-and-problems.html#hyperband"><i class="fa fa-check"></i><b>9.1.3</b> Hyperband</a></li>
<li class="chapter" data-level="9.1.4" data-path="other-models-and-problems.html"><a href="other-models-and-problems.html#fabolas"><i class="fa fa-check"></i><b>9.1.4</b> <strong>Fabolas</strong></a></li>
<li class="chapter" data-level="9.1.5" data-path="other-models-and-problems.html"><a href="other-models-and-problems.html#bohb"><i class="fa fa-check"></i><b>9.1.5</b> <strong>BOHB</strong></a></li>
<li class="chapter" data-level="9.1.6" data-path="other-models-and-problems.html"><a href="other-models-and-problems.html#population-based-training-ptb"><i class="fa fa-check"></i><b>9.1.6</b> <strong>Population-based training (PTB)</strong></a></li>
</ul></li>
<li class="chapter" data-level="9.2" data-path="other-models-and-problems.html"><a href="other-models-and-problems.html#social-network"><i class="fa fa-check"></i><b>9.2</b> Social Network</a></li>
<li class="chapter" data-level="9.3" data-path="other-models-and-problems.html"><a href="other-models-and-problems.html#queuing-kolejki"><i class="fa fa-check"></i><b>9.3</b> Queuing (kolejki)</a></li>
<li class="chapter" data-level="9.4" data-path="other-models-and-problems.html"><a href="other-models-and-problems.html#spacial-model-modele-przestrzenne"><i class="fa fa-check"></i><b>9.4</b> Spacial model (modele przestrzenne)</a></li>
<li class="chapter" data-level="9.5" data-path="other-models-and-problems.html"><a href="other-models-and-problems.html#six-sigma-process-quality-control-quality-control-charts"><i class="fa fa-check"></i><b>9.5</b> SIX-Sigma (process quality control, quality control charts)</a></li>
<li class="chapter" data-level="9.6" data-path="other-models-and-problems.html"><a href="other-models-and-problems.html#process-analysis-analiza-procesu"><i class="fa fa-check"></i><b>9.6</b> Process Analysis (Analiza procesu)</a></li>
<li class="chapter" data-level="9.7" data-path="other-models-and-problems.html"><a href="other-models-and-problems.html#reliability-and-item-analysis-analiza-rzetelności"><i class="fa fa-check"></i><b>9.7</b> Reliability and Item Analysis (Analiza rzetelności)</a></li>
<li class="chapter" data-level="9.8" data-path="other-models-and-problems.html"><a href="other-models-and-problems.html#experimentla-design-planowanie-doświadczeń"><i class="fa fa-check"></i><b>9.8</b> Experimentla design (Planowanie doświadczeń)</a></li>
<li class="chapter" data-level="9.9" data-path="other-models-and-problems.html"><a href="other-models-and-problems.html#sequential-analysis"><i class="fa fa-check"></i><b>9.9</b> Sequential analysis</a></li>
<li class="chapter" data-level="9.10" data-path="other-models-and-problems.html"><a href="other-models-and-problems.html#logic-programming-programowanie-logiczne"><i class="fa fa-check"></i><b>9.10</b> Logic programming (programowanie logiczne)</a></li>
<li class="chapter" data-level="9.11" data-path="other-models-and-problems.html"><a href="other-models-and-problems.html#financial-models"><i class="fa fa-check"></i><b>9.11</b> Financial models</a>
<ul>
<li class="chapter" data-level="9.11.1" data-path="other-models-and-problems.html"><a href="other-models-and-problems.html#distance-to-default"><i class="fa fa-check"></i><b>9.11.1</b> Distance to default</a></li>
<li class="chapter" data-level="9.11.2" data-path="other-models-and-problems.html"><a href="other-models-and-problems.html#copula-methods-kopuły"><i class="fa fa-check"></i><b>9.11.2</b> Copula methods (kopuły)</a></li>
<li class="chapter" data-level="9.11.3" data-path="other-models-and-problems.html"><a href="other-models-and-problems.html#black-scholes"><i class="fa fa-check"></i><b>9.11.3</b> Black Scholes</a></li>
<li class="chapter" data-level="9.11.4" data-path="other-models-and-problems.html"><a href="other-models-and-problems.html#vasicek"><i class="fa fa-check"></i><b>9.11.4</b> Vasicek</a></li>
<li class="chapter" data-level="9.11.5" data-path="other-models-and-problems.html"><a href="other-models-and-problems.html#markovitz"><i class="fa fa-check"></i><b>9.11.5</b> Markovitz</a></li>
<li class="chapter" data-level="9.11.6" data-path="other-models-and-problems.html"><a href="other-models-and-problems.html#kmv"><i class="fa fa-check"></i><b>9.11.6</b> KMV</a></li>
<li class="chapter" data-level="9.11.7" data-path="other-models-and-problems.html"><a href="other-models-and-problems.html#credit-metrics"><i class="fa fa-check"></i><b>9.11.7</b> Credit Metrics</a></li>
<li class="chapter" data-level="9.11.8" data-path="other-models-and-problems.html"><a href="other-models-and-problems.html#credit-plus"><i class="fa fa-check"></i><b>9.11.8</b> Credit Plus</a></li>
<li class="chapter" data-level="9.11.9" data-path="other-models-and-problems.html"><a href="other-models-and-problems.html#z-scores"><i class="fa fa-check"></i><b>9.11.9</b> z-scores</a></li>
<li class="chapter" data-level="9.11.10" data-path="other-models-and-problems.html"><a href="other-models-and-problems.html#capm"><i class="fa fa-check"></i><b>9.11.10</b> CAPM</a></li>
<li class="chapter" data-level="9.11.11" data-path="other-models-and-problems.html"><a href="other-models-and-problems.html#var---value-at-risk"><i class="fa fa-check"></i><b>9.11.11</b> VaR - Value at risk</a></li>
<li class="chapter" data-level="9.11.12" data-path="other-models-and-problems.html"><a href="other-models-and-problems.html#cva"><i class="fa fa-check"></i><b>9.11.12</b> CVA</a></li>
<li class="chapter" data-level="9.11.13" data-path="other-models-and-problems.html"><a href="other-models-and-problems.html#acturial-models"><i class="fa fa-check"></i><b>9.11.13</b> Acturial models</a></li>
</ul></li>
<li class="chapter" data-level="9.12" data-path="other-models-and-problems.html"><a href="other-models-and-problems.html#biologicalmedical-models"><i class="fa fa-check"></i><b>9.12</b> Biological/Medical Models</a></li>
<li class="chapter" data-level="9.13" data-path="other-models-and-problems.html"><a href="other-models-and-problems.html#case-studies"><i class="fa fa-check"></i><b>9.13</b> Case Studies</a>
<ul>
<li class="chapter" data-level="9.13.1" data-path="other-models-and-problems.html"><a href="other-models-and-problems.html#score-cards"><i class="fa fa-check"></i><b>9.13.1</b> Score cards</a></li>
<li class="chapter" data-level="9.13.2" data-path="other-models-and-problems.html"><a href="other-models-and-problems.html#pd-models"><i class="fa fa-check"></i><b>9.13.2</b> PD models</a></li>
<li class="chapter" data-level="9.13.3" data-path="other-models-and-problems.html"><a href="other-models-and-problems.html#lgd-models"><i class="fa fa-check"></i><b>9.13.3</b> LGD models</a></li>
<li class="chapter" data-level="9.13.4" data-path="other-models-and-problems.html"><a href="other-models-and-problems.html#churn-models"><i class="fa fa-check"></i><b>9.13.4</b> Churn models</a></li>
<li class="chapter" data-level="9.13.5" data-path="other-models-and-problems.html"><a href="other-models-and-problems.html#icaap"><i class="fa fa-check"></i><b>9.13.5</b> ICAAP</a></li>
<li class="chapter" data-level="9.13.6" data-path="other-models-and-problems.html"><a href="other-models-and-problems.html#ama"><i class="fa fa-check"></i><b>9.13.6</b> AMA</a></li>
<li class="chapter" data-level="9.13.7" data-path="other-models-and-problems.html"><a href="other-models-and-problems.html#stress-tests"><i class="fa fa-check"></i><b>9.13.7</b> Stress tests</a></li>
<li class="chapter" data-level="9.13.8" data-path="other-models-and-problems.html"><a href="other-models-and-problems.html#master-scale"><i class="fa fa-check"></i><b>9.13.8</b> Master Scale</a></li>
<li class="chapter" data-level="9.13.9" data-path="other-models-and-problems.html"><a href="other-models-and-problems.html#model-summer"><i class="fa fa-check"></i><b>9.13.9</b> Model summer</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="10" data-path="appendicies.html"><a href="appendicies.html"><i class="fa fa-check"></i><b>10</b> APPENDICIES</a>
<ul>
<li class="chapter" data-level="10.1" data-path="appendicies.html"><a href="appendicies.html#appendix-a-index-of-statistical-test"><i class="fa fa-check"></i><b>10.1</b> Appendix A INDEX OF STATISTICAL TEST</a></li>
<li class="chapter" data-level="10.2" data-path="appendicies.html"><a href="appendicies.html#appendix-b-most-important-theorems-in-statistics-and-probability-calculus"><i class="fa fa-check"></i><b>10.2</b> Appendix B Most important theorems in Statistics and probability calculus</a>
<ul>
<li class="chapter" data-level="10.2.1" data-path="appendicies.html"><a href="appendicies.html#central-limit"><i class="fa fa-check"></i><b>10.2.1</b> Central Limit</a></li>
<li class="chapter" data-level="10.2.2" data-path="appendicies.html"><a href="appendicies.html#fisher-tippett-gnedenko"><i class="fa fa-check"></i><b>10.2.2</b> Fisher-Tippett-Gnedenko</a></li>
</ul></li>
<li class="chapter" data-level="10.3" data-path="appendicies.html"><a href="appendicies.html#appendix-c-different-entries"><i class="fa fa-check"></i><b>10.3</b> Appendix C Different entries</a>
<ul>
<li class="chapter" data-level="10.3.1" data-path="appendicies.html"><a href="appendicies.html#out-of-bag-error-1"><i class="fa fa-check"></i><b>10.3.1</b> out-of-bag error</a></li>
<li class="chapter" data-level="10.3.2" data-path="appendicies.html"><a href="appendicies.html#hyperparameters"><i class="fa fa-check"></i><b>10.3.2</b> hyperparameters</a></li>
<li class="chapter" data-level="10.3.3" data-path="appendicies.html"><a href="appendicies.html#information-leakage"><i class="fa fa-check"></i><b>10.3.3</b> information leakage</a></li>
<li class="chapter" data-level="10.3.4" data-path="appendicies.html"><a href="appendicies.html#apriori-vs-aposteriori"><i class="fa fa-check"></i><b>10.3.4</b> apriori vs aposteriori</a></li>
<li class="chapter" data-level="10.3.5" data-path="appendicies.html"><a href="appendicies.html#colaborative-filtering"><i class="fa fa-check"></i><b>10.3.5</b> colaborative filtering</a></li>
<li class="chapter" data-level="10.3.6" data-path="appendicies.html"><a href="appendicies.html#embedding-2"><i class="fa fa-check"></i><b>10.3.6</b> embedding</a></li>
</ul></li>
<li class="chapter" data-level="10.4" data-path="appendicies.html"><a href="appendicies.html#appendix-d-dictionary-polish---english"><i class="fa fa-check"></i><b>10.4</b> Appendix D DICTIONARY POLISH - ENGLISH</a></li>
<li class="chapter" data-level="10.5" data-path="appendicies.html"><a href="appendicies.html#links---important"><i class="fa fa-check"></i><b>10.5</b> Links - important</a>
<ul>
<li class="chapter" data-level="10.5.1" data-path="appendicies.html"><a href="appendicies.html#books"><i class="fa fa-check"></i><b>10.5.1</b> books</a></li>
<li class="chapter" data-level="10.5.2" data-path="appendicies.html"><a href="appendicies.html#strony"><i class="fa fa-check"></i><b>10.5.2</b> strony</a></li>
<li class="chapter" data-level="10.5.3" data-path="appendicies.html"><a href="appendicies.html#youtube"><i class="fa fa-check"></i><b>10.5.3</b> youtube</a></li>
<li class="chapter" data-level="10.5.4" data-path="appendicies.html"><a href="appendicies.html#narzedzia"><i class="fa fa-check"></i><b>10.5.4</b> narzedzia</a></li>
</ul></li>
<li class="chapter" data-level="10.6" data-path="appendicies.html"><a href="appendicies.html#ściąga-latex"><i class="fa fa-check"></i><b>10.6</b> <strong>Ściąga latex</strong></a></li>
<li class="chapter" data-level="10.7" data-path="appendicies.html"><a href="appendicies.html#courses-notes"><i class="fa fa-check"></i><b>10.7</b> Courses notes</a>
<ul>
<li class="chapter" data-level="10.7.1" data-path="appendicies.html"><a href="appendicies.html#udacity"><i class="fa fa-check"></i><b>10.7.1</b> Udacity</a></li>
</ul></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Data Science Book</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="auxiliary-fields" class="section level1" number="3">
<h1><span class="header-section-number">Chapter 3</span> AUXILIARY FIELDS</h1>
<div id="introduction-2" class="section level2" number="3.1">
<h2><span class="header-section-number">3.1</span> Introduction</h2>
</div>
<div id="philosophy" class="section level2" number="3.2">
<h2><span class="header-section-number">3.2</span> Philosophy</h2>
</div>
<div id="logic" class="section level2" number="3.3">
<h2><span class="header-section-number">3.3</span> Logic</h2>
</div>
<div id="psychology" class="section level2" number="3.4">
<h2><span class="header-section-number">3.4</span> Psychology</h2>
</div>
<div id="linguistics" class="section level2" number="3.5">
<h2><span class="header-section-number">3.5</span> Linguistics</h2>
</div>
<div id="cybernetics-control-theory" class="section level2" number="3.6">
<h2><span class="header-section-number">3.6</span> Cybernetics (control theory)</h2>
</div>
<div id="math_1-probability" class="section level2" number="3.7">
<h2><span class="header-section-number">3.7</span> Math_1 – Probability</h2>
<div id="basics" class="section level3" number="3.7.1">
<h3><span class="header-section-number">3.7.1</span> Basics</h3>
</div>
<div id="univariate-distributions" class="section level3" number="3.7.2">
<h3><span class="header-section-number">3.7.2</span> Univariate distributions</h3>
</div>
<div id="multivariate-distributions" class="section level3" number="3.7.3">
<h3><span class="header-section-number">3.7.3</span> Multivariate distributions</h3>
</div>
<div id="stochastic-processes" class="section level3" number="3.7.4">
<h3><span class="header-section-number">3.7.4</span> Stochastic processes</h3>
</div>
</div>
<div id="math_2-statistics" class="section level2" number="3.8">
<h2><span class="header-section-number">3.8</span> Math_2 – Statistics</h2>
<div id="descriptive-statistics" class="section level3" number="3.8.1">
<h3><span class="header-section-number">3.8.1</span> Descriptive statistics</h3>
<div id="univariate" class="section level4" number="3.8.1.1">
<h4><span class="header-section-number">3.8.1.1</span> Univariate</h4>
</div>
<div id="multivariate" class="section level4" number="3.8.1.2">
<h4><span class="header-section-number">3.8.1.2</span> Multivariate</h4>
<div id="correlation" class="section level5" number="3.8.1.2.1">
<h5><span class="header-section-number">3.8.1.2.1</span> Correlation</h5>
<p>Rozbudowane omówienie właściwości korelacji: <a href="https://www.probabilitycourse.com/chapter5/5_3_1_covariance_correlation.php">link</a></p>
<p>Kowariancja sumy zmiennych losowych:</p>
<p><img src="01_AUX/figures/kowariancja_sumy_zmiennych.PNG" /></p>
<p>Wariancja sumy zmiennych losowych:</p>
<p><img src="01_AUX/figures/wariancja_sumy_zmiennych.PNG" /></p>
<p><img src="" /></p>
<p>Różne właściwości korelacji (np. przechodniość): <a href="https://www.analyticsvidhya.com/blog/2015/06/correlation-common-questions/">link</a></p>
<p>Geometryczna interpretacja korelacji wielorakiej:</p>
<p><img src="" /></p>
<p><img src="" /></p>
<p><img src="01_AUX/figures/correlation_geometrc_interpretation.png" /><strong>Semipartial correlation</strong></p>
<p>The semipartial (or part) correlation statistic is similar to the partial correlation statistic. Both measure variance after certain factors are controlled for, but to calculate the semipartial correlation one holds the third variable constant for **either X or Y**, whereas for partial correlations one holds the third variable constant for **both**.[6] The semipartial correlation measures unique and joint variance while the partial correlation measures unique variance[clarification needed]. The semipartial (or part) correlation can be viewed as more practically relevant “because it is scaled to (i.e., relative to) the total variability in the dependent (response) variable.” [7] Conversely, it is less theoretically useful because it is less precise about the unique contribution of the independent variable. Although it may seem paradoxical, the semipartial correlation of X with Y is always less than or equal to the partial correlation of X with Y</p>
</div>
<div id="autocerrelation" class="section level5" number="3.8.1.2.2">
<h5><span class="header-section-number">3.8.1.2.2</span> Autocerrelation</h5>
<p><a href="https://towardsdatascience.com/understanding-partial-auto-correlation-fa39271146ac">link:towardsdatascience</a></p>
</div>
</div>
</div>
<div id="statistical-and-ecometrical-inference" class="section level3" number="3.8.2">
<h3><span class="header-section-number">3.8.2</span> Statistical and ecometrical inference</h3>
<div id="basics-1" class="section level4" number="3.8.2.1">
<h4><span class="header-section-number">3.8.2.1</span> Basics</h4>
</div>
<div id="pameters-estimation-algorithms" class="section level4" number="3.8.2.2">
<h4><span class="header-section-number">3.8.2.2</span> Pameters estimation algorithms</h4>
<div id="general-moments-methods" class="section level5" number="3.8.2.2.1">
<h5><span class="header-section-number">3.8.2.2.1</span> General moments methods</h5>
</div>
<div id="maxium-likehood" class="section level5" number="3.8.2.2.2">
<h5><span class="header-section-number">3.8.2.2.2</span> Maxium likehood</h5>
</div>
<div id="nonparametric-techniques" class="section level5" number="3.8.2.2.3">
<h5><span class="header-section-number">3.8.2.2.3</span> Nonparametric techniques</h5>
</div>
</div>
<div id="sampling-techniques" class="section level4" number="3.8.2.3">
<h4><span class="header-section-number">3.8.2.3</span> Sampling techniques</h4>
<div id="holdout" class="section level5" number="3.8.2.3.1">
<h5><span class="header-section-number">3.8.2.3.1</span> Holdout</h5>
</div>
<div id="boostrap" class="section level5" number="3.8.2.3.2">
<h5><span class="header-section-number">3.8.2.3.2</span> Boostrap</h5>
<p><a href="https://online.stat.psu.edu/stat555/node/119/">link</a></p>
<p>W bootstrapie z probki n-elementowej losujemy k raz podpróbki n-elementowe ALE ze zwracaniem. Losowanie próbek z podpróbek powinno symulować losowanie próbek z populacji (The population is to the sample as the sample is to the bootstrap samples). Bootstrap dzielimy na:</p>
<ul>
<li><p><strong>parametryczny</strong>: losowanie jest wykonywane z zadanego rozkładu a nie z samej próbki (czyli zakładamy że znamy klasę rozkładu, np. jest to rozkład normalny)</p></li>
<li><p><strong>semi-parametryczny</strong> : The semiparametric bootstrap assumes that the population includes <strong>other items that are similar to the observed sample by sampling from a smoothed version of the sample histogram</strong>. It turns out that this can be done very simply by first taking a sample with replacement from the observed sample (just like the nonparametric bootstrap) and then adding noise.</p></li>
<li><p><strong>nieparametryczny</strong>. Elementy są losowanie z konkretnych elementów z samej próbki.</p></li>
</ul>
<p><strong>Boostrap dla regresji</strong></p>
<p><span class="citation">(<a href="#ref-Biecek2008" role="doc-biblioref"><strong>Biecek2008?</strong></a>)</span> s 13. (link)[<a href="https://stats.stackexchange.com/questions/64813/two-ways-of-using-bootstrap-to-estimate-the-confidence-interval-of-coefficients" class="uri">https://stats.stackexchange.com/questions/64813/two-ways-of-using-bootstrap-to-estimate-the-confidence-interval-of-coefficients</a>]</p>
<ol style="list-style-type: decimal">
<li>Sample paired response-predictor: Randomly resample pairs of <span class="math inline">\(y_i−x_i\)</span>, and apply linear regression to each run. After m runs, we obtain a collection of estimated coefficients <span class="math inline">\(\hat{β_j},j=1,…,m\)</span>.. Finally, compute the quantile of <span class="math inline">\(\hat{β_j}\)</span>.</li>
<li>Sample error: First apply linear regression on the original observed data, from this model we obtain <span class="math inline">\(\hat{β_o}\)</span> and the error <span class="math inline">\(ϵ_i\)</span>. Afterwards, randomly resample the error <span class="math inline">\(ϵ_i\)</span> and compute the new data with <span class="math inline">\(\hat{β_o}\)</span> and <span class="math inline">\(y_i=\hat{β_o}x_i+ϵ_i\)</span>. Apply once again linear regression. After m runs, we obtain a collection of estimated coefficeints <span class="math inline">\(\hat{β_j},j=1,…,m\)</span>. Finally, compute the quantile of <span class="math inline">\(\hat{β_j}\)</span>.</li>
</ol>
</div>
<div id="jacknife" class="section level5" number="3.8.2.3.3">
<h5><span class="header-section-number">3.8.2.3.3</span> Jacknife</h5>
</div>
<div id="permutation" class="section level5" number="3.8.2.3.4">
<h5><span class="header-section-number">3.8.2.3.4</span> Permutation</h5>
<p><span class="citation">(<a href="#ref-Biecek2008" role="doc-biblioref"><strong>Biecek2008?</strong></a>)</span> s 13</p>
</div>
<div id="cross-validation" class="section level5" number="3.8.2.3.5">
<h5><span class="header-section-number">3.8.2.3.5</span> Cross validation</h5>
</div>
<div id="monte-carlo" class="section level5" number="3.8.2.3.6">
<h5><span class="header-section-number">3.8.2.3.6</span> Monte Carlo</h5>
<p>Hasting algorithm.</p>
<p>Bardzo dobry filmik <a href="https://www.youtube.com/watch?v=yCv2N7wGDCw">link</a> :</p>
</div>
<div id="stratified-sampling" class="section level5" number="3.8.2.3.7">
<h5><span class="header-section-number">3.8.2.3.7</span> Stratified sampling</h5>
</div>
</div>
</div>
<div id="other-issues" class="section level3" number="3.8.3">
<h3><span class="header-section-number">3.8.3</span> Other issues</h3>
<div id="similarity-and-dissimilarity-meassures-for-observations" class="section level4" number="3.8.3.1">
<h4><span class="header-section-number">3.8.3.1</span> Similarity and dissimilarity meassures for observations</h4>
</div>
<div id="similarity-and-dissimilarity-meassures-for-distributions" class="section level4" number="3.8.3.2">
<h4><span class="header-section-number">3.8.3.2</span> Similarity and dissimilarity meassures for distributions</h4>
</div>
<div id="measures-of-disorderrandomness" class="section level4" number="3.8.3.3">
<h4><span class="header-section-number">3.8.3.3</span> Measures of disorder/randomness</h4>
</div>
<div id="conformal-prediction" class="section level4" number="3.8.3.4">
<h4><span class="header-section-number">3.8.3.4</span> Conformal prediction</h4>
<div id="przykład-knn-dla-random-forest-klasyfikacja-i-regresja" class="section level5" number="3.8.3.4.1">
<h5><span class="header-section-number">3.8.3.4.1</span> Przykład knn dla random forest (klasyfikacja i regresja)</h5>
<p><img src="01_AUX/figures/conformal_1.PNG" /></p>
<p><img src="01_AUX/figures/conformal_2.PNG" /></p>
</div>
<div id="przykład-dla-knn-dla-klasyfikacji-link" class="section level5" number="3.8.3.4.2">
<h5><span class="header-section-number">3.8.3.4.2</span> Przykład dla knn dla klasyfikacji (<a href="https://medium.com/analytics-vidhya/a-guideline-to-conformal-prediction-7a392fc29bc1">link</a>)</h5>
<p>Let’s do an exercise.</p>
<p><strong><em>Training set:</em></strong><br />
1. Positive samples: (0, 3), (2, 2), (3, 3)<br />
2. Negative samples: (-1, 1), (-1, -1), (0, 1)<br />
<strong><em>Test sample:</em></strong> (0, 0)<br />
Let us calculate the euclidean distance from the new sample to each training sample.</p>
<p><img src="01_AUX/figures/conformal_knn_1.PNG" /></p>
<p>As conformity measure, use the distance to the nearest sample of a different class divided by the distance to the nearest sample of the same class.</p>
<p><img src="01_AUX/figures/conformal_knn_2.PNG" /></p>
<blockquote>
<p>1. Assume the label of (0, 0) is +1. The test sample is the strangest, so the p-value is 1/7 = 0.143.</p>
<p>2. Assume the label of (0, 0) is -1. The test sample is the second most conforming; its rank is 6, so the p-value is 6/7 = 0.857.</p>
</blockquote>
<p>The <em>p-values</em> are 0.143 (for +1) and 0.857 (for -1). We can predict -1, but our prediction does not achieve statistical significance of 5% for that we should at least have 20 training observations.</p>
</div>
</div>
<div id="paradoxes" class="section level4" number="3.8.3.5">
<h4><span class="header-section-number">3.8.3.5</span> Paradoxes</h4>
<p>3 paradoxes from kdnugget: <a href="https://www.kdnuggets.com/2021/04/top-3-statistical-paradoxes-data-science.html">link</a></p>
</div>
</div>
</div>
<div id="math_3---deep-learning" class="section level2" number="3.9">
<h2><span class="header-section-number">3.9</span> Math_3 - Deep Learning</h2>
<p>Dobry zestaw materiałów dm.in do Deep LEarningu z Pytorch : <a href="https://github.com/aladdinpersson/Machine-Learning-Collection">link</a></p>
<p>Wyprowadzenie CNN i z sieci FC (fully connected): <a href="https://www.kdnuggets.com/2018/04/derivation-convolutional-neural-network-fully-connected-step-by-step.html">link</a></p>
<div id="różne-uwagi" class="section level3" number="3.9.1">
<h3><span class="header-section-number">3.9.1</span> Różne uwagi</h3>
<div id="ogólnie-o-sieciach" class="section level4" number="3.9.1.1">
<h4><span class="header-section-number">3.9.1.1</span> Ogólnie o sieciach</h4>
<p>Jeżeli mamy w sieci kilka outputów i dla każdego z nich inną funkcję straty, to wtedy w celu umożliwianie wstecznej propagacji tworzymy jedną funkcję straty które jest np. ważoną funkcją wszystkich poszczególnych funkcji straty.</p>
<p>Kolejność elementów po warstwie trenowanej:</p>
<p>The correct order is: Conv &gt; Normalization &gt; Activation &gt; Dropout &gt; Pooling</p>
</div>
<div id="funkcje-aktywacyjne" class="section level4" number="3.9.1.2">
<h4><span class="header-section-number">3.9.1.2</span> Funkcje aktywacyjne</h4>
<p><a href="https://machinelearningmastery.com/choose-an-activation-function-for-deep-learning/" class="uri">https://machinelearningmastery.com/choose-an-activation-function-for-deep-learning/</a></p>
<p>Wybór funkcji aktywacyjnej do warstw ukrytych (hidden):</p>
<p><img src="01_AUX/figures/activation_functions_for_hidden_layers.png" /></p>
<p>Wybór funkcji aktywacyjnych do warstwy wyjściowe (output)</p>
<p><img src="01_AUX/figures/activation_functions_for_output_layers.png" /></p>
<p><strong>Dropout</strong>:</p>
<p>Na czym on polega? Wydaje mi się że wyłączenie nauronu to po prostu nałożenie na niego funkcji aktywacyjnej które niezależnie wejścia zwraca zero. Funkcja taka ma zerowy gradient, więc jeżeli robimy wsteczną propagację to nie będziemy modyfikowali wag “wyłączonego” nauronu.</p>
<p>Dodatkowo należy pamiętać o przeskalowaniu. Jeżeli w danej warstwie wyłączam <em>p</em> procent neuronów to output z pozostałych skaluje przez 1/(1+p).</p>
</div>
<div id="rnn" class="section level4" number="3.9.1.3">
<h4><span class="header-section-number">3.9.1.3</span> RNN</h4>
<p><a href="https://datascience-enthusiast.com/DL/Building_a_Recurrent_Neural_Network-Step_by_Step_v1.html">link</a> <a href="https://chowdera.com/2021/01/20210111201949567G.html">link</a></p>
<p>propagacja (Backpropagation Through Time (BPTT) wsteczna recznie rozpisana: <a href="https://towardsdatascience.com/back-to-basics-deriving-back-propagation-on-simple-rnn-lstm-feat-aidan-gomez-c7f286ba973d">link</a> <a href="https://willwolf.io/2016/10/18/recurrent-neural-network-gradients-and-lessons-learned-therein/">link</a></p>
<p>Poniżej warto pamiętać że Wx i Wh są we wszystkich miejscach te same. To zakłada oczywiście stałość rozmiaru xt i ht w kolejnych warstwach.</p>
<p><img src="01_AUX/figures/RNN_unfolding.png" /></p>
<p>LSTM:</p>
<p><img src="01_AUX/figures/LSTM_architecture.PNG" /></p>
<p>Parametry w funkcjach:</p>
<ul>
<li><p>input_dim = rozmiar wektora dla konkretnego t</p></li>
<li><p>n_layers - ilość warstw</p></li>
<li><p>hidden_dim - rozmiar output = rozmiar stanu ukrytwgo h (pamiec krotkowerminowa) = rozmiar stanu ukrytego c (pamiec dlugoterminowa).</p></li>
</ul>
<p>Embeding plus LSTM: <a href="https://towardsdatascience.com/taming-lstms-variable-sized-mini-batches-and-why-pytorch-is-good-for-your-health-61d35642972e">link</a></p>
<p>Zmienny rozmiar inputu z LSTM (batch = 1): <a href="https://stackoverflow.com/questions/49832739/variable-size-input-for-lstm-in-pytorch">link</a></p>
</div>
<div id="cnn-dwuwymiarowe" class="section level4" number="3.9.1.4">
<h4><span class="header-section-number">3.9.1.4</span> CNN dwuwymiarowe:</h4>
<p>Filtry konwolucyjne są wielowymiarowe natomiast warstwy pooling są płaskie. Po przepuszczeniu przez nie obrazu zmieniają się tylko wymiary dot. szerokości i wysokości.</p>
<div id="r-cnn-region-cnn" class="section level5" number="3.9.1.4.1">
<h5><span class="header-section-number">3.9.1.4.1</span> R-CNN (Region-CNN)</h5>
<p>podstawowe : <a href="https://towardsdatascience.com/deep-learning-method-for-object-detection-r-cnn-explained-ecdadd751d22">link</a></p>
<p>Architektura sieci:</p>
<ol style="list-style-type: decimal">
<li>Zdjęcie jest przepuszczane przez algorytm który daje propozycje regionów gdzie mogą być obiekty (ROI).</li>
<li>Każdy proponowany ROI jest przepuszczany przez sieć CNN. Ostatnia warstwa pooling w sieci CNN daje nam parametry do regresji która koryguje współrzędne bounding boxa. Dane są przepuszczane dalej do sieci FC (fully connected) która przekazuje wektor do modelu SVM który dokonuje klasyfikacji.</li>
</ol>
<p>Trenowanie sieci:</p>
<ol style="list-style-type: decimal">
<li><p>Przygotowuje sobie jakiś algorytm do tworzenia ROI (region of interest), np. Selective Search. Czyli algorytm ten zwróci nam propozycje bounding boxów gdzie mogą być jakieś elementy. Ewentualne trenowania/dostrajanie tego algorytmu jest dodatkowym zagadnieniem które nas tutaj nie interesuje. Zakładamy że mamy po prostu gotowy działający algorytm.</p></li>
<li><p>Mam zbiór ze zdjęciami gdzie na każdym jest jeden obiekt danej klasy. Na tym zbiorze wstępnie trenuje sieć (np. VGG-16).</p></li>
<li><p>Teraz zakładam że mam już zbiór ze zdjęciami gdzie każde z nich może zawierać wiele elementów rożnych klas. Dodatkowo są na nich zaznaczona poprawne (ground truth) bounding boxy. Z wstępnie wytrenowanej sieci usuwam ostatnią warstwę (output layer mogącą prognozować k klas ) i zastępują ją warstwą która ma możliwość prognozowania k+1 klas. Ta dodatkowa klasa jest po to aby umożliwić dotrenowanie sieci tak aby umożliwić wykrywanie dodatkowej klasy jaką jest tło (background). Zatem: Przepuszczam zdjęcie przez algorytm ROI. Zaproponowany przez ROI (proposed) region przekazuje do sieci. Następnie sieć klasyfikuje obiekt (wcześniej musimy zrobić resize, bo każdy obraz trafiający do sieci musi być tego samego rozmiaru). Jeżeli proponowany region pokrywa się z którym z prawdziwych regionów w przynajmniej 50% (pokrycie nazywa się: IoU - Intersection over Union) to sieć robi predykcje do jakiej klasy należy obiekt znajdujący się w tym regionie. Jeżeli pokrycie jest poniżej 50% to klasyfikujemy region jako tło (tła nie mają żadnych bounding boxów w groud truh).</p></li>
<li><p>W kolejnym etapie, znowu usuwam ostatnią klasyfikacyjną warstwę (output layer). Na bazie wyników z nowej ostatniej warstwy (jest to wektor wynikowy z warstwy FC (fully connected)), trenujemy modele binarne SVM w rozpoznawaniu obiektów. Jeżeli mamy k klas to modeli SVM będzie k. Tutaj znowu zdjęcie przechodzi przez algorytm ROI i potem przez sieć. Jeżeli dla konkretnego i-tego modelu SVM (roznającego i-tą klasę) IoU &lt; threshold to automatycznie mamy wynik negtywny, w przeciwnym razie SVM klasyfikuje region binarnie. Dodatkowo równolegle trenujemy mechanizm do korekty rozmiaru i pozycji bounding boxa, tak żeby był jak najlepiej dopasowany do obiektu. Są to 4 modele regresyjne ( (1) modyfikacja szerokości (2) modyfikacja wysokości (3) przesunięcie w pionie (4) przesunięcie w poziomie). Tak więc poprzez regresje wytrenowaną na zależności między <em>proposed region</em> i <em>ground truth</em> region dostaniemy mechanizm do korekty. Wartości tych korekt będą oczywiście dynamiczne w zależności od zdjęcia. Aby tą dynamiczność uzyskać wartościami które są parametrami regresji stają się features from the last pooling layer of the CNN.</p></li>
</ol>
</div>
<div id="fast-r-cnn" class="section level5" number="3.9.1.4.2">
<h5><span class="header-section-number">3.9.1.4.2</span> Fast R-CNN</h5>
<p><a href="https://towardsdatascience.com/fast-r-cnn-for-object-detection-a-technical-summary-a0ff94faa022">link</a></p>
</div>
<div id="fast-er-r-cnn" class="section level5" number="3.9.1.4.3">
<h5><span class="header-section-number">3.9.1.4.3</span> Fast-er R-CNN</h5>
<p><a href="https://medium.com/alegion/deep-learning-for-object-detection-and-localization-using-fast-r-cnn-85d52e3928a1">link</a>; <a href="https://medium.com/@smallfishbigsea/faster-r-cnn-explained-864d4fb7e3f8">link</a></p>
<p>Jest to ulepszenie R-CNN i Fast R-CNN. Tutaj do tworzenia RoI nie potrzebujemy dodatkowego algorytmu. RoI będą powstawały w ramach naszej sieci i będzie to tzw RPN (<em>Region proposal network</em>). Dodatkowo co CNN trafia cały obraz a nie RoI to przyśpiesza trenowanie sieci. RoI są dopiero wykorzystywane na featurach zwracanych przez CNN.</p>
<p>Architektura:</p>
<p>Na zdjęciu ustalam tzw. anchors/boxes. Są to okna o różnych rozmiarach i proporcjach. Ilość tych okien i ich rozmiar jest hiperparametrem który możemy ustawiać. Każdy anchor jest przeliczany dla każdego pixela (czyli slidujemy po każdym pixelu).</p>
<p>Zdjęcia przepuszczamy przez sieć CNN. Wyniki z CNN oraz anchors trafiają następnie do sieci RPN (<a href="https://blog.deepsense.ai/region-of-interest-pooling-explained/">link</a>), odpowiadającą za tworzenie RoI. Sieć zwraca dla każdego anchors prawdopodobieństwa że zawierają obiekt. Musimy wyselekcjonować najlepsze anchors. Robimy to poprzez NMS czyli Non-maximum suppression (<a href="https://medium.com/alegion/faster-r-cnn-using-region-proposal-network-for-object-detection-c113b6dd00a">link</a>):</p>
<ol style="list-style-type: decimal">
<li><p>Select the box that has the highest score.</p></li>
<li><p>Compute its overlap with all other boxes, and remove boxes that overlap it more than the IOU threshold</p></li>
<li><p>Go back to step 1 and iterate until there’s no more boxes with a lower score than the current selected box.</p></li>
</ol>
<p>Otrzymane najlepsze anchors są dodatkowo korygowane pod względem rozmiaru i pozycji modelem regresyjnym i dzięki temu otrzymujemy finalne RoI. Te RoI następnie służą do wycinania elementów z wyników CNN (czyli wycinamy na featurach, a nie na oryginalnym zdjęciu). Następnie przepuszczam te wyniki przez warstwę RoiI pooling która standaryzuje mi rozmiar outputu. Warstwa ta ma dynamiczny rozmiar w zależności od rozmiaru zdjęcia. Dynamiczny wymiar umożliwia właśnie stały rozmiar outputu przy zmiennym rozmiarze inputu (wycinki mogą mieć różny rozmiar i proporcje). Standaryzacja zdjęcia jest potrzebna aby można było je potem przepuścić do warstw FC (które w przeciwieństwie do warstw konwolucyjnych muszą mieć określone rozmiary).</p>
<p><img src="01_AUX/figures/Faster_RCNN.jpeg" /></p>
<p>Dalej wyniki przepuszczam przez kolejne warstwy (tutaj nie wiem czy są to po prostu od razu FC (fully connected), czy jakaś większa architektura. Ale raczej od razu powinno być FC. Tak czy inaczej na końcu zawsze jest jakieś FC i standaryzacja przez RoI pooling ma sens). Po czym mamy rozgałęzienie aby otrzymać dwie predykcje:</p>
<ul>
<li><p>klasę obiektu (konkretna klasa a nie tylko binarne rozróżnienie tło/obiekt).</p></li>
<li><p>korektę (drugą - bo pierwsza była liczona w algorytmie RNP) na współrzędne bounding box.</p></li>
</ul>
<p>O tym jak robić to rozgałęzienie trzeba poczytać w materiałach o podstawowym R-CNN.</p>
<p>Trenowanie sieci:</p>
<ol style="list-style-type: decimal">
<li><p>RPN - Siec ma rozpoznawać 2 rzeczy: po pierwsze dla każdej pozycji każdego anchora ma binarnie określać czy mamy do czynienia z obiektem czy z tłem. Po drugie musimy mieć współrzędne i wymiary bounding boxów które mają największe prawdopodobieństwo że znajduje się w nich obiekty.</p>
<p>Zatem aby wytrenować RPN pod kątem rozpoznawania tło/obiekt zakładamy, że mamy zbiór danych z gronud truch bounding boxes. Dla każdego anchor muszę określić jakie jest prawdopodobieństwo, że zawiera obiekt. Zakładam że stopień w jakim anchor pokrywa się z ground truth bounding box określa prawdopodobieństwo, że ten anchor rzeczywiście zawiera obiekt a nie tło. Zatem możemy zbudować sieć o następującym inpucie: Let’s say the 600x800 image shinks 16 times to a 39x51 feature map after applying CNNs. Every position (dla każego pixela) in the feature map has 9 anchors, and every anchor has two possible labels (background, foreground). If we make the depth of the feature map as 18 (9 anchors x 2 labels), we will make every anchor have a vector with two values (normal called logit) representing foreground and background.</p>
<p>Na outpucie siecie dajemy softmax/logistic regression activation function i trenujemy model który nam zwróci prawdopodobieństwo.</p>
<p>Następnie trenujemy też regresję do korekty proponowanych anchores. Tutaj pamiętamy, że tło (backgroud) nie ma gorund truth boxes. Ma ją je tylko obiekty. Kontynując założenia z przykładu do trenowania labeli mamy: The depth of feature map is 32 (9 anchors x 4 positions (4 bo : wysokość, szerokość, przesunięcie w pionie, przesunięcie w poziomie)).</p>
<p>The overall loss of the RPN is a combination of the classification loss and the regression loss.</p></li>
<li><p>Jeżeli chodzi o trenowanie pozostałych elementów sieci to tutaj trzeba chyba poczytać o zwykłym RCNN. Bo de facto w porównaniu do zwykłego R-CNN zmienił nam się sposób budowy i lokalizacji algorytmu RoI, ale reszta elementów powinna działać podobnie. Pytanie czy RoI można trenować równolegle z pozostałymi elementami sieci.</p></li>
</ol>
<p><img src="01_AUX/figures/Faster_RCNN_training_RPN.jpeg" /></p>
</div>
<div id="yolo" class="section level5" number="3.9.1.4.4">
<h5><span class="header-section-number">3.9.1.4.4</span> Yolo</h5>
<p>Architektura:</p>
<p>Przepuszczam obaz przez sieć po czym dostaję predykcję bounding boxów i class elementów w bounding boxach.</p>
<p>Następnie stosuje algorytm NMS. Ma 2 thresholdy. Jeden usuwa boxy któRe mają małe prawdopodobieństwa wystąpienia obiektu w boxie (niskie pc). Drui odpowiada za IoU. Jeżeli IoU wynosi <em>n</em> to elementy z tej samej klasy dla których bounding boxy pokrywają się w takim stopniu że IoU jest większy nić *n* to usuwamy je (z wyjątkiem tego o największym Pc).</p>
<p>Wady sieci. W jednej komórce może wykryć tylko jeden obiekt danej klasy.</p>
<p>Trenowanie:</p>
<p>Przygotowujemy zbiory obrazow dla których mamy podział na grid i dla każdego grida określone elementy wektora:</p>
<p>pc1</p>
<p>c1</p>
<p>…</p>
<p>cn</p>
<p>x1</p>
<p>y1</p>
<p>w1</p>
<p>h1</p>
<p>pc2</p>
<p>c1</p>
<p>…</p>
<p>cn</p>
<p>x2</p>
<p>y2</p>
<p>w2</p>
<p>h2</p>
</div>
</div>
</div>
<div id="embedding" class="section level3" number="3.9.2">
<h3><span class="header-section-number">3.9.2</span> Embedding</h3>
<p>Impelementacja word2vec w pytorch:</p>
<p><a href="https://gist.github.com/GavinXing/9954ea846072e115bb07d9758892382c" class="uri">https://gist.github.com/GavinXing/9954ea846072e115bb07d9758892382c</a></p>
<p>Logika dzialania embedding w przypadku pytorch-a dla tekstu (według moich domysłów!) jezeli chcialbym to zaimplementowac zwykla warstwa Linear:</p>
<p>Dostaje obserwacja postawi calego zdanie. Zdanie to dekomponuje na macierz o wymiarach vxd. v - o slownik (wszystkie mozliwe unikalne wyrazy we wszystkich probkach) a d to ilosc slow. Nastepnie slowo po slowie laduje do sieci i dostaje kolejne wyniki o wymiarach e (e to wymiar embeddingu).</p>
</div>
</div>
<div id="math_4-game-theory" class="section level2" number="3.10">
<h2><span class="header-section-number">3.10</span> Math_4 – Game theory</h2>
</div>
<div id="math_5-optimisation" class="section level2" number="3.11">
<h2><span class="header-section-number">3.11</span> Math_5 – Optimisation</h2>
<div id="functions-optimum" class="section level3" number="3.11.1">
<h3><span class="header-section-number">3.11.1</span> Functions optimum</h3>
</div>
<div id="functions-optimum-constrained" class="section level3" number="3.11.2">
<h3><span class="header-section-number">3.11.2</span> Functions optimum – constrained</h3>
<div id="lagrange-multipliers" class="section level4" number="3.11.2.1">
<h4><span class="header-section-number">3.11.2.1</span> Lagrange Multipliers</h4>
</div>
<div id="linear-programming" class="section level4" number="3.11.2.2">
<h4><span class="header-section-number">3.11.2.2</span> Linear programming</h4>
</div>
<div id="nonlinear-programming" class="section level4" number="3.11.2.3">
<h4><span class="header-section-number">3.11.2.3</span> Nonlinear programming</h4>
</div>
<div id="regularization" class="section level4" number="3.11.2.4">
<h4><span class="header-section-number">3.11.2.4</span> Regularization</h4>
</div>
</div>
<div id="functional-optimum" class="section level3" number="3.11.3">
<h3><span class="header-section-number">3.11.3</span> Functional optimum</h3>
<div id="dynamic-programming" class="section level4" number="3.11.3.1">
<h4><span class="header-section-number">3.11.3.1</span> Dynamic programming</h4>
</div>
<div id="calculus-of-variations" class="section level4" number="3.11.3.2">
<h4><span class="header-section-number">3.11.3.2</span> Calculus of variations</h4>
</div>
</div>
<div id="cost-functions" class="section level3" number="3.11.4">
<h3><span class="header-section-number">3.11.4</span> Cost functions</h3>
</div>
<div id="back-propagation" class="section level3" number="3.11.5">
<h3><span class="header-section-number">3.11.5</span> Back propagation</h3>
</div>
<div id="heuristic-algorithms" class="section level3" number="3.11.6">
<h3><span class="header-section-number">3.11.6</span> Heuristic algorithms</h3>
<div id="swarm-algorithm" class="section level4" number="3.11.6.1">
<h4><span class="header-section-number">3.11.6.1</span> Swarm algorithm</h4>
</div>
<div id="ants-algorithm" class="section level4" number="3.11.6.2">
<h4><span class="header-section-number">3.11.6.2</span> Ants algorithm</h4>
</div>
<div id="genetics-algorithms" class="section level4" number="3.11.6.3">
<h4><span class="header-section-number">3.11.6.3</span> Genetics algorithms</h4>
</div>
</div>
</div>
<div id="math_5-other-issues" class="section level2" number="3.12">
<h2><span class="header-section-number">3.12</span> Math_5 – Other issues</h2>
<div id="functions-usefull-in-data-science" class="section level3" number="3.12.1">
<h3><span class="header-section-number">3.12.1</span> Functions usefull in Data Science</h3>
</div>
<div id="useful-tricks" class="section level3" number="3.12.2">
<h3><span class="header-section-number">3.12.2</span> Useful tricks</h3>
</div>
<div id="linear-algebra" class="section level3" number="3.12.3">
<h3><span class="header-section-number">3.12.3</span> Linear algebra</h3>
</div>
<div id="combinatorics" class="section level3" number="3.12.4">
<h3><span class="header-section-number">3.12.4</span> Combinatorics</h3>
</div>
<div id="numerical-methods" class="section level3" number="3.12.5">
<h3><span class="header-section-number">3.12.5</span> Numerical methods</h3>
</div>
<div id="equations" class="section level3" number="3.12.6">
<h3><span class="header-section-number">3.12.6</span> Equations</h3>
<div id="x-as-number" class="section level4" number="3.12.6.1">
<h4><span class="header-section-number">3.12.6.1</span> x as number</h4>
</div>
<div id="x-as-derivative-differential-and-difference-equations" class="section level4" number="3.12.6.2">
<h4><span class="header-section-number">3.12.6.2</span> X as derivative: differential and difference equations</h4>
</div>
<div id="choas" class="section level4" number="3.12.6.3">
<h4><span class="header-section-number">3.12.6.3</span> Choas</h4>
<div id="logistic-map" class="section level5" number="3.12.6.3.1">
<h5><span class="header-section-number">3.12.6.3.1</span> logistic map</h5>
<p><a href="https://www.youtube.com/watch?v=ovJcsL7vyrk&amp;t=356s">link: varitasium channel</a></p>
</div>
</div>
</div>
<div id="fuzzy-logic" class="section level3" number="3.12.7">
<h3><span class="header-section-number">3.12.7</span> Fuzzy logic</h3>
</div>
<div id="graphs" class="section level3" number="3.12.8">
<h3><span class="header-section-number">3.12.8</span> Graphs</h3>

</div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="introduction.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="learning-patterns-discovering.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/rstudio/bookdown-demo/edit/master/01_AUX.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["bookdown-demo.pdf", "bookdown-demo.epub"],
"toc": {
"collapse": "section"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
